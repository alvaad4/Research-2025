llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     785.61 ms /    55 tokens (   14.28 ms per token,    70.01 tokens per second)

llama_perf_context_print:        eval time =     489.62 ms /     7 runs   (   69.95 ms per token,    14.30 tokens per second)

llama_perf_context_print:       total time =    1283.47 ms /    62 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     342.22 ms /    21 tokens (   16.30 ms per token,    61.36 tokens per second)

llama_perf_context_print:        eval time =    3019.86 ms /    44 runs   (   68.63 ms per token,    14.57 tokens per second)

llama_perf_context_print:       total time =    3405.91 ms /    65 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     370.61 ms /    21 tokens (   17.65 ms per token,    56.66 tokens per second)

llama_perf_context_print:        eval time =    4476.78 ms /    65 runs   (   68.87 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    4920.49 ms /    86 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     478.98 ms /    28 tokens (   17.11 ms per token,    58.46 tokens per second)

llama_perf_context_print:        eval time =    1215.05 ms /    18 runs   (   67.50 ms per token,    14.81 tokens per second)

llama_perf_context_print:       total time =    1711.83 ms /    46 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     281.11 ms /    14 tokens (   20.08 ms per token,    49.80 tokens per second)

llama_perf_context_print:        eval time =    6110.19 ms /    90 runs   (   67.89 ms per token,    14.73 tokens per second)

llama_perf_context_print:       total time =    6515.12 ms /   104 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     263.94 ms /    16 tokens (   16.50 ms per token,    60.62 tokens per second)

llama_perf_context_print:        eval time =    3818.17 ms /    56 runs   (   68.18 ms per token,    14.67 tokens per second)

llama_perf_context_print:       total time =    4149.57 ms /    72 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     281.70 ms /    17 tokens (   16.57 ms per token,    60.35 tokens per second)

llama_perf_context_print:        eval time =    2305.94 ms /    34 runs   (   67.82 ms per token,    14.74 tokens per second)

llama_perf_context_print:       total time =    2620.72 ms /    51 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     307.73 ms /    15 tokens (   20.52 ms per token,    48.74 tokens per second)

llama_perf_context_print:        eval time =     568.45 ms /     8 runs   (   71.06 ms per token,    14.07 tokens per second)

llama_perf_context_print:       total time =     884.75 ms /    23 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 7, 'total_tokens': 62}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 44, 'total_tokens': 106}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 65, 'total_tokens': 127}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 18, 'total_tokens': 87}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 90, 'total_tokens': 145}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 56, 'total_tokens': 113}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 34, 'total_tokens': 92}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     482.73 ms /    27 tokens (   17.88 ms per token,    55.93 tokens per second)

llama_perf_context_print:        eval time =     934.22 ms /    14 runs   (   66.73 ms per token,    14.99 tokens per second)

llama_perf_context_print:       total time =    1439.20 ms /    41 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     349.92 ms /    21 tokens (   16.66 ms per token,    60.01 tokens per second)

llama_perf_context_print:        eval time =    8305.07 ms /   121 runs   (   68.64 ms per token,    14.57 tokens per second)

llama_perf_context_print:       total time =    8781.77 ms /   142 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1362.02 ms /    90 tokens (   15.13 ms per token,    66.08 tokens per second)

llama_perf_context_print:        eval time =   22013.66 ms /   315 runs   (   69.88 ms per token,    14.31 tokens per second)

llama_perf_context_print:       total time =   23797.56 ms /   405 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     608.30 ms /    40 tokens (   15.21 ms per token,    65.76 tokens per second)

llama_perf_context_print:        eval time =   12529.47 ms /   182 runs   (   68.84 ms per token,    14.53 tokens per second)

llama_perf_context_print:       total time =   13360.06 ms /   222 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     774.69 ms /    51 tokens (   15.19 ms per token,    65.83 tokens per second)

llama_perf_context_print:        eval time =    9977.22 ms /   145 runs   (   68.81 ms per token,    14.53 tokens per second)

llama_perf_context_print:       total time =   10929.08 ms /   196 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 8, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 14, 'total_tokens': 82}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 121, 'total_tokens': 183}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 315, 'total_tokens': 446}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 182, 'total_tokens': 263}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     892.88 ms /    58 tokens (   15.39 ms per token,    64.96 tokens per second)

llama_perf_context_print:        eval time =    4216.81 ms /    61 runs   (   69.13 ms per token,    14.47 tokens per second)

llama_perf_context_print:       total time =    5169.30 ms /   119 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     464.84 ms /    29 tokens (   16.03 ms per token,    62.39 tokens per second)

llama_perf_context_print:        eval time =    5441.14 ms /    79 runs   (   68.88 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    5984.71 ms /   108 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     370.62 ms /    24 tokens (   15.44 ms per token,    64.76 tokens per second)

llama_perf_context_print:        eval time =   19230.37 ms /   278 runs   (   69.17 ms per token,    14.46 tokens per second)

llama_perf_context_print:       total time =   19975.44 ms /   302 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     771.94 ms /    51 tokens (   15.14 ms per token,    66.07 tokens per second)

llama_perf_context_print:        eval time =    4214.67 ms /    61 runs   (   69.09 ms per token,    14.47 tokens per second)

llama_perf_context_print:       total time =    5046.59 ms /   112 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 145, 'total_tokens': 237}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 61, 'total_tokens': 160}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 79, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 278, 'total_tokens': 342}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 61, 'total_tokens': 153}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     882.96 ms /    58 tokens (   15.22 ms per token,    65.69 tokens per second)

llama_perf_context_print:        eval time =   21402.88 ms /   308 runs   (   69.49 ms per token,    14.39 tokens per second)

llama_perf_context_print:       total time =   22676.91 ms /   366 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1207.64 ms /    63 tokens (   19.17 ms per token,    52.17 tokens per second)

llama_perf_context_print:        eval time =   15830.29 ms /   228 runs   (   69.43 ms per token,    14.40 tokens per second)

llama_perf_context_print:       total time =   17312.08 ms /   291 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1511.69 ms /   102 tokens (   14.82 ms per token,    67.47 tokens per second)

llama_perf_context_print:        eval time =   11756.38 ms /   170 runs   (   69.16 ms per token,    14.46 tokens per second)

llama_perf_context_print:       total time =   13491.50 ms /   272 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 308, 'total_tokens': 410}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 228, 'total_tokens': 335}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     793.69 ms /    51 tokens (   15.56 ms per token,    64.26 tokens per second)

llama_perf_context_print:        eval time =   17591.90 ms /   254 runs   (   69.26 ms per token,    14.44 tokens per second)

llama_perf_context_print:       total time =   18725.03 ms /   305 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     827.32 ms /    54 tokens (   15.32 ms per token,    65.27 tokens per second)

llama_perf_context_print:        eval time =   10910.08 ms /   158 runs   (   69.05 ms per token,    14.48 tokens per second)

llama_perf_context_print:       total time =   11920.76 ms /   212 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     526.88 ms /    34 tokens (   15.50 ms per token,    64.53 tokens per second)

llama_perf_context_print:        eval time =    8861.14 ms /   129 runs   (   68.69 ms per token,    14.56 tokens per second)

llama_perf_context_print:       total time =    9529.76 ms /   163 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     724.90 ms /    45 tokens (   16.11 ms per token,    62.08 tokens per second)

llama_perf_context_print:        eval time =   21158.73 ms /   304 runs   (   69.60 ms per token,    14.37 tokens per second)

llama_perf_context_print:       total time =   22269.26 ms /   349 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 143, 'completion_tokens': 170, 'total_tokens': 313}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 91, 'completion_tokens': 254, 'total_tokens': 345}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 158, 'total_tokens': 252}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 129, 'total_tokens': 204}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1171.67 ms /    75 tokens (   15.62 ms per token,    64.01 tokens per second)

llama_perf_context_print:        eval time =   28866.16 ms /   411 runs   (   70.23 ms per token,    14.24 tokens per second)

llama_perf_context_print:       total time =   30594.75 ms /   486 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     674.07 ms /    42 tokens (   16.05 ms per token,    62.31 tokens per second)

llama_perf_context_print:        eval time =    9338.51 ms /   136 runs   (   68.67 ms per token,    14.56 tokens per second)

llama_perf_context_print:       total time =   10170.41 ms /   178 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 304, 'total_tokens': 390}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 116, 'completion_tokens': 411, 'total_tokens': 527}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     493.11 ms /    29 tokens (   17.00 ms per token,    58.81 tokens per second)

llama_perf_context_print:        eval time =   20085.16 ms /   290 runs   (   69.26 ms per token,    14.44 tokens per second)

llama_perf_context_print:       total time =   20952.44 ms /   319 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     695.21 ms /    43 tokens (   16.17 ms per token,    61.85 tokens per second)

llama_perf_context_print:        eval time =    8410.92 ms /   123 runs   (   68.38 ms per token,    14.62 tokens per second)

llama_perf_context_print:       total time =    9249.04 ms /   166 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     560.44 ms /    35 tokens (   16.01 ms per token,    62.45 tokens per second)

llama_perf_context_print:        eval time =    7876.34 ms /   114 runs   (   69.09 ms per token,    14.47 tokens per second)

llama_perf_context_print:       total time =    8564.52 ms /   149 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     452.62 ms /    28 tokens (   16.16 ms per token,    61.86 tokens per second)

llama_perf_context_print:        eval time =    9944.99 ms /   144 runs   (   69.06 ms per token,    14.48 tokens per second)

llama_perf_context_print:       total time =   10566.00 ms /   172 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     345.41 ms /    21 tokens (   16.45 ms per token,    60.80 tokens per second)

llama_perf_context_print:        eval time =    3079.91 ms /    45 runs   (   68.44 ms per token,    14.61 tokens per second)

llama_perf_context_print:       total time =    3468.94 ms /    66 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 136, 'total_tokens': 219}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 290, 'total_tokens': 360}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 123, 'total_tokens': 207}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 114, 'total_tokens': 190}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 144, 'total_tokens': 213}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     435.30 ms /    26 tokens (   16.74 ms per token,    59.73 tokens per second)

llama_perf_context_print:        eval time =   27427.07 ms /   393 runs   (   69.79 ms per token,    14.33 tokens per second)

llama_perf_context_print:       total time =   28387.27 ms /   419 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     513.74 ms /    33 tokens (   15.57 ms per token,    64.23 tokens per second)

llama_perf_context_print:        eval time =    5235.27 ms /    76 runs   (   68.89 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    5824.47 ms /   109 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     327.92 ms /    20 tokens (   16.40 ms per token,    60.99 tokens per second)

llama_perf_context_print:        eval time =   12724.88 ms /   185 runs   (   68.78 ms per token,    14.54 tokens per second)

llama_perf_context_print:       total time =   13268.92 ms /   205 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     306.91 ms /    15 tokens (   20.46 ms per token,    48.87 tokens per second)

llama_perf_context_print:        eval time =    1845.97 ms /    27 runs   (   68.37 ms per token,    14.63 tokens per second)

llama_perf_context_print:       total time =    2179.21 ms /    42 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 45, 'total_tokens': 108}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 393, 'total_tokens': 459}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 76, 'total_tokens': 149}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 185, 'total_tokens': 246}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     343.47 ms /    19 tokens (   18.08 ms per token,    55.32 tokens per second)

llama_perf_context_print:        eval time =   28204.99 ms /   405 runs   (   69.64 ms per token,    14.36 tokens per second)

llama_perf_context_print:       total time =   29144.21 ms /   424 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     281.85 ms /    14 tokens (   20.13 ms per token,    49.67 tokens per second)

llama_perf_context_print:        eval time =     691.04 ms /    10 runs   (   69.10 ms per token,    14.47 tokens per second)

llama_perf_context_print:       total time =     983.20 ms /    24 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     399.74 ms /    23 tokens (   17.38 ms per token,    57.54 tokens per second)

llama_perf_context_print:        eval time =    1310.69 ms /    19 runs   (   68.98 ms per token,    14.50 tokens per second)

llama_perf_context_print:       total time =    1729.65 ms /    42 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     311.57 ms /    18 tokens (   17.31 ms per token,    57.77 tokens per second)

llama_perf_context_print:        eval time =   31928.81 ms /   458 runs   (   69.71 ms per token,    14.34 tokens per second)

llama_perf_context_print:       total time =   32908.53 ms /   476 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 27, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 405, 'total_tokens': 465}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 19, 'total_tokens': 83}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     573.03 ms /    35 tokens (   16.37 ms per token,    61.08 tokens per second)

llama_perf_context_print:        eval time =    6108.44 ms /    89 runs   (   68.63 ms per token,    14.57 tokens per second)

llama_perf_context_print:       total time =    6787.77 ms /   124 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1414.59 ms /    93 tokens (   15.21 ms per token,    65.74 tokens per second)

llama_perf_context_print:        eval time =    3430.92 ms /    50 runs   (   68.62 ms per token,    14.57 tokens per second)

llama_perf_context_print:       total time =    4903.02 ms /   143 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1682.63 ms /   111 tokens (   15.16 ms per token,    65.97 tokens per second)

llama_perf_context_print:        eval time =    5593.89 ms /    81 runs   (   69.06 ms per token,    14.48 tokens per second)

llama_perf_context_print:       total time =    7373.95 ms /   192 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 458, 'total_tokens': 517}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 89, 'total_tokens': 165}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 134, 'completion_tokens': 50, 'total_tokens': 184}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1935.28 ms /   133 tokens (   14.55 ms per token,    68.72 tokens per second)

llama_perf_context_print:        eval time =    4382.76 ms /    63 runs   (   69.57 ms per token,    14.37 tokens per second)

llama_perf_context_print:       total time =    6380.48 ms /   196 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1725.34 ms /   117 tokens (   14.75 ms per token,    67.81 tokens per second)

llama_perf_context_print:        eval time =    4179.54 ms /    61 runs   (   68.52 ms per token,    14.59 tokens per second)

llama_perf_context_print:       total time =    5984.73 ms /   178 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1143.82 ms /    76 tokens (   15.05 ms per token,    66.44 tokens per second)

llama_perf_context_print:        eval time =    1098.35 ms /    16 runs   (   68.65 ms per token,    14.57 tokens per second)

llama_perf_context_print:       total time =    2258.12 ms /    92 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1939.43 ms /   133 tokens (   14.58 ms per token,    68.58 tokens per second)

llama_perf_context_print:        eval time =    5804.27 ms /    84 runs   (   69.10 ms per token,    14.47 tokens per second)

llama_perf_context_print:       total time =    7835.75 ms /   217 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 152, 'completion_tokens': 81, 'total_tokens': 233}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 63, 'total_tokens': 237}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 158, 'completion_tokens': 61, 'total_tokens': 219}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 16, 'total_tokens': 133}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 84, 'total_tokens': 258}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1453.44 ms /    98 tokens (   14.83 ms per token,    67.43 tokens per second)

llama_perf_context_print:        eval time =    6226.91 ms /    90 runs   (   69.19 ms per token,    14.45 tokens per second)

llama_perf_context_print:       total time =    7770.90 ms /   188 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     466.05 ms /    27 tokens (   17.26 ms per token,    57.93 tokens per second)

llama_perf_context_print:        eval time =    7881.55 ms /   115 runs   (   68.54 ms per token,    14.59 tokens per second)

llama_perf_context_print:       total time =    8482.24 ms /   142 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1019.87 ms /    67 tokens (   15.22 ms per token,    65.69 tokens per second)

llama_perf_context_print:        eval time =    2204.50 ms /    32 runs   (   68.89 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    3263.53 ms /    99 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     364.76 ms /    22 tokens (   16.58 ms per token,    60.31 tokens per second)

llama_perf_context_print:        eval time =    3765.47 ms /    55 runs   (   68.46 ms per token,    14.61 tokens per second)

llama_perf_context_print:       total time =    4184.07 ms /    77 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     679.74 ms /    43 tokens (   15.81 ms per token,    63.26 tokens per second)

llama_perf_context_print:        eval time =    2214.07 ms /    32 runs   (   69.19 ms per token,    14.45 tokens per second)

llama_perf_context_print:       total time =    2924.67 ms /    75 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     921.59 ms /    59 tokens (   15.62 ms per token,    64.02 tokens per second)

llama_perf_context_print:        eval time =    3493.24 ms /    51 runs   (   68.49 ms per token,    14.60 tokens per second)

llama_perf_context_print:       total time =    4464.76 ms /   110 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     801.00 ms /    53 tokens (   15.11 ms per token,    66.17 tokens per second)

llama_perf_context_print:        eval time =    2125.27 ms /    31 runs   (   68.56 ms per token,    14.59 tokens per second)

llama_perf_context_print:       total time =    2956.65 ms /    84 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 139, 'completion_tokens': 90, 'total_tokens': 229}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 115, 'total_tokens': 183}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 32, 'total_tokens': 140}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 55, 'total_tokens': 118}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 32, 'total_tokens': 116}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 51, 'total_tokens': 151}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1142.39 ms /    76 tokens (   15.03 ms per token,    66.53 tokens per second)

llama_perf_context_print:        eval time =    6014.90 ms /    87 runs   (   69.14 ms per token,    14.46 tokens per second)

llama_perf_context_print:       total time =    7244.50 ms /   163 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     992.47 ms /    66 tokens (   15.04 ms per token,    66.50 tokens per second)

llama_perf_context_print:        eval time =    2892.35 ms /    42 runs   (   68.87 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    3933.57 ms /   108 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     942.27 ms /    61 tokens (   15.45 ms per token,    64.74 tokens per second)

llama_perf_context_print:        eval time =    3402.55 ms /    49 runs   (   69.44 ms per token,    14.40 tokens per second)

llama_perf_context_print:       total time =    4400.58 ms /   110 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     751.26 ms /    52 tokens (   14.45 ms per token,    69.22 tokens per second)

llama_perf_context_print:        eval time =    2868.76 ms /    42 runs   (   68.30 ms per token,    14.64 tokens per second)

llama_perf_context_print:       total time =    3669.12 ms /    94 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     851.68 ms /    55 tokens (   15.49 ms per token,    64.58 tokens per second)

llama_perf_context_print:        eval time =    2767.74 ms /    40 runs   (   69.19 ms per token,    14.45 tokens per second)

llama_perf_context_print:       total time =    3658.22 ms /    95 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     711.10 ms /    45 tokens (   15.80 ms per token,    63.28 tokens per second)

llama_perf_context_print:        eval time =    1978.47 ms /    29 runs   (   68.22 ms per token,    14.66 tokens per second)

llama_perf_context_print:       total time =    2717.98 ms /    74 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     950.55 ms /    61 tokens (   15.58 ms per token,    64.17 tokens per second)

llama_perf_context_print:        eval time =    2708.39 ms /    40 runs   (   67.71 ms per token,    14.77 tokens per second)

llama_perf_context_print:       total time =    3706.06 ms /   101 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 31, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 87, 'total_tokens': 204}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 42, 'total_tokens': 149}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 49, 'total_tokens': 151}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 93, 'completion_tokens': 42, 'total_tokens': 135}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 40, 'total_tokens': 136}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 29, 'total_tokens': 115}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     321.99 ms /    15 tokens (   21.47 ms per token,    46.59 tokens per second)

llama_perf_context_print:        eval time =    2955.99 ms /    43 runs   (   68.74 ms per token,    14.55 tokens per second)

llama_perf_context_print:       total time =    3319.92 ms /    58 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     932.60 ms /    59 tokens (   15.81 ms per token,    63.26 tokens per second)

llama_perf_context_print:        eval time =    1374.22 ms /    20 runs   (   68.71 ms per token,    14.55 tokens per second)

llama_perf_context_print:       total time =    2326.57 ms /    79 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     270.58 ms /    17 tokens (   15.92 ms per token,    62.83 tokens per second)

llama_perf_context_print:        eval time =     486.62 ms /     7 runs   (   69.52 ms per token,    14.38 tokens per second)

llama_perf_context_print:       total time =     764.72 ms /    24 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     764.12 ms /    47 tokens (   16.26 ms per token,    61.51 tokens per second)

llama_perf_context_print:        eval time =    1564.20 ms /    23 runs   (   68.01 ms per token,    14.70 tokens per second)

llama_perf_context_print:       total time =    2351.16 ms /    70 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     367.49 ms /    21 tokens (   17.50 ms per token,    57.14 tokens per second)

llama_perf_context_print:        eval time =    1086.37 ms /    16 runs   (   67.90 ms per token,    14.73 tokens per second)

llama_perf_context_print:       total time =    1469.46 ms /    37 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     713.23 ms /    49 tokens (   14.56 ms per token,    68.70 tokens per second)

llama_perf_context_print:        eval time =    1254.18 ms /    18 runs   (   69.68 ms per token,    14.35 tokens per second)

llama_perf_context_print:       total time =    1986.19 ms /    67 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     269.07 ms /    17 tokens (   15.83 ms per token,    63.18 tokens per second)

llama_perf_context_print:        eval time =     832.64 ms /    12 runs   (   69.39 ms per token,    14.41 tokens per second)

llama_perf_context_print:       total time =    1124.74 ms /    29 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1073.24 ms /    71 tokens (   15.12 ms per token,    66.16 tokens per second)

llama_perf_context_print:        eval time =    1308.07 ms /    19 runs   (   68.85 ms per token,    14.53 tokens per second)

llama_perf_context_print:       total time =    2399.97 ms /    90 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     308.43 ms /    20 tokens (   15.42 ms per token,    64.84 tokens per second)

llama_perf_context_print:        eval time =    1239.69 ms /    18 runs   (   68.87 ms per token,    14.52 tokens per second)

llama_perf_context_print:       total time =    1565.88 ms /    38 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 40, 'total_tokens': 142}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 43, 'total_tokens': 99}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 20, 'total_tokens': 120}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 88, 'completion_tokens': 23, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 16, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 18, 'total_tokens': 108}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 12, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 19, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 18, 'total_tokens': 78}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     950.25 ms /    61 tokens (   15.58 ms per token,    64.19 tokens per second)

llama_perf_context_print:        eval time =    1222.39 ms /    18 runs   (   67.91 ms per token,    14.73 tokens per second)

llama_perf_context_print:       total time =    2190.32 ms /    79 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     690.70 ms /    44 tokens (   15.70 ms per token,    63.70 tokens per second)

llama_perf_context_print:        eval time =    1774.32 ms /    26 runs   (   68.24 ms per token,    14.65 tokens per second)

llama_perf_context_print:       total time =    2490.55 ms /    70 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     582.91 ms /    37 tokens (   15.75 ms per token,    63.47 tokens per second)

llama_perf_context_print:        eval time =    3214.12 ms /    47 runs   (   68.39 ms per token,    14.62 tokens per second)

llama_perf_context_print:       total time =    3842.96 ms /    84 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     617.68 ms /    40 tokens (   15.44 ms per token,    64.76 tokens per second)

llama_perf_context_print:        eval time =    3347.02 ms /    49 runs   (   68.31 ms per token,    14.64 tokens per second)

llama_perf_context_print:       total time =    4012.35 ms /    89 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     699.53 ms /    43 tokens (   16.27 ms per token,    61.47 tokens per second)

llama_perf_context_print:        eval time =    1587.63 ms /    23 runs   (   69.03 ms per token,    14.49 tokens per second)

llama_perf_context_print:       total time =    2309.79 ms /    66 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     833.24 ms /    55 tokens (   15.15 ms per token,    66.01 tokens per second)

llama_perf_context_print:        eval time =    2884.62 ms /    42 runs   (   68.68 ms per token,    14.56 tokens per second)

llama_perf_context_print:       total time =    3758.78 ms /    97 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     721.80 ms /    43 tokens (   16.79 ms per token,    59.57 tokens per second)

llama_perf_context_print:        eval time =     828.66 ms /    12 runs   (   69.06 ms per token,    14.48 tokens per second)

llama_perf_context_print:       total time =    1563.04 ms /    55 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     710.87 ms /    43 tokens (   16.53 ms per token,    60.49 tokens per second)

llama_perf_context_print:        eval time =    3510.13 ms /    51 runs   (   68.83 ms per token,    14.53 tokens per second)

llama_perf_context_print:       total time =    4272.12 ms /    94 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 101, 'completion_tokens': 18, 'total_tokens': 119}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 26, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 47, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 49, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 23, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 42, 'total_tokens': 138}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 12, 'total_tokens': 96}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 51, 'total_tokens': 135}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     714.07 ms /    45 tokens (   15.87 ms per token,    63.02 tokens per second)

llama_perf_context_print:        eval time =    2116.66 ms /    31 runs   (   68.28 ms per token,    14.65 tokens per second)

llama_perf_context_print:       total time =    2860.56 ms /    76 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     748.69 ms /    46 tokens (   16.28 ms per token,    61.44 tokens per second)

llama_perf_context_print:        eval time =    3136.43 ms /    46 runs   (   68.18 ms per token,    14.67 tokens per second)

llama_perf_context_print:       total time =    3929.96 ms /    92 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     582.08 ms /    37 tokens (   15.73 ms per token,    63.57 tokens per second)

llama_perf_context_print:        eval time =    6103.22 ms /    89 runs   (   68.58 ms per token,    14.58 tokens per second)

llama_perf_context_print:       total time =    6782.23 ms /   126 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     856.89 ms /    57 tokens (   15.03 ms per token,    66.52 tokens per second)

llama_perf_context_print:        eval time =   16305.41 ms /   235 runs   (   69.38 ms per token,    14.41 tokens per second)

llama_perf_context_print:       total time =   17449.97 ms /   292 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     690.18 ms /    44 tokens (   15.69 ms per token,    63.75 tokens per second)

llama_perf_context_print:        eval time =   14565.93 ms /   211 runs   (   69.03 ms per token,    14.49 tokens per second)

llama_perf_context_print:       total time =   15518.95 ms /   255 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 31, 'total_tokens': 117}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 46, 'total_tokens': 133}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 89, 'total_tokens': 167}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 235, 'total_tokens': 322}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     777.58 ms /    51 tokens (   15.25 ms per token,    65.59 tokens per second)

llama_perf_context_print:        eval time =   12983.56 ms /   188 runs   (   69.06 ms per token,    14.48 tokens per second)

llama_perf_context_print:       total time =   13991.54 ms /   239 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1153.76 ms /    76 tokens (   15.18 ms per token,    65.87 tokens per second)

llama_perf_context_print:        eval time =   26055.41 ms /   372 runs   (   70.04 ms per token,    14.28 tokens per second)

llama_perf_context_print:       total time =   27711.61 ms /   448 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 74, 'completion_tokens': 211, 'total_tokens': 285}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 188, 'total_tokens': 269}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     843.33 ms /    56 tokens (   15.06 ms per token,    66.40 tokens per second)

llama_perf_context_print:        eval time =    9910.19 ms /   144 runs   (   68.82 ms per token,    14.53 tokens per second)

llama_perf_context_print:       total time =   10932.18 ms /   200 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     923.49 ms /    58 tokens (   15.92 ms per token,    62.81 tokens per second)

llama_perf_context_print:        eval time =   18472.13 ms /   266 runs   (   69.44 ms per token,    14.40 tokens per second)

llama_perf_context_print:       total time =   19738.87 ms /   324 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     864.83 ms /    56 tokens (   15.44 ms per token,    64.75 tokens per second)

llama_perf_context_print:        eval time =   33020.58 ms /   469 runs   (   70.41 ms per token,    14.20 tokens per second)

llama_perf_context_print:       total time =   34615.34 ms /   525 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 372, 'total_tokens': 478}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 144, 'total_tokens': 230}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 89, 'completion_tokens': 266, 'total_tokens': 355}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     422.89 ms /    29 tokens (   14.58 ms per token,    68.58 tokens per second)

llama_perf_context_print:        eval time =     433.12 ms /     6 runs   (   72.19 ms per token,    13.85 tokens per second)

llama_perf_context_print:       total time =     862.12 ms /    35 tokens

llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =     830.14 ms /    55 tokens (   15.09 ms per token,    66.25 tokens per second)

llama_perf_context_print:        eval time =   23033.87 ms /   331 runs   (   69.59 ms per token,    14.37 tokens per second)

llama_perf_context_print:       total time =   24311.67 ms /   386 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 469, 'total_tokens': 555}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
llama_perf_context_print:        load time =     785.73 ms

llama_perf_context_print: prompt eval time =    1619.90 ms /   107 tokens (   15.14 ms per token,    66.05 tokens per second)

llama_perf_context_print:        eval time =   15483.85 ms /   222 runs   (   69.75 ms per token,    14.34 tokens per second)

llama_perf_context_print:       total time =   17396.07 ms /   329 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 331, 'total_tokens': 416}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 137, 'completion_tokens': 222, 'total_tokens': 359}}
