logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 8, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 75, 'total_tokens': 153}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 17, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 9, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 41, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 335, 'total_tokens': 396}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 42, 'total_tokens': 102}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 15, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 134, 'total_tokens': 191}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 74, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 142, 'total_tokens': 225}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 391, 'total_tokens': 461}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 10, 'total_tokens': 68}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 96, 'total_tokens': 172}}
logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 452, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 36, 'total_tokens': 105}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 71, 'total_tokens': 136}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 159, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 38, 'total_tokens': 116}}
logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 450, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 19, 'total_tokens': 91}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 69, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 144, 'total_tokens': 201}}
llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   57172.10 ms /    58 tokens (  985.73 ms per token,     1.01 tokens per second)

llama_perf_context_print:        eval time =    3493.38 ms /     7 runs   (  499.05 ms per token,     2.00 tokens per second)

llama_perf_context_print:       total time =   60689.69 ms /    65 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   45871.31 ms /    38 tokens ( 1207.14 ms per token,     0.83 tokens per second)

llama_perf_context_print:        eval time =    3048.87 ms /     8 runs   (  381.11 ms per token,     2.62 tokens per second)

llama_perf_context_print:       total time =   48928.23 ms /    46 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   55782.54 ms /    38 tokens ( 1467.96 ms per token,     0.68 tokens per second)

llama_perf_context_print:        eval time =   28302.62 ms /    75 runs   (  377.37 ms per token,     2.65 tokens per second)

llama_perf_context_print:       total time =   84176.41 ms /   113 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   59860.33 ms /    33 tokens ( 1813.95 ms per token,     0.55 tokens per second)

llama_perf_context_print:        eval time =    4802.05 ms /    17 runs   (  282.47 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   64681.66 ms /    50 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   21497.86 ms /    24 tokens (  895.74 ms per token,     1.12 tokens per second)

llama_perf_context_print:        eval time =    2538.80 ms /     9 runs   (  282.09 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   24047.27 ms /    33 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   26122.31 ms /    22 tokens ( 1187.38 ms per token,     0.84 tokens per second)

llama_perf_context_print:        eval time =   11880.45 ms /    41 runs   (  289.77 ms per token,     3.45 tokens per second)

llama_perf_context_print:       total time =   38048.57 ms /    63 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   27805.91 ms /    20 tokens ( 1390.30 ms per token,     0.72 tokens per second)

llama_perf_context_print:        eval time =  123193.10 ms /   335 runs   (  367.74 ms per token,     2.72 tokens per second)

llama_perf_context_print:       total time =  151477.41 ms /   355 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   23431.91 ms /    19 tokens ( 1233.26 ms per token,     0.81 tokens per second)

llama_perf_context_print:        eval time =   12263.13 ms /    42 runs   (  291.98 ms per token,     3.42 tokens per second)

llama_perf_context_print:       total time =   35742.83 ms /    61 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   45106.77 ms /    26 tokens ( 1734.88 ms per token,     0.58 tokens per second)

llama_perf_context_print:        eval time =    6539.89 ms /    15 runs   (  435.99 ms per token,     2.29 tokens per second)

llama_perf_context_print:       total time =   51661.37 ms /    41 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   36750.47 ms /    17 tokens ( 2161.79 ms per token,     0.46 tokens per second)

llama_perf_context_print:        eval time =   50742.08 ms /   134 runs   (  378.67 ms per token,     2.64 tokens per second)

llama_perf_context_print:       total time =   87639.88 ms /   151 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   55920.06 ms /    56 tokens (  998.57 ms per token,     1.00 tokens per second)

llama_perf_context_print:        eval time =   21021.87 ms /    74 runs   (  284.08 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =   77025.21 ms /   130 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 8, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 75, 'total_tokens': 153}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 17, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 9, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 41, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 335, 'total_tokens': 396}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 42, 'total_tokens': 102}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 15, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 134, 'total_tokens': 191}}
llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   22895.94 ms /    14 tokens ( 1635.42 ms per token,     0.61 tokens per second)

llama_perf_context_print:        eval time =    3939.75 ms /    10 runs   (  393.97 ms per token,     2.54 tokens per second)

llama_perf_context_print:       total time =   26862.91 ms /    24 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   62298.17 ms /    42 tokens ( 1483.29 ms per token,     0.67 tokens per second)

llama_perf_context_print:        eval time =   43098.05 ms /   142 runs   (  303.51 ms per token,     3.29 tokens per second)

llama_perf_context_print:       total time =  105569.62 ms /   184 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   20819.97 ms /    29 tokens (  717.93 ms per token,     1.39 tokens per second)

llama_perf_context_print:        eval time =  133900.55 ms /   391 runs   (  342.46 ms per token,     2.92 tokens per second)

llama_perf_context_print:       total time =  155283.66 ms /   420 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   44711.64 ms /    17 tokens ( 2630.10 ms per token,     0.38 tokens per second)

llama_perf_context_print:        eval time =    3635.12 ms /    10 runs   (  363.51 ms per token,     2.75 tokens per second)

llama_perf_context_print:       total time =   48356.73 ms /    27 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   36242.15 ms /    35 tokens ( 1035.49 ms per token,     0.97 tokens per second)

llama_perf_context_print:        eval time =   28393.60 ms /    96 runs   (  295.77 ms per token,     3.38 tokens per second)

llama_perf_context_print:       total time =   64742.30 ms /   131 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   26191.64 ms /    19 tokens ( 1378.51 ms per token,     0.73 tokens per second)

llama_perf_context_print:        eval time =  149208.27 ms /   451 runs   (  330.84 ms per token,     3.02 tokens per second)

llama_perf_context_print:       total time =  176067.74 ms /   470 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 74, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 142, 'total_tokens': 225}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 391, 'total_tokens': 461}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 10, 'total_tokens': 68}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 96, 'total_tokens': 172}}
llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   41763.00 ms /    28 tokens ( 1491.54 ms per token,     0.67 tokens per second)

llama_perf_context_print:        eval time =   15856.82 ms /    36 runs   (  440.47 ms per token,     2.27 tokens per second)

llama_perf_context_print:       total time =   57654.60 ms /    64 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   30119.18 ms /    24 tokens ( 1254.97 ms per token,     0.80 tokens per second)

llama_perf_context_print:        eval time =   20533.17 ms /    71 runs   (  289.20 ms per token,     3.46 tokens per second)

llama_perf_context_print:       total time =   50735.14 ms /    95 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   42878.58 ms /    35 tokens ( 1225.10 ms per token,     0.82 tokens per second)

llama_perf_context_print:        eval time =   60941.65 ms /   159 runs   (  383.28 ms per token,     2.61 tokens per second)

llama_perf_context_print:       total time =  104026.51 ms /   194 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   28224.71 ms /    37 tokens (  762.83 ms per token,     1.31 tokens per second)

llama_perf_context_print:        eval time =   11213.00 ms /    38 runs   (  295.08 ms per token,     3.39 tokens per second)

llama_perf_context_print:       total time =   39479.35 ms /    75 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   20638.78 ms /    21 tokens (  982.80 ms per token,     1.02 tokens per second)

llama_perf_context_print:        eval time =  153731.44 ms /   449 runs   (  342.39 ms per token,     2.92 tokens per second)

llama_perf_context_print:       total time =  175053.15 ms /   470 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 452, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 36, 'total_tokens': 105}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 71, 'total_tokens': 136}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 159, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 38, 'total_tokens': 116}}
llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   38634.83 ms /    32 tokens ( 1207.34 ms per token,     0.83 tokens per second)

llama_perf_context_print:        eval time =    7592.92 ms /    19 runs   (  399.63 ms per token,     2.50 tokens per second)

llama_perf_context_print:       total time =   46246.39 ms /    51 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   36516.43 ms /    21 tokens ( 1738.88 ms per token,     0.58 tokens per second)

llama_perf_context_print:        eval time =   20442.57 ms /    69 runs   (  296.27 ms per token,     3.38 tokens per second)

llama_perf_context_print:       total time =   57037.96 ms /    90 tokens

llama_perf_context_print:        load time =   57172.31 ms

llama_perf_context_print: prompt eval time =   21526.31 ms /    16 tokens ( 1345.39 ms per token,     0.74 tokens per second)

llama_perf_context_print:        eval time =   22674.74 ms /   144 runs   (  157.46 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   44340.54 ms /   160 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 450, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 19, 'total_tokens': 91}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 69, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 144, 'total_tokens': 201}}
llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    8414.64 ms /    58 tokens (  145.08 ms per token,     6.89 tokens per second)

llama_perf_context_print:        eval time =    1125.06 ms /     7 runs   (  160.72 ms per token,     6.22 tokens per second)

llama_perf_context_print:       total time =    9547.36 ms /    65 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4963.24 ms /    38 tokens (  130.61 ms per token,     7.66 tokens per second)

llama_perf_context_print:        eval time =    1291.12 ms /     8 runs   (  161.39 ms per token,     6.20 tokens per second)

llama_perf_context_print:       total time =    6262.50 ms /    46 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    5039.21 ms /    38 tokens (  132.61 ms per token,     7.54 tokens per second)

llama_perf_context_print:        eval time =   12052.75 ms /    75 runs   (  160.70 ms per token,     6.22 tokens per second)

llama_perf_context_print:       total time =   17162.13 ms /   113 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4271.14 ms /    33 tokens (  129.43 ms per token,     7.73 tokens per second)

llama_perf_context_print:        eval time =    2723.87 ms /    17 runs   (  160.23 ms per token,     6.24 tokens per second)

llama_perf_context_print:       total time =    7011.35 ms /    50 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    3207.02 ms /    24 tokens (  133.63 ms per token,     7.48 tokens per second)

llama_perf_context_print:        eval time =    1445.77 ms /     9 runs   (  160.64 ms per token,     6.23 tokens per second)

llama_perf_context_print:       total time =    4661.94 ms /    33 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2878.15 ms /    22 tokens (  130.83 ms per token,     7.64 tokens per second)

llama_perf_context_print:        eval time =    6587.62 ms /    41 runs   (  160.67 ms per token,     6.22 tokens per second)

llama_perf_context_print:       total time =    9503.88 ms /    63 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2612.14 ms /    20 tokens (  130.61 ms per token,     7.66 tokens per second)

llama_perf_context_print:        eval time =   53316.07 ms /   335 runs   (  159.15 ms per token,     6.28 tokens per second)

llama_perf_context_print:       total time =   56296.64 ms /   355 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2459.03 ms /    19 tokens (  129.42 ms per token,     7.73 tokens per second)

llama_perf_context_print:        eval time =    6613.32 ms /    42 runs   (  157.46 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =    9111.02 ms /    61 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    3389.84 ms /    26 tokens (  130.38 ms per token,     7.67 tokens per second)

llama_perf_context_print:        eval time =    2368.88 ms /    15 runs   (  157.93 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =    5772.99 ms /    41 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2191.60 ms /    17 tokens (  128.92 ms per token,     7.76 tokens per second)

llama_perf_context_print:        eval time =   21147.31 ms /   134 runs   (  157.82 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   23468.47 ms /   151 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    7163.56 ms /    56 tokens (  127.92 ms per token,     7.82 tokens per second)

llama_perf_context_print:        eval time =   11695.40 ms /    74 runs   (  158.05 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   18927.83 ms /   130 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 8, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 75, 'total_tokens': 153}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 17, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 9, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 41, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 335, 'total_tokens': 396}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 42, 'total_tokens': 102}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 15, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 134, 'total_tokens': 191}}
llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    1831.71 ms /    14 tokens (  130.84 ms per token,     7.64 tokens per second)

llama_perf_context_print:        eval time =    1584.71 ms /    10 runs   (  158.47 ms per token,     6.31 tokens per second)

llama_perf_context_print:       total time =    3426.27 ms /    24 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    5344.67 ms /    42 tokens (  127.25 ms per token,     7.86 tokens per second)

llama_perf_context_print:        eval time =   22457.67 ms /   142 runs   (  158.15 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   27941.83 ms /   184 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    3747.07 ms /    29 tokens (  129.21 ms per token,     7.74 tokens per second)

llama_perf_context_print:        eval time =   62059.54 ms /   391 runs   (  158.72 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =   66246.62 ms /   420 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2184.73 ms /    17 tokens (  128.51 ms per token,     7.78 tokens per second)

llama_perf_context_print:        eval time =    1571.36 ms /    10 runs   (  157.14 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    3765.87 ms /    27 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4485.82 ms /    35 tokens (  128.17 ms per token,     7.80 tokens per second)

llama_perf_context_print:        eval time =   15160.62 ms /    96 runs   (  157.92 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   19737.73 ms /   131 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2491.07 ms /    19 tokens (  131.11 ms per token,     7.63 tokens per second)

llama_perf_context_print:        eval time =   71666.64 ms /   451 runs   (  158.91 ms per token,     6.29 tokens per second)

llama_perf_context_print:       total time =   74685.28 ms /   470 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 74, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 142, 'total_tokens': 225}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 391, 'total_tokens': 461}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 10, 'total_tokens': 68}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 96, 'total_tokens': 172}}
llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    3568.76 ms /    28 tokens (  127.46 ms per token,     7.85 tokens per second)

llama_perf_context_print:        eval time =    5675.22 ms /    36 runs   (  157.64 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =    9277.04 ms /    64 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    3053.85 ms /    24 tokens (  127.24 ms per token,     7.86 tokens per second)

llama_perf_context_print:        eval time =   11184.88 ms /    71 runs   (  157.53 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   14304.54 ms /    95 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4504.91 ms /    35 tokens (  128.71 ms per token,     7.77 tokens per second)

llama_perf_context_print:        eval time =   25107.45 ms /   159 runs   (  157.91 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   29768.21 ms /   194 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4747.81 ms /    37 tokens (  128.32 ms per token,     7.79 tokens per second)

llama_perf_context_print:        eval time =    5995.32 ms /    38 runs   (  157.77 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   10778.12 ms /    75 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2739.06 ms /    21 tokens (  130.43 ms per token,     7.67 tokens per second)

llama_perf_context_print:        eval time =   71370.59 ms /   449 runs   (  158.95 ms per token,     6.29 tokens per second)

llama_perf_context_print:       total time =   74625.98 ms /   470 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 452, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 36, 'total_tokens': 105}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 71, 'total_tokens': 136}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 159, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 38, 'total_tokens': 116}}
llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    4114.86 ms /    32 tokens (  128.59 ms per token,     7.78 tokens per second)

llama_perf_context_print:        eval time =    2991.17 ms /    19 runs   (  157.43 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =    7123.70 ms /    51 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2768.30 ms /    21 tokens (  131.82 ms per token,     7.59 tokens per second)

llama_perf_context_print:        eval time =   11085.23 ms /    69 runs   (  160.66 ms per token,     6.22 tokens per second)

llama_perf_context_print:       total time =   13917.64 ms /    90 tokens

llama_perf_context_print:        load time =    8414.77 ms

llama_perf_context_print: prompt eval time =    2129.93 ms /    16 tokens (  133.12 ms per token,     7.51 tokens per second)

llama_perf_context_print:        eval time =   22783.17 ms /   144 runs   (  158.22 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   25052.61 ms /   160 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 450, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 19, 'total_tokens': 91}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 69, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 144, 'total_tokens': 201}}
