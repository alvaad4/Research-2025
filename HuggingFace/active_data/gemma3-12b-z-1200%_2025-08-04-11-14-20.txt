llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =     892.71 ms /    17 tokens (   52.51 ms per token,    19.04 tokens per second)

llama_perf_context_print:        eval time =    9084.30 ms /    36 runs   (  252.34 ms per token,     3.96 tokens per second)

llama_perf_context_print:       total time =   10047.13 ms /    53 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1125.68 ms /    20 tokens (   56.28 ms per token,    17.77 tokens per second)

llama_perf_context_print:        eval time =   31331.49 ms /   124 runs   (  252.67 ms per token,     3.96 tokens per second)

llama_perf_context_print:       total time =   32690.82 ms /   144 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1121.01 ms /    20 tokens (   56.05 ms per token,    17.84 tokens per second)

llama_perf_context_print:        eval time =   56801.73 ms /   223 runs   (  254.72 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   58362.38 ms /   243 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1648.92 ms /    26 tokens (   63.42 ms per token,    15.77 tokens per second)

llama_perf_context_print:        eval time =    8175.98 ms /    32 runs   (  255.50 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =    9884.08 ms /    58 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =     896.21 ms /    16 tokens (   56.01 ms per token,    17.85 tokens per second)

llama_perf_context_print:        eval time =   29077.64 ms /   114 runs   (  255.07 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   30188.42 ms /   130 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 36, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 124, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 223, 'total_tokens': 247}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 32, 'total_tokens': 62}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1114.75 ms /    14 tokens (   79.63 ms per token,    12.56 tokens per second)

llama_perf_context_print:        eval time =   28203.57 ms /   111 runs   (  254.09 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   29530.52 ms /   125 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1026.19 ms /    17 tokens (   60.36 ms per token,    16.57 tokens per second)

llama_perf_context_print:        eval time =    5647.11 ms /    22 runs   (  256.69 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =    6714.67 ms /    39 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1108.12 ms /    14 tokens (   79.15 ms per token,    12.63 tokens per second)

llama_perf_context_print:        eval time =    6098.34 ms /    24 runs   (  254.10 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    7255.19 ms /    38 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1375.37 ms /    24 tokens (   57.31 ms per token,    17.45 tokens per second)

llama_perf_context_print:        eval time =   27714.50 ms /   109 runs   (  254.26 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   29299.13 ms /   133 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1121.99 ms /    20 tokens (   56.10 ms per token,    17.83 tokens per second)

llama_perf_context_print:        eval time =   31092.27 ms /   122 runs   (  254.85 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   32444.63 ms /   142 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4987.48 ms /    93 tokens (   53.63 ms per token,    18.65 tokens per second)

llama_perf_context_print:        eval time =    6867.48 ms /    27 runs   (  254.35 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   11905.77 ms /   120 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 114, 'total_tokens': 134}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 111, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 22, 'total_tokens': 43}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 24, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 109, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 122, 'total_tokens': 146}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 27, 'total_tokens': 124}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2189.05 ms /    38 tokens (   57.61 ms per token,    17.36 tokens per second)

llama_perf_context_print:        eval time =    2801.67 ms /    11 runs   (  254.70 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =    5012.02 ms /    49 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2811.30 ms /    47 tokens (   59.81 ms per token,    16.72 tokens per second)

llama_perf_context_print:        eval time =     253.63 ms /     1 runs   (  253.63 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    3068.61 ms /    48 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3141.59 ms /    55 tokens (   57.12 ms per token,    17.51 tokens per second)

llama_perf_context_print:        eval time =    1539.26 ms /     6 runs   (  256.54 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =    4693.34 ms /    61 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1503.00 ms /    25 tokens (   60.12 ms per token,    16.63 tokens per second)

llama_perf_context_print:        eval time =   18940.31 ms /    75 runs   (  252.54 ms per token,     3.96 tokens per second)

llama_perf_context_print:       total time =   20586.01 ms /   100 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1549.34 ms /    23 tokens (   67.36 ms per token,    14.84 tokens per second)

llama_perf_context_print:        eval time =    1522.59 ms /     6 runs   (  253.76 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    3084.52 ms /    29 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2785.64 ms /    50 tokens (   55.71 ms per token,    17.95 tokens per second)

llama_perf_context_print:        eval time =    1789.95 ms /     7 runs   (  255.71 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =    4589.82 ms /    57 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2970.81 ms /    56 tokens (   53.05 ms per token,    18.85 tokens per second)

llama_perf_context_print:        eval time =    2561.21 ms /    10 runs   (  256.12 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =    5551.70 ms /    66 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3552.38 ms /    68 tokens (   52.24 ms per token,    19.14 tokens per second)

llama_perf_context_print:        eval time =    2055.59 ms /     8 runs   (  256.95 ms per token,     3.89 tokens per second)

llama_perf_context_print:       total time =    5624.23 ms /    76 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    5416.10 ms /   102 tokens (   53.10 ms per token,    18.83 tokens per second)

llama_perf_context_print:        eval time =    4890.71 ms /    19 runs   (  257.41 ms per token,     3.88 tokens per second)

llama_perf_context_print:       total time =   10342.46 ms /   121 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2859.92 ms /    53 tokens (   53.96 ms per token,    18.53 tokens per second)

llama_perf_context_print:        eval time =   50286.50 ms /   197 runs   (  255.26 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   53535.58 ms /   250 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 11, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 1, 'total_tokens': 52}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 75, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 6, 'total_tokens': 33}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 7, 'total_tokens': 61}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 10, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 8, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 19, 'total_tokens': 125}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3004.77 ms /    54 tokens (   55.64 ms per token,    17.97 tokens per second)

llama_perf_context_print:        eval time =   42094.00 ms /   165 runs   (  255.12 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   45418.54 ms /   219 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1963.18 ms /    34 tokens (   57.74 ms per token,    17.32 tokens per second)

llama_perf_context_print:        eval time =   33577.12 ms /   132 runs   (  254.37 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   35790.27 ms /   166 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2825.31 ms /    47 tokens (   60.11 ms per token,    16.64 tokens per second)

llama_perf_context_print:        eval time =   87401.74 ms /   341 runs   (  256.31 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =   90931.65 ms /   388 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4189.81 ms /    75 tokens (   55.86 ms per token,    17.90 tokens per second)

llama_perf_context_print:        eval time =   97040.28 ms /   377 runs   (  257.40 ms per token,     3.88 tokens per second)

llama_perf_context_print:       total time =  102019.28 ms /   452 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 197, 'total_tokens': 254}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 165, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 132, 'total_tokens': 170}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 341, 'total_tokens': 392}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2580.16 ms /    45 tokens (   57.34 ms per token,    17.44 tokens per second)

llama_perf_context_print:        eval time =   30900.33 ms /   122 runs   (  253.28 ms per token,     3.95 tokens per second)

llama_perf_context_print:       total time =   33709.98 ms /   167 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2023.33 ms /    31 tokens (   65.27 ms per token,    15.32 tokens per second)

llama_perf_context_print:        eval time =   32278.58 ms /   127 runs   (  254.16 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   34541.83 ms /   158 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2465.69 ms /    44 tokens (   56.04 ms per token,    17.84 tokens per second)

llama_perf_context_print:        eval time =   34377.20 ms /   135 runs   (  254.65 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   37098.22 ms /   179 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2086.91 ms /    35 tokens (   59.63 ms per token,    16.77 tokens per second)

llama_perf_context_print:        eval time =   66118.18 ms /   259 runs   (  255.28 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   68727.78 ms /   294 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 377, 'total_tokens': 456}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 122, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 127, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 135, 'total_tokens': 183}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1752.38 ms /    29 tokens (   60.43 ms per token,    16.55 tokens per second)

llama_perf_context_print:        eval time =   86155.28 ms /   332 runs   (  259.50 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   88595.10 ms /   361 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1412.50 ms /    22 tokens (   64.20 ms per token,    15.58 tokens per second)

llama_perf_context_print:        eval time =    5223.45 ms /    21 runs   (  248.74 ms per token,     4.02 tokens per second)

llama_perf_context_print:       total time =    6675.91 ms /    43 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1776.16 ms /    29 tokens (   61.25 ms per token,    16.33 tokens per second)

llama_perf_context_print:        eval time =  120766.47 ms /   467 runs   (  258.60 ms per token,     3.87 tokens per second)

llama_perf_context_print:       total time =  123577.48 ms /   496 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2122.99 ms /    35 tokens (   60.66 ms per token,    16.49 tokens per second)

llama_perf_context_print:        eval time =   32545.04 ms /   128 runs   (  254.26 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   34916.79 ms /   163 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 259, 'total_tokens': 298}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 332, 'total_tokens': 365}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 21, 'total_tokens': 48}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 467, 'total_tokens': 500}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1355.05 ms /    19 tokens (   71.32 ms per token,    14.02 tokens per second)

llama_perf_context_print:        eval time =   51156.44 ms /   200 runs   (  255.78 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   52908.74 ms /   219 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1270.92 ms /    15 tokens (   84.73 ms per token,    11.80 tokens per second)

llama_perf_context_print:        eval time =   42840.68 ms /   168 runs   (  255.00 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   44443.66 ms /   183 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1039.68 ms /    17 tokens (   61.16 ms per token,    16.35 tokens per second)

llama_perf_context_print:        eval time =  263145.97 ms /   999 runs   (  263.41 ms per token,     3.80 tokens per second)

llama_perf_context_print:       total time =  266904.63 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 128, 'total_tokens': 167}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 200, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 168, 'total_tokens': 187}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =     891.75 ms /    16 tokens (   55.73 ms per token,    17.94 tokens per second)

llama_perf_context_print:        eval time =    7815.35 ms /    31 runs   (  252.11 ms per token,     3.97 tokens per second)

llama_perf_context_print:       total time =    8765.62 ms /    47 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1419.34 ms /    22 tokens (   64.52 ms per token,    15.50 tokens per second)

llama_perf_context_print:        eval time =    5813.62 ms /    23 runs   (  252.77 ms per token,     3.96 tokens per second)

llama_perf_context_print:       total time =    7276.76 ms /    45 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1048.48 ms /    17 tokens (   61.68 ms per token,    16.21 tokens per second)

llama_perf_context_print:        eval time =  262979.80 ms /   999 runs   (  263.24 ms per token,     3.80 tokens per second)

llama_perf_context_print:       total time =  266738.50 ms /  1016 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 23, 'total_tokens': 49}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2191.32 ms /    37 tokens (   59.22 ms per token,    16.88 tokens per second)

llama_perf_context_print:        eval time =   21107.39 ms /    83 runs   (  254.31 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   23454.12 ms /   120 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4836.64 ms /    90 tokens (   53.74 ms per token,    18.61 tokens per second)

llama_perf_context_print:        eval time =    8410.17 ms /    33 runs   (  254.85 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   13307.99 ms /   123 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    5937.24 ms /   114 tokens (   52.08 ms per token,    19.20 tokens per second)

llama_perf_context_print:        eval time =   19608.69 ms /    77 runs   (  254.66 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   25690.13 ms /   191 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 83, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 33, 'total_tokens': 127}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    6870.03 ms /   131 tokens (   52.44 ms per token,    19.07 tokens per second)

llama_perf_context_print:        eval time =   11216.06 ms /    44 runs   (  254.91 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   18167.78 ms /   175 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    6358.04 ms /   119 tokens (   53.43 ms per token,    18.72 tokens per second)

llama_perf_context_print:        eval time =   22756.83 ms /    89 runs   (  255.69 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   29285.12 ms /   208 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4066.99 ms /    76 tokens (   53.51 ms per token,    18.69 tokens per second)

llama_perf_context_print:        eval time =    4320.77 ms /    17 runs   (  254.16 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =    8420.21 ms /    93 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    6840.11 ms /   127 tokens (   53.86 ms per token,    18.57 tokens per second)

llama_perf_context_print:        eval time =   40839.46 ms /   160 runs   (  255.25 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   47990.42 ms /   287 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 77, 'total_tokens': 195}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 44, 'total_tokens': 179}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 89, 'total_tokens': 212}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 17, 'total_tokens': 97}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    5410.17 ms /   104 tokens (   52.02 ms per token,    19.22 tokens per second)

llama_perf_context_print:        eval time =   17893.46 ms /    70 runs   (  255.62 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   23435.56 ms /   174 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1393.06 ms /    24 tokens (   58.04 ms per token,    17.23 tokens per second)

llama_perf_context_print:        eval time =   25016.96 ms /    98 runs   (  255.28 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   26596.94 ms /   122 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3640.95 ms /    66 tokens (   55.17 ms per token,    18.13 tokens per second)

llama_perf_context_print:        eval time =   17144.63 ms /    67 runs   (  255.89 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   20911.57 ms /   133 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1351.84 ms /    19 tokens (   71.15 ms per token,    14.05 tokens per second)

llama_perf_context_print:        eval time =   10633.39 ms /    42 runs   (  253.18 ms per token,     3.95 tokens per second)

llama_perf_context_print:       total time =   12064.08 ms /    61 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2366.09 ms /    41 tokens (   57.71 ms per token,    17.33 tokens per second)

llama_perf_context_print:        eval time =    9188.56 ms /    36 runs   (  255.24 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   11622.14 ms /    77 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3436.81 ms /    59 tokens (   58.25 ms per token,    17.17 tokens per second)

llama_perf_context_print:        eval time =   12460.29 ms /    49 runs   (  254.29 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   15988.64 ms /   108 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 160, 'total_tokens': 291}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 70, 'total_tokens': 178}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 98, 'total_tokens': 126}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 67, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 42, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 36, 'total_tokens': 81}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3190.52 ms /    55 tokens (   58.01 ms per token,    17.24 tokens per second)

llama_perf_context_print:        eval time =   10715.00 ms /    42 runs   (  255.12 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   13984.25 ms /    97 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4370.23 ms /    78 tokens (   56.03 ms per token,    17.85 tokens per second)

llama_perf_context_print:        eval time =   16837.60 ms /    66 runs   (  255.12 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   21332.14 ms /   144 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3644.54 ms /    66 tokens (   55.22 ms per token,    18.11 tokens per second)

llama_perf_context_print:        eval time =   23465.31 ms /    92 runs   (  255.06 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   27287.68 ms /   158 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3282.11 ms /    60 tokens (   54.70 ms per token,    18.28 tokens per second)

llama_perf_context_print:        eval time =   15064.71 ms /    59 runs   (  255.33 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   18458.15 ms /   119 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3197.26 ms /    55 tokens (   58.13 ms per token,    17.20 tokens per second)

llama_perf_context_print:        eval time =   15365.72 ms /    60 runs   (  256.10 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =   18675.89 ms /   115 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3039.89 ms /    56 tokens (   54.28 ms per token,    18.42 tokens per second)

llama_perf_context_print:        eval time =   12024.24 ms /    47 runs   (  255.83 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   15152.25 ms /   103 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 49, 'total_tokens': 112}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 42, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 66, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 92, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 59, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 60, 'total_tokens': 119}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2759.22 ms /    46 tokens (   59.98 ms per token,    16.67 tokens per second)

llama_perf_context_print:        eval time =   10128.90 ms /    40 runs   (  253.22 ms per token,     3.95 tokens per second)

llama_perf_context_print:       total time =   12962.48 ms /    86 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3547.23 ms /    68 tokens (   52.17 ms per token,    19.17 tokens per second)

llama_perf_context_print:        eval time =   12692.02 ms /    50 runs   (  253.84 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   16331.98 ms /   118 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1106.11 ms /    14 tokens (   79.01 ms per token,    12.66 tokens per second)

llama_perf_context_print:        eval time =   31724.46 ms /   125 runs   (  253.80 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   33067.45 ms /   139 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3365.19 ms /    59 tokens (   57.04 ms per token,    17.53 tokens per second)

llama_perf_context_print:        eval time =    6094.93 ms /    24 runs   (  253.96 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    9505.11 ms /    83 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =     866.62 ms /    16 tokens (   54.16 ms per token,    18.46 tokens per second)

llama_perf_context_print:        eval time =    5576.88 ms /    22 runs   (  253.49 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    6484.77 ms /    38 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2822.20 ms /    47 tokens (   60.05 ms per token,    16.65 tokens per second)

llama_perf_context_print:        eval time =    7146.16 ms /    28 runs   (  255.22 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   10020.70 ms /    75 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1125.77 ms /    20 tokens (   56.29 ms per token,    17.77 tokens per second)

llama_perf_context_print:        eval time =  263207.49 ms /   999 runs   (  263.47 ms per token,     3.80 tokens per second)

llama_perf_context_print:       total time =  267054.75 ms /  1019 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 47, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 40, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 50, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 125, 'total_tokens': 143}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 24, 'total_tokens': 87}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 22, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 28, 'total_tokens': 79}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2678.94 ms /    49 tokens (   54.67 ms per token,    18.29 tokens per second)

llama_perf_context_print:        eval time =    5120.59 ms /    20 runs   (  256.03 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =    7837.99 ms /    69 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =     897.07 ms /    16 tokens (   56.07 ms per token,    17.84 tokens per second)

llama_perf_context_print:        eval time =   10921.80 ms /    43 runs   (  254.00 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   11899.32 ms /    59 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4238.68 ms /    75 tokens (   56.52 ms per token,    17.69 tokens per second)

llama_perf_context_print:        eval time =    5917.24 ms /    23 runs   (  257.27 ms per token,     3.89 tokens per second)

llama_perf_context_print:       total time =   10199.50 ms /    98 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1144.63 ms /    20 tokens (   57.23 ms per token,    17.47 tokens per second)

llama_perf_context_print:        eval time =   76719.22 ms /   299 runs   (  256.59 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =   78481.63 ms /   319 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 1000, 'total_tokens': 1024}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 20, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 43, 'total_tokens': 63}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 23, 'total_tokens': 102}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3662.73 ms /    63 tokens (   58.14 ms per token,    17.20 tokens per second)

llama_perf_context_print:        eval time =    4570.23 ms /    18 runs   (  253.90 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =    8267.49 ms /    81 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2620.23 ms /    43 tokens (   60.94 ms per token,    16.41 tokens per second)

llama_perf_context_print:        eval time =    8186.62 ms /    32 runs   (  255.83 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   10867.07 ms /    75 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2123.23 ms /    35 tokens (   60.66 ms per token,    16.48 tokens per second)

llama_perf_context_print:        eval time =   20944.10 ms /    82 runs   (  255.42 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   23222.92 ms /   117 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2379.09 ms /    39 tokens (   61.00 ms per token,    16.39 tokens per second)

llama_perf_context_print:        eval time =   41212.56 ms /   162 runs   (  254.40 ms per token,     3.93 tokens per second)

llama_perf_context_print:       total time =   43907.32 ms /   201 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 299, 'total_tokens': 323}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 18, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 32, 'total_tokens': 79}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 82, 'total_tokens': 121}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2265.28 ms /    40 tokens (   56.63 ms per token,    17.66 tokens per second)

llama_perf_context_print:        eval time =   70745.15 ms /   276 runs   (  256.32 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =   73575.93 ms /   316 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3021.23 ms /    56 tokens (   53.95 ms per token,    18.54 tokens per second)

llama_perf_context_print:        eval time =   11665.15 ms /    46 runs   (  253.59 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   14772.39 ms /   102 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2472.71 ms /    44 tokens (   56.20 ms per token,    17.79 tokens per second)

llama_perf_context_print:        eval time =   11239.66 ms /    44 runs   (  255.45 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   13794.84 ms /    88 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2344.60 ms /    41 tokens (   57.19 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =   20071.01 ms /    79 runs   (  254.06 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   22570.45 ms /   120 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 162, 'total_tokens': 205}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 276, 'total_tokens': 320}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 46, 'total_tokens': 106}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 44, 'total_tokens': 92}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2467.92 ms /    44 tokens (   56.09 ms per token,    17.83 tokens per second)

llama_perf_context_print:        eval time =    9398.64 ms /    37 runs   (  254.02 ms per token,     3.94 tokens per second)

llama_perf_context_print:       total time =   11936.06 ms /    81 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2585.20 ms /    45 tokens (   57.45 ms per token,    17.41 tokens per second)

llama_perf_context_print:        eval time =   12530.90 ms /    49 runs   (  255.73 ms per token,     3.91 tokens per second)

llama_perf_context_print:       total time =   15207.83 ms /    94 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2258.88 ms /    38 tokens (   59.44 ms per token,    16.82 tokens per second)

llama_perf_context_print:        eval time =    8415.81 ms /    33 runs   (  255.02 ms per token,     3.92 tokens per second)

llama_perf_context_print:       total time =   10736.80 ms /    71 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3419.33 ms /    61 tokens (   56.05 ms per token,    17.84 tokens per second)

llama_perf_context_print:        eval time =  177979.02 ms /   681 runs   (  261.35 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =  183054.81 ms /   742 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 79, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 37, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 49, 'total_tokens': 98}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 33, 'total_tokens': 75}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    2522.87 ms /    48 tokens (   52.56 ms per token,    19.03 tokens per second)

llama_perf_context_print:        eval time =   54421.83 ms /   212 runs   (  256.71 ms per token,     3.90 tokens per second)

llama_perf_context_print:       total time =   57366.51 ms /   260 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3194.40 ms /    55 tokens (   58.08 ms per token,    17.22 tokens per second)

llama_perf_context_print:        eval time =   29791.88 ms /   116 runs   (  256.83 ms per token,     3.89 tokens per second)

llama_perf_context_print:       total time =   33208.09 ms /   171 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    4508.57 ms /    79 tokens (   57.07 ms per token,    17.52 tokens per second)

llama_perf_context_print:        eval time =  263835.67 ms /   999 runs   (  264.10 ms per token,     3.79 tokens per second)

llama_perf_context_print:       total time =  271070.47 ms /  1078 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 681, 'total_tokens': 746}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 212, 'total_tokens': 264}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 116, 'total_tokens': 175}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3566.34 ms /    62 tokens (   57.52 ms per token,    17.38 tokens per second)

llama_perf_context_print:        eval time =   52695.76 ms /   205 runs   (  257.05 ms per token,     3.89 tokens per second)

llama_perf_context_print:       total time =   56668.28 ms /   267 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3690.99 ms /    63 tokens (   58.59 ms per token,    17.07 tokens per second)

llama_perf_context_print:        eval time =  126229.45 ms /   488 runs   (  258.67 ms per token,     3.87 tokens per second)

llama_perf_context_print:       total time =  131019.39 ms /   551 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 1000, 'total_tokens': 1083}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 205, 'total_tokens': 271}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3286.76 ms /    60 tokens (   54.78 ms per token,    18.26 tokens per second)

llama_perf_context_print:        eval time =  263683.42 ms /   999 runs   (  263.95 ms per token,     3.79 tokens per second)

llama_perf_context_print:       total time =  269722.02 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 488, 'total_tokens': 556}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    1866.38 ms /    33 tokens (   56.56 ms per token,    17.68 tokens per second)

llama_perf_context_print:        eval time =    1770.21 ms /     7 runs   (  252.89 ms per token,     3.95 tokens per second)

llama_perf_context_print:       total time =    3651.44 ms /    40 tokens

llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    3345.20 ms /    58 tokens (   57.68 ms per token,    17.34 tokens per second)

llama_perf_context_print:        eval time =  169768.93 ms /   654 runs   (  259.59 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =  174660.54 ms /   712 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 7, 'total_tokens': 44}}
llama_perf_context_print:        load time =     892.80 ms

llama_perf_context_print: prompt eval time =    6036.11 ms /   111 tokens (   54.38 ms per token,    18.39 tokens per second)

llama_perf_context_print:        eval time =  174052.79 ms /   645 runs   (  269.85 ms per token,     3.71 tokens per second)

llama_perf_context_print:       total time =  181606.53 ms /   756 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 654, 'total_tokens': 716}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 645, 'total_tokens': 760}}
