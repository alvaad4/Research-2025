llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1052.95 ms /    17 tokens (   61.94 ms per token,    16.15 tokens per second)

llama_perf_context_print:        eval time =   10095.34 ms /    36 runs   (  280.43 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   11235.58 ms /    53 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1204.19 ms /    20 tokens (   60.21 ms per token,    16.61 tokens per second)

llama_perf_context_print:        eval time =   34931.46 ms /   124 runs   (  281.71 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   36375.46 ms /   144 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1213.62 ms /    20 tokens (   60.68 ms per token,    16.48 tokens per second)

llama_perf_context_print:        eval time =   63110.02 ms /   223 runs   (  283.00 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   64773.21 ms /   243 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1762.24 ms /    26 tokens (   67.78 ms per token,    14.75 tokens per second)

llama_perf_context_print:        eval time =    8983.04 ms /    32 runs   (  280.72 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   10803.10 ms /    58 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =     931.86 ms /    16 tokens (   58.24 ms per token,    17.17 tokens per second)

llama_perf_context_print:        eval time =   32105.43 ms /   114 runs   (  281.63 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   33263.07 ms /   130 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 36, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 124, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 223, 'total_tokens': 247}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 32, 'total_tokens': 62}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1185.84 ms /    14 tokens (   84.70 ms per token,    11.81 tokens per second)

llama_perf_context_print:        eval time =   31234.28 ms /   111 runs   (  281.39 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   32632.60 ms /   125 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1089.45 ms /    17 tokens (   64.09 ms per token,    15.60 tokens per second)

llama_perf_context_print:        eval time =    6162.66 ms /    22 runs   (  280.12 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =    7294.39 ms /    39 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1184.85 ms /    14 tokens (   84.63 ms per token,    11.82 tokens per second)

llama_perf_context_print:        eval time =    6734.15 ms /    24 runs   (  280.59 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =    7962.76 ms /    38 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1470.52 ms /    24 tokens (   61.27 ms per token,    16.32 tokens per second)

llama_perf_context_print:        eval time =   30642.51 ms /   109 runs   (  281.12 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   32346.80 ms /   133 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1199.25 ms /    20 tokens (   59.96 ms per token,    16.68 tokens per second)

llama_perf_context_print:        eval time =   34489.10 ms /   122 runs   (  282.70 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   35917.38 ms /   142 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    5467.66 ms /    93 tokens (   58.79 ms per token,    17.01 tokens per second)

llama_perf_context_print:        eval time =    7698.08 ms /    27 runs   (  285.11 ms per token,     3.51 tokens per second)

llama_perf_context_print:       total time =   13217.00 ms /   120 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 114, 'total_tokens': 134}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 111, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 22, 'total_tokens': 43}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 24, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 109, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 122, 'total_tokens': 146}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 27, 'total_tokens': 124}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2333.91 ms /    38 tokens (   61.42 ms per token,    16.28 tokens per second)

llama_perf_context_print:        eval time =    3068.26 ms /    11 runs   (  278.93 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =    5423.41 ms /    49 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2987.30 ms /    47 tokens (   63.56 ms per token,    15.73 tokens per second)

llama_perf_context_print:        eval time =     276.60 ms /     1 runs   (  276.60 ms per token,     3.62 tokens per second)

llama_perf_context_print:       total time =    3267.55 ms /    48 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3321.68 ms /    55 tokens (   60.39 ms per token,    16.56 tokens per second)

llama_perf_context_print:        eval time =    1664.09 ms /     6 runs   (  277.35 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =    5006.45 ms /    61 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1609.41 ms /    25 tokens (   64.38 ms per token,    15.53 tokens per second)

llama_perf_context_print:        eval time =   21093.03 ms /    75 runs   (  281.24 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   22856.02 ms /   100 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1683.26 ms /    23 tokens (   73.19 ms per token,    13.66 tokens per second)

llama_perf_context_print:        eval time =    1707.64 ms /     6 runs   (  284.61 ms per token,     3.51 tokens per second)

llama_perf_context_print:       total time =    3403.55 ms /    29 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3058.38 ms /    50 tokens (   61.17 ms per token,    16.35 tokens per second)

llama_perf_context_print:        eval time =    1982.35 ms /     7 runs   (  283.19 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =    5055.63 ms /    57 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3341.90 ms /    56 tokens (   59.68 ms per token,    16.76 tokens per second)

llama_perf_context_print:        eval time =    2843.98 ms /    10 runs   (  284.40 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =    6206.38 ms /    66 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3971.98 ms /    68 tokens (   58.41 ms per token,    17.12 tokens per second)

llama_perf_context_print:        eval time =    2297.60 ms /     8 runs   (  287.20 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =    6286.35 ms /    76 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    6074.52 ms /   102 tokens (   59.55 ms per token,    16.79 tokens per second)

llama_perf_context_print:        eval time =    5388.74 ms /    19 runs   (  283.62 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   11499.95 ms /   121 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3213.81 ms /    53 tokens (   60.64 ms per token,    16.49 tokens per second)

llama_perf_context_print:        eval time =   55804.32 ms /   197 runs   (  283.27 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   59415.74 ms /   250 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 11, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 1, 'total_tokens': 52}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 75, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 6, 'total_tokens': 33}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 7, 'total_tokens': 61}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 10, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 8, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 19, 'total_tokens': 125}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3180.97 ms /    54 tokens (   58.91 ms per token,    16.98 tokens per second)

llama_perf_context_print:        eval time =   46624.20 ms /   165 runs   (  282.57 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   50124.11 ms /   219 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2086.87 ms /    34 tokens (   61.38 ms per token,    16.29 tokens per second)

llama_perf_context_print:        eval time =   37308.39 ms /   132 runs   (  282.64 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   39688.48 ms /   166 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3006.98 ms /    47 tokens (   63.98 ms per token,    15.63 tokens per second)

llama_perf_context_print:        eval time =   96613.29 ms /   341 runs   (  283.32 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =  100355.84 ms /   388 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    4434.85 ms /    75 tokens (   59.13 ms per token,    16.91 tokens per second)

llama_perf_context_print:        eval time =  107342.95 ms /   377 runs   (  284.73 ms per token,     3.51 tokens per second)

llama_perf_context_print:       total time =  112607.13 ms /   452 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 197, 'total_tokens': 254}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 165, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 132, 'total_tokens': 170}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 341, 'total_tokens': 392}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2769.04 ms /    45 tokens (   61.53 ms per token,    16.25 tokens per second)

llama_perf_context_print:        eval time =   34589.94 ms /   122 runs   (  283.52 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   37624.57 ms /   167 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2228.07 ms /    31 tokens (   71.87 ms per token,    13.91 tokens per second)

llama_perf_context_print:        eval time =   35800.62 ms /   127 runs   (  281.89 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   38298.61 ms /   158 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2684.11 ms /    44 tokens (   61.00 ms per token,    16.39 tokens per second)

llama_perf_context_print:        eval time =   38325.60 ms /   135 runs   (  283.89 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =   41306.87 ms /   179 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2347.76 ms /    35 tokens (   67.08 ms per token,    14.91 tokens per second)

llama_perf_context_print:        eval time =   73281.07 ms /   259 runs   (  282.94 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   76167.65 ms /   294 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 377, 'total_tokens': 456}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 122, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 127, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 135, 'total_tokens': 183}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1870.90 ms /    29 tokens (   64.51 ms per token,    15.50 tokens per second)

llama_perf_context_print:        eval time =   93985.29 ms /   332 runs   (  283.09 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   96551.86 ms /   361 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1516.23 ms /    22 tokens (   68.92 ms per token,    14.51 tokens per second)

llama_perf_context_print:        eval time =    5965.12 ms /    21 runs   (  284.05 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =    7520.09 ms /    43 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1895.82 ms /    29 tokens (   65.37 ms per token,    15.30 tokens per second)

llama_perf_context_print:        eval time =  132849.05 ms /   467 runs   (  284.47 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =  135780.94 ms /   496 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2221.98 ms /    35 tokens (   63.49 ms per token,    15.75 tokens per second)

llama_perf_context_print:        eval time =   36167.13 ms /   128 runs   (  282.56 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   38650.78 ms /   163 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 259, 'total_tokens': 298}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 332, 'total_tokens': 365}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 21, 'total_tokens': 48}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 467, 'total_tokens': 500}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1413.96 ms /    19 tokens (   74.42 ms per token,    13.44 tokens per second)

llama_perf_context_print:        eval time =   56611.91 ms /   200 runs   (  283.06 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   58449.68 ms /   219 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1353.53 ms /    15 tokens (   90.23 ms per token,    11.08 tokens per second)

llama_perf_context_print:        eval time =   47345.10 ms /   168 runs   (  281.82 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   49025.36 ms /   183 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1092.33 ms /    17 tokens (   64.25 ms per token,    15.56 tokens per second)

llama_perf_context_print:        eval time =  289040.84 ms /   999 runs   (  289.33 ms per token,     3.46 tokens per second)

llama_perf_context_print:       total time =  293078.27 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 128, 'total_tokens': 167}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 200, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 168, 'total_tokens': 187}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =     938.26 ms /    16 tokens (   58.64 ms per token,    17.05 tokens per second)

llama_perf_context_print:        eval time =    8728.24 ms /    31 runs   (  281.56 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =    9724.92 ms /    47 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1521.04 ms /    22 tokens (   69.14 ms per token,    14.46 tokens per second)

llama_perf_context_print:        eval time =    6449.29 ms /    23 runs   (  280.40 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =    8013.22 ms /    45 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1109.24 ms /    17 tokens (   65.25 ms per token,    15.33 tokens per second)

llama_perf_context_print:        eval time =  288951.49 ms /   999 runs   (  289.24 ms per token,     3.46 tokens per second)

llama_perf_context_print:       total time =  293023.93 ms /  1016 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 23, 'total_tokens': 49}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2226.07 ms /    37 tokens (   60.16 ms per token,    16.62 tokens per second)

llama_perf_context_print:        eval time =   23494.54 ms /    83 runs   (  283.07 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   25906.88 ms /   120 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    5217.55 ms /    90 tokens (   57.97 ms per token,    17.25 tokens per second)

llama_perf_context_print:        eval time =    9331.75 ms /    33 runs   (  282.78 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   14618.04 ms /   123 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    6429.62 ms /   114 tokens (   56.40 ms per token,    17.73 tokens per second)

llama_perf_context_print:        eval time =   21834.81 ms /    77 runs   (  283.57 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   28422.63 ms /   191 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 83, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 33, 'total_tokens': 127}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    7337.13 ms /   131 tokens (   56.01 ms per token,    17.85 tokens per second)

llama_perf_context_print:        eval time =   12452.88 ms /    44 runs   (  283.02 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   19880.98 ms /   175 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    6828.30 ms /   119 tokens (   57.38 ms per token,    17.43 tokens per second)

llama_perf_context_print:        eval time =   25233.72 ms /    89 runs   (  283.52 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   32251.77 ms /   208 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    4344.50 ms /    76 tokens (   57.16 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =    4767.32 ms /    17 runs   (  280.43 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =    9151.87 ms /    93 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    7359.01 ms /   127 tokens (   57.94 ms per token,    17.26 tokens per second)

llama_perf_context_print:        eval time =   45345.85 ms /   160 runs   (  283.41 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   53026.05 ms /   287 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 77, 'total_tokens': 195}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 44, 'total_tokens': 179}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 89, 'total_tokens': 212}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 17, 'total_tokens': 97}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    5833.48 ms /   104 tokens (   56.09 ms per token,    17.83 tokens per second)

llama_perf_context_print:        eval time =   19859.81 ms /    70 runs   (  283.71 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =   25831.33 ms /   174 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1494.16 ms /    24 tokens (   62.26 ms per token,    16.06 tokens per second)

llama_perf_context_print:        eval time =   27617.74 ms /    98 runs   (  281.81 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   29302.95 ms /   122 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3838.77 ms /    66 tokens (   58.16 ms per token,    17.19 tokens per second)

llama_perf_context_print:        eval time =   18980.92 ms /    67 runs   (  283.30 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   22951.32 ms /   133 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1407.62 ms /    19 tokens (   74.09 ms per token,    13.50 tokens per second)

llama_perf_context_print:        eval time =   11812.97 ms /    42 runs   (  281.26 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   13297.16 ms /    61 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2464.56 ms /    41 tokens (   60.11 ms per token,    16.64 tokens per second)

llama_perf_context_print:        eval time =   10145.10 ms /    36 runs   (  281.81 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   12684.17 ms /    77 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3641.03 ms /    59 tokens (   61.71 ms per token,    16.20 tokens per second)

llama_perf_context_print:        eval time =   13863.82 ms /    49 runs   (  282.94 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   17610.77 ms /   108 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 160, 'total_tokens': 291}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 70, 'total_tokens': 178}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 98, 'total_tokens': 126}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 67, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 42, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 36, 'total_tokens': 81}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3383.27 ms /    55 tokens (   61.51 ms per token,    16.26 tokens per second)

llama_perf_context_print:        eval time =   11785.12 ms /    42 runs   (  280.60 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   15262.26 ms /    97 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    4621.56 ms /    78 tokens (   59.25 ms per token,    16.88 tokens per second)

llama_perf_context_print:        eval time =   18679.42 ms /    66 runs   (  283.02 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   23439.84 ms /   144 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3856.87 ms /    66 tokens (   58.44 ms per token,    17.11 tokens per second)

llama_perf_context_print:        eval time =   25986.72 ms /    92 runs   (  282.46 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   30011.80 ms /   158 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3444.06 ms /    60 tokens (   57.40 ms per token,    17.42 tokens per second)

llama_perf_context_print:        eval time =   16656.74 ms /    59 runs   (  282.32 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   20226.32 ms /   119 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3372.42 ms /    55 tokens (   61.32 ms per token,    16.31 tokens per second)

llama_perf_context_print:        eval time =   16965.44 ms /    60 runs   (  282.76 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   20464.74 ms /   115 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3228.61 ms /    56 tokens (   57.65 ms per token,    17.34 tokens per second)

llama_perf_context_print:        eval time =   13276.55 ms /    47 runs   (  282.48 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   16591.06 ms /   103 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 49, 'total_tokens': 112}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 42, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 66, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 92, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 59, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 60, 'total_tokens': 119}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2905.28 ms /    46 tokens (   63.16 ms per token,    15.83 tokens per second)

llama_perf_context_print:        eval time =   11303.88 ms /    40 runs   (  282.60 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   14282.61 ms /    86 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3829.06 ms /    68 tokens (   56.31 ms per token,    17.76 tokens per second)

llama_perf_context_print:        eval time =   14089.86 ms /    50 runs   (  281.80 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   18018.39 ms /   118 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1175.40 ms /    14 tokens (   83.96 ms per token,    11.91 tokens per second)

llama_perf_context_print:        eval time =   35294.91 ms /   125 runs   (  282.36 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   36704.22 ms /   139 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3588.55 ms /    59 tokens (   60.82 ms per token,    16.44 tokens per second)

llama_perf_context_print:        eval time =    6754.50 ms /    24 runs   (  281.44 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   10395.19 ms /    83 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =     952.19 ms /    16 tokens (   59.51 ms per token,    16.80 tokens per second)

llama_perf_context_print:        eval time =    6171.48 ms /    22 runs   (  280.52 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =    7164.05 ms /    38 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2969.66 ms /    47 tokens (   63.18 ms per token,    15.83 tokens per second)

llama_perf_context_print:        eval time =    7836.45 ms /    28 runs   (  279.87 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   10857.37 ms /    75 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1213.80 ms /    20 tokens (   60.69 ms per token,    16.48 tokens per second)

llama_perf_context_print:        eval time =  289182.67 ms /   999 runs   (  289.47 ms per token,     3.45 tokens per second)

llama_perf_context_print:       total time =  293297.36 ms /  1019 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 47, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 40, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 50, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 125, 'total_tokens': 143}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 24, 'total_tokens': 87}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 22, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 28, 'total_tokens': 79}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2789.90 ms /    49 tokens (   56.94 ms per token,    17.56 tokens per second)

llama_perf_context_print:        eval time =    5624.47 ms /    20 runs   (  281.22 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =    8451.81 ms /    69 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =     944.76 ms /    16 tokens (   59.05 ms per token,    16.94 tokens per second)

llama_perf_context_print:        eval time =   12081.91 ms /    43 runs   (  280.97 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   13114.04 ms /    59 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    4532.41 ms /    75 tokens (   60.43 ms per token,    16.55 tokens per second)

llama_perf_context_print:        eval time =    6502.97 ms /    23 runs   (  282.74 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   11077.62 ms /    98 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    1210.81 ms /    20 tokens (   60.54 ms per token,    16.52 tokens per second)

llama_perf_context_print:        eval time =   84655.24 ms /   299 runs   (  283.13 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   86528.00 ms /   319 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 1000, 'total_tokens': 1024}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 20, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 43, 'total_tokens': 63}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 23, 'total_tokens': 102}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3833.24 ms /    63 tokens (   60.85 ms per token,    16.44 tokens per second)

llama_perf_context_print:        eval time =    5086.36 ms /    18 runs   (  282.58 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =    8952.84 ms /    81 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2739.14 ms /    43 tokens (   63.70 ms per token,    15.70 tokens per second)

llama_perf_context_print:        eval time =    9002.69 ms /    32 runs   (  281.33 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   11800.05 ms /    75 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2225.76 ms /    35 tokens (   63.59 ms per token,    15.72 tokens per second)

llama_perf_context_print:        eval time =   23141.36 ms /    82 runs   (  282.21 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   25516.36 ms /   117 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2469.04 ms /    39 tokens (   63.31 ms per token,    15.80 tokens per second)

llama_perf_context_print:        eval time =   45758.82 ms /   162 runs   (  282.46 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   48558.82 ms /   201 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 299, 'total_tokens': 323}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 18, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 32, 'total_tokens': 79}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 82, 'total_tokens': 121}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2370.63 ms /    40 tokens (   59.27 ms per token,    16.87 tokens per second)

llama_perf_context_print:        eval time =   78201.06 ms /   276 runs   (  283.34 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   81157.09 ms /   316 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3150.93 ms /    56 tokens (   56.27 ms per token,    17.77 tokens per second)

llama_perf_context_print:        eval time =   12956.25 ms /    46 runs   (  281.66 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   16190.88 ms /   102 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2565.49 ms /    44 tokens (   58.31 ms per token,    17.15 tokens per second)

llama_perf_context_print:        eval time =   12373.70 ms /    44 runs   (  281.22 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   15027.36 ms /    88 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2462.54 ms /    41 tokens (   60.06 ms per token,    16.65 tokens per second)

llama_perf_context_print:        eval time =   22259.66 ms /    79 runs   (  281.77 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   24874.59 ms /   120 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 162, 'total_tokens': 205}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 276, 'total_tokens': 320}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 46, 'total_tokens': 106}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 44, 'total_tokens': 92}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2568.83 ms /    44 tokens (   58.38 ms per token,    17.13 tokens per second)

llama_perf_context_print:        eval time =   10371.37 ms /    37 runs   (  280.31 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   13025.83 ms /    81 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2723.39 ms /    45 tokens (   60.52 ms per token,    16.52 tokens per second)

llama_perf_context_print:        eval time =   13859.27 ms /    49 runs   (  282.84 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   16679.75 ms /    94 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2340.33 ms /    38 tokens (   61.59 ms per token,    16.24 tokens per second)

llama_perf_context_print:        eval time =    9296.72 ms /    33 runs   (  281.72 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   11696.92 ms /    71 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3582.01 ms /    61 tokens (   58.72 ms per token,    17.03 tokens per second)

llama_perf_context_print:        eval time =  195568.18 ms /   681 runs   (  287.18 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =  200843.49 ms /   742 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 79, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 37, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 49, 'total_tokens': 98}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 33, 'total_tokens': 75}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2646.90 ms /    48 tokens (   55.14 ms per token,    18.13 tokens per second)

llama_perf_context_print:        eval time =   59854.81 ms /   212 runs   (  282.33 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   62938.53 ms /   260 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3314.85 ms /    55 tokens (   60.27 ms per token,    16.59 tokens per second)

llama_perf_context_print:        eval time =   32688.41 ms /   116 runs   (  281.80 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =   36243.39 ms /   171 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    4680.86 ms /    79 tokens (   59.25 ms per token,    16.88 tokens per second)

llama_perf_context_print:        eval time =  290571.74 ms /   999 runs   (  290.86 ms per token,     3.44 tokens per second)

llama_perf_context_print:       total time =  298101.90 ms /  1078 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 681, 'total_tokens': 746}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 212, 'total_tokens': 264}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 116, 'total_tokens': 175}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3713.02 ms /    62 tokens (   59.89 ms per token,    16.70 tokens per second)

llama_perf_context_print:        eval time =   58108.68 ms /   205 runs   (  283.46 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   62224.28 ms /   267 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3848.57 ms /    63 tokens (   61.09 ms per token,    16.37 tokens per second)

llama_perf_context_print:        eval time =  139061.13 ms /   488 runs   (  284.96 ms per token,     3.51 tokens per second)

llama_perf_context_print:       total time =  144077.70 ms /   551 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 1000, 'total_tokens': 1083}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 205, 'total_tokens': 271}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3401.50 ms /    60 tokens (   56.69 ms per token,    17.64 tokens per second)

llama_perf_context_print:        eval time =  289895.73 ms /   999 runs   (  290.19 ms per token,     3.45 tokens per second)

llama_perf_context_print:       total time =  296174.99 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 488, 'total_tokens': 556}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    2048.63 ms /    33 tokens (   62.08 ms per token,    16.11 tokens per second)

llama_perf_context_print:        eval time =    1962.77 ms /     7 runs   (  280.40 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =    4025.79 ms /    40 tokens

llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    3425.82 ms /    58 tokens (   59.07 ms per token,    16.93 tokens per second)

llama_perf_context_print:        eval time =  187523.04 ms /   654 runs   (  286.73 ms per token,     3.49 tokens per second)

llama_perf_context_print:       total time =  192576.73 ms /   712 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 7, 'total_tokens': 44}}
llama_perf_context_print:        load time =    1053.06 ms

llama_perf_context_print: prompt eval time =    6345.32 ms /   111 tokens (   57.17 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =  185402.48 ms /   645 runs   (  287.45 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =  193353.87 ms /   756 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 654, 'total_tokens': 716}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 645, 'total_tokens': 760}}
