llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6732.28 ms /    55 tokens (  122.41 ms per token,     8.17 tokens per second)

llama_perf_context_print:        eval time =    1122.61 ms /     7 runs   (  160.37 ms per token,     6.24 tokens per second)

llama_perf_context_print:       total time =    7862.73 ms /    62 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2741.37 ms /    21 tokens (  130.54 ms per token,     7.66 tokens per second)

llama_perf_context_print:        eval time =    9765.41 ms /    61 runs   (  160.09 ms per token,     6.25 tokens per second)

llama_perf_context_print:       total time =   12564.57 ms /    82 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2731.94 ms /    21 tokens (  130.09 ms per token,     7.69 tokens per second)

llama_perf_context_print:        eval time =    1756.33 ms /    11 runs   (  159.67 ms per token,     6.26 tokens per second)

llama_perf_context_print:       total time =    4499.19 ms /    32 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3627.14 ms /    28 tokens (  129.54 ms per token,     7.72 tokens per second)

llama_perf_context_print:        eval time =    5119.69 ms /    32 runs   (  159.99 ms per token,     6.25 tokens per second)

llama_perf_context_print:       total time =    8777.23 ms /    60 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    1840.77 ms /    14 tokens (  131.48 ms per token,     7.61 tokens per second)

llama_perf_context_print:        eval time =   19547.66 ms /   122 runs   (  160.23 ms per token,     6.24 tokens per second)

llama_perf_context_print:       total time =   21507.98 ms /   136 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2101.73 ms /    16 tokens (  131.36 ms per token,     7.61 tokens per second)

llama_perf_context_print:        eval time =    5751.92 ms /    36 runs   (  159.78 ms per token,     6.26 tokens per second)

llama_perf_context_print:       total time =    7887.68 ms /    52 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2213.11 ms /    17 tokens (  130.18 ms per token,     7.68 tokens per second)

llama_perf_context_print:        eval time =    4792.29 ms /    30 runs   (  159.74 ms per token,     6.26 tokens per second)

llama_perf_context_print:       total time =    7033.97 ms /    47 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    1976.78 ms /    15 tokens (  131.79 ms per token,     7.59 tokens per second)

llama_perf_context_print:        eval time =    1276.53 ms /     8 runs   (  159.57 ms per token,     6.27 tokens per second)

llama_perf_context_print:       total time =    3261.56 ms /    23 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 7, 'total_tokens': 62}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 61, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 11, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 32, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 122, 'total_tokens': 177}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 36, 'total_tokens': 93}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 30, 'total_tokens': 88}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3485.53 ms /    27 tokens (  129.09 ms per token,     7.75 tokens per second)

llama_perf_context_print:        eval time =    2078.30 ms /    13 runs   (  159.87 ms per token,     6.26 tokens per second)

llama_perf_context_print:       total time =    5576.92 ms /    40 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2726.95 ms /    21 tokens (  129.85 ms per token,     7.70 tokens per second)

llama_perf_context_print:        eval time =   15633.54 ms /    99 runs   (  157.91 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   18455.69 ms /   120 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   11320.11 ms /    90 tokens (  125.78 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   49488.04 ms /   311 runs   (  159.13 ms per token,     6.28 tokens per second)

llama_perf_context_print:       total time =   61144.56 ms /   401 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5039.70 ms /    40 tokens (  125.99 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   19231.39 ms /   122 runs   (  157.63 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   24389.19 ms /   162 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6425.72 ms /    51 tokens (  125.99 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   56082.05 ms /   354 runs   (  158.42 ms per token,     6.31 tokens per second)

llama_perf_context_print:       total time =   62902.70 ms /   405 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 8, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 13, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 99, 'total_tokens': 161}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 311, 'total_tokens': 442}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 122, 'total_tokens': 203}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7307.90 ms /    58 tokens (  126.00 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   30500.35 ms /   193 runs   (  158.03 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   38003.17 ms /   251 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3664.29 ms /    29 tokens (  126.35 ms per token,     7.91 tokens per second)

llama_perf_context_print:        eval time =   11027.85 ms /    70 runs   (  157.54 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   14758.38 ms /    99 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3041.38 ms /    24 tokens (  126.72 ms per token,     7.89 tokens per second)

llama_perf_context_print:        eval time =   68819.29 ms /   434 runs   (  158.57 ms per token,     6.31 tokens per second)

llama_perf_context_print:       total time =   72368.75 ms /   458 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 354, 'total_tokens': 446}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 193, 'total_tokens': 292}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 70, 'total_tokens': 139}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6446.69 ms /    51 tokens (  126.41 ms per token,     7.91 tokens per second)

llama_perf_context_print:        eval time =   39071.70 ms /   247 runs   (  158.19 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   45775.27 ms /   298 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7305.97 ms /    58 tokens (  125.96 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   24949.68 ms /   158 runs   (  157.91 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   32411.12 ms /   216 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 434, 'total_tokens': 498}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 247, 'total_tokens': 339}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7947.39 ms /    63 tokens (  126.15 ms per token,     7.93 tokens per second)

llama_perf_context_print:        eval time =  119230.78 ms /   746 runs   (  159.83 ms per token,     6.26 tokens per second)

llama_perf_context_print:       total time =  128193.68 ms /   809 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 158, 'total_tokens': 260}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   12810.30 ms /   102 tokens (  125.59 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   18031.15 ms /   114 runs   (  158.17 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   30950.84 ms /   216 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6414.15 ms /    51 tokens (  125.77 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   41606.15 ms /   263 runs   (  158.20 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   48295.42 ms /   314 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 746, 'total_tokens': 853}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 143, 'completion_tokens': 114, 'total_tokens': 257}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6793.50 ms /    54 tokens (  125.81 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   24489.42 ms /   155 runs   (  158.00 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   31436.15 ms /   209 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4286.42 ms /    34 tokens (  126.07 ms per token,     7.93 tokens per second)

llama_perf_context_print:        eval time =   17180.42 ms /   109 runs   (  157.62 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   21570.86 ms /   143 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5667.65 ms /    45 tokens (  125.95 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   36820.71 ms /   233 runs   (  158.03 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   42727.64 ms /   278 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    9425.12 ms /    75 tokens (  125.67 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   62228.74 ms /   392 runs   (  158.75 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =   72096.05 ms /   467 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 91, 'completion_tokens': 263, 'total_tokens': 354}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 155, 'total_tokens': 249}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 109, 'total_tokens': 184}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 233, 'total_tokens': 319}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5287.42 ms /    42 tokens (  125.89 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   21300.08 ms /   135 runs   (  157.78 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   26718.39 ms /   177 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3665.78 ms /    29 tokens (  126.41 ms per token,     7.91 tokens per second)

llama_perf_context_print:        eval time =   28718.32 ms /   182 runs   (  157.79 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   32565.05 ms /   211 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5414.98 ms /    43 tokens (  125.93 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   14664.62 ms /    93 runs   (  157.68 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   20167.44 ms /   136 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 116, 'completion_tokens': 392, 'total_tokens': 508}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 135, 'total_tokens': 218}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 182, 'total_tokens': 252}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4412.02 ms /    35 tokens (  126.06 ms per token,     7.93 tokens per second)

llama_perf_context_print:        eval time =   23033.73 ms /   146 runs   (  157.77 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   27587.91 ms /   181 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3567.25 ms /    28 tokens (  127.40 ms per token,     7.85 tokens per second)

llama_perf_context_print:        eval time =   26182.68 ms /   166 runs   (  157.73 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   29913.31 ms /   194 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2674.85 ms /    21 tokens (  127.37 ms per token,     7.85 tokens per second)

llama_perf_context_print:        eval time =    2355.83 ms /    15 runs   (  157.06 ms per token,     6.37 tokens per second)

llama_perf_context_print:       total time =    5045.03 ms /    36 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3315.43 ms /    26 tokens (  127.52 ms per token,     7.84 tokens per second)

llama_perf_context_print:        eval time =   25540.22 ms /   162 runs   (  157.66 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   29015.08 ms /   188 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4153.60 ms /    33 tokens (  125.87 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   18119.21 ms /   115 runs   (  157.56 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   22382.96 ms /   148 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2558.54 ms /    20 tokens (  127.93 ms per token,     7.82 tokens per second)

llama_perf_context_print:        eval time =     951.74 ms /     6 runs   (  158.62 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =    3516.72 ms /    26 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 93, 'total_tokens': 177}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 146, 'total_tokens': 222}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 166, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 15, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 162, 'total_tokens': 228}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 115, 'total_tokens': 188}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    1936.84 ms /    15 tokens (  129.12 ms per token,     7.74 tokens per second)

llama_perf_context_print:        eval time =   10372.15 ms /    66 runs   (  157.15 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =   12371.02 ms /    81 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2420.96 ms /    19 tokens (  127.42 ms per token,     7.85 tokens per second)

llama_perf_context_print:        eval time =   46787.13 ms /   296 runs   (  158.06 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   49525.32 ms /   315 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    1811.65 ms /    14 tokens (  129.40 ms per token,     7.73 tokens per second)

llama_perf_context_print:        eval time =    1566.87 ms /    10 runs   (  156.69 ms per token,     6.38 tokens per second)

llama_perf_context_print:       total time =    3388.44 ms /    24 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2910.68 ms /    23 tokens (  126.55 ms per token,     7.90 tokens per second)

llama_perf_context_print:        eval time =    3300.72 ms /    21 runs   (  157.18 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    6231.05 ms /    44 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2302.34 ms /    18 tokens (  127.91 ms per token,     7.82 tokens per second)

llama_perf_context_print:        eval time =   72323.81 ms /   456 runs   (  158.60 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =   75158.35 ms /   474 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 6, 'total_tokens': 67}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 66, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 296, 'total_tokens': 356}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 21, 'total_tokens': 85}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4411.00 ms /    35 tokens (  126.03 ms per token,     7.93 tokens per second)

llama_perf_context_print:        eval time =   14831.40 ms /    94 runs   (  157.78 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   19331.30 ms /   129 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   11668.32 ms /    93 tokens (  125.47 ms per token,     7.97 tokens per second)

llama_perf_context_print:        eval time =    5680.47 ms /    36 runs   (  157.79 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   17382.28 ms /   129 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   13940.83 ms /   111 tokens (  125.59 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   12487.42 ms /    79 runs   (  158.07 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   26502.92 ms /   190 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 456, 'total_tokens': 515}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 94, 'total_tokens': 170}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 134, 'completion_tokens': 36, 'total_tokens': 170}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   16701.30 ms /   133 tokens (  125.57 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   13447.72 ms /    85 runs   (  158.21 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   30230.16 ms /   218 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   14705.98 ms /   117 tokens (  125.69 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    4429.18 ms /    28 runs   (  158.18 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   19161.36 ms /   145 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    9552.81 ms /    76 tokens (  125.69 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    3153.08 ms /    20 runs   (  157.65 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   12724.83 ms /    96 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   16680.34 ms /   133 tokens (  125.42 ms per token,     7.97 tokens per second)

llama_perf_context_print:        eval time =   26443.45 ms /   167 runs   (  158.34 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   43290.00 ms /   300 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 152, 'completion_tokens': 79, 'total_tokens': 231}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 85, 'total_tokens': 259}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 158, 'completion_tokens': 28, 'total_tokens': 186}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 20, 'total_tokens': 137}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   12307.90 ms /    98 tokens (  125.59 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   12477.58 ms /    79 runs   (  157.94 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   24859.95 ms /   177 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3426.80 ms /    27 tokens (  126.92 ms per token,     7.88 tokens per second)

llama_perf_context_print:        eval time =   14483.63 ms /    92 runs   (  157.43 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   17997.66 ms /   119 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    8437.31 ms /    67 tokens (  125.93 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    3620.95 ms /    23 runs   (  157.43 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   12079.87 ms /    90 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2795.49 ms /    22 tokens (  127.07 ms per token,     7.87 tokens per second)

llama_perf_context_print:        eval time =    7074.51 ms /    45 runs   (  157.21 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    9911.80 ms /    67 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5399.51 ms /    43 tokens (  125.57 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    9921.13 ms /    63 runs   (  157.48 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   15379.64 ms /   106 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 167, 'total_tokens': 341}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 139, 'completion_tokens': 79, 'total_tokens': 218}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 92, 'total_tokens': 160}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 23, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 45, 'total_tokens': 108}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 63, 'total_tokens': 147}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7433.49 ms /    59 tokens (  125.99 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    5991.23 ms /    38 runs   (  157.66 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   13459.95 ms /    97 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6678.14 ms /    53 tokens (  126.00 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   41133.62 ms /   260 runs   (  158.21 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   48083.96 ms /   313 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    9546.08 ms /    76 tokens (  125.61 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   13896.85 ms /    88 runs   (  157.92 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   23526.32 ms /   164 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    8294.47 ms /    66 tokens (  125.67 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    6935.83 ms /    44 runs   (  157.63 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   15271.21 ms /   110 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7676.06 ms /    61 tokens (  125.84 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =    7407.47 ms /    47 runs   (  157.61 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   15127.39 ms /   108 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 38, 'total_tokens': 138}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 260, 'total_tokens': 354}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 88, 'total_tokens': 205}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 44, 'total_tokens': 151}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6542.28 ms /    52 tokens (  125.81 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   20206.85 ms /   128 runs   (  157.87 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   26873.32 ms /   180 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6921.93 ms /    55 tokens (  125.85 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =    6154.45 ms /    39 runs   (  157.81 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   13112.64 ms /    94 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5654.82 ms /    45 tokens (  125.66 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   39999.99 ms /   253 runs   (  158.10 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   45920.10 ms /   298 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7690.03 ms /    61 tokens (  126.07 ms per token,     7.93 tokens per second)

llama_perf_context_print:        eval time =   50076.15 ms /   316 runs   (  158.47 ms per token,     6.31 tokens per second)

llama_perf_context_print:       total time =   58109.22 ms /   377 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 47, 'total_tokens': 149}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 93, 'completion_tokens': 128, 'total_tokens': 221}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 39, 'total_tokens': 135}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 253, 'total_tokens': 339}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    1945.88 ms /    15 tokens (  129.73 ms per token,     7.71 tokens per second)

llama_perf_context_print:        eval time =    6762.68 ms /    43 runs   (  157.27 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    8748.55 ms /    58 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7445.85 ms /    59 tokens (  126.20 ms per token,     7.92 tokens per second)

llama_perf_context_print:        eval time =   15942.10 ms /   101 runs   (  157.84 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   23484.24 ms /   160 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2178.37 ms /    17 tokens (  128.14 ms per token,     7.80 tokens per second)

llama_perf_context_print:        eval time =    2516.27 ms /    16 runs   (  157.27 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    4709.92 ms /    33 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5910.15 ms /    47 tokens (  125.75 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =    3619.53 ms /    23 runs   (  157.37 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =    9551.24 ms /    70 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2680.09 ms /    21 tokens (  127.62 ms per token,     7.84 tokens per second)

llama_perf_context_print:        eval time =    2515.04 ms /    16 runs   (  157.19 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    5210.38 ms /    37 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6171.06 ms /    49 tokens (  125.94 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    2831.48 ms /    18 runs   (  157.30 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    9019.61 ms /    67 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2166.70 ms /    17 tokens (  127.45 ms per token,     7.85 tokens per second)

llama_perf_context_print:        eval time =    1887.58 ms /    12 runs   (  157.30 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    4065.97 ms /    29 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 316, 'total_tokens': 418}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 43, 'total_tokens': 99}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 101, 'total_tokens': 201}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 16, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 88, 'completion_tokens': 23, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 16, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 18, 'total_tokens': 108}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    8919.52 ms /    71 tokens (  125.63 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    3151.08 ms /    20 runs   (  157.55 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   12089.69 ms /    91 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    2538.97 ms /    20 tokens (  126.95 ms per token,     7.88 tokens per second)

llama_perf_context_print:        eval time =    2671.49 ms /    17 runs   (  157.15 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    5226.68 ms /    37 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7672.16 ms /    61 tokens (  125.77 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =    1899.50 ms /    12 runs   (  158.29 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =    9583.38 ms /    73 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5543.08 ms /    44 tokens (  125.98 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    4089.42 ms /    26 runs   (  157.29 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    9656.97 ms /    70 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4681.85 ms /    37 tokens (  126.54 ms per token,     7.90 tokens per second)

llama_perf_context_print:        eval time =    1413.55 ms /     9 runs   (  157.06 ms per token,     6.37 tokens per second)

llama_perf_context_print:       total time =    6104.43 ms /    46 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5031.56 ms /    40 tokens (  125.79 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   16705.46 ms /   106 runs   (  157.60 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   21838.69 ms /   146 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5408.55 ms /    43 tokens (  125.78 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   23821.88 ms /   151 runs   (  157.76 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   29379.24 ms /   194 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 12, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 20, 'total_tokens': 132}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 101, 'completion_tokens': 12, 'total_tokens': 113}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 26, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 9, 'total_tokens': 87}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 106, 'total_tokens': 187}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6930.97 ms /    55 tokens (  126.02 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    5193.54 ms /    33 runs   (  157.38 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   12155.47 ms /    88 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5400.02 ms /    43 tokens (  125.58 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =    6454.38 ms /    41 runs   (  157.42 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   11892.82 ms /    84 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5415.52 ms /    43 tokens (  125.94 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =    9289.08 ms /    59 runs   (  157.44 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   14760.03 ms /   102 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5656.80 ms /    45 tokens (  125.71 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   10723.62 ms /    68 runs   (  157.70 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   16444.54 ms /   113 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5820.84 ms /    46 tokens (  126.54 ms per token,     7.90 tokens per second)

llama_perf_context_print:        eval time =   10555.65 ms /    67 runs   (  157.55 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   16439.55 ms /   113 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    4671.57 ms /    37 tokens (  126.26 ms per token,     7.92 tokens per second)

llama_perf_context_print:        eval time =   11974.87 ms /    76 runs   (  157.56 ms per token,     6.35 tokens per second)

llama_perf_context_print:       total time =   16718.10 ms /   113 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 151, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 33, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 41, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 59, 'total_tokens': 143}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 68, 'total_tokens': 154}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 67, 'total_tokens': 154}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7169.49 ms /    57 tokens (  125.78 ms per token,     7.95 tokens per second)

llama_perf_context_print:        eval time =   35571.11 ms /   225 runs   (  158.09 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   42972.92 ms /   282 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    5567.41 ms /    44 tokens (  126.53 ms per token,     7.90 tokens per second)

llama_perf_context_print:        eval time =   33952.17 ms /   215 runs   (  157.92 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   39739.23 ms /   259 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6423.29 ms /    51 tokens (  125.95 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   26832.94 ms /   170 runs   (  157.84 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   33425.64 ms /   221 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 76, 'total_tokens': 154}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 225, 'total_tokens': 312}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 74, 'completion_tokens': 215, 'total_tokens': 289}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    9551.40 ms /    76 tokens (  125.68 ms per token,     7.96 tokens per second)

llama_perf_context_print:        eval time =   66212.09 ms /   417 runs   (  158.78 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =   76246.41 ms /   493 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7053.30 ms /    56 tokens (  125.95 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   42534.07 ms /   269 runs   (  158.12 ms per token,     6.32 tokens per second)

llama_perf_context_print:       total time =   49872.70 ms /   325 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 170, 'total_tokens': 251}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 417, 'total_tokens': 523}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7303.32 ms /    58 tokens (  125.92 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   23668.28 ms /   150 runs   (  157.79 ms per token,     6.34 tokens per second)

llama_perf_context_print:       total time =   31119.60 ms /   208 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    7053.74 ms /    56 tokens (  125.96 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   91334.40 ms /   574 runs   (  159.12 ms per token,     6.28 tokens per second)

llama_perf_context_print:       total time =   99110.49 ms /   630 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 269, 'total_tokens': 355}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 89, 'completion_tokens': 150, 'total_tokens': 239}}
llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    3672.94 ms /    29 tokens (  126.65 ms per token,     7.90 tokens per second)

llama_perf_context_print:        eval time =     786.48 ms /     5 runs   (  157.30 ms per token,     6.36 tokens per second)

llama_perf_context_print:       total time =    4464.95 ms /    34 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =    6923.11 ms /    55 tokens (  125.87 ms per token,     7.94 tokens per second)

llama_perf_context_print:        eval time =   37611.16 ms /   238 runs   (  158.03 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =   44782.41 ms /   293 tokens

llama_perf_context_print:        load time =    6732.39 ms

llama_perf_context_print: prompt eval time =   13679.95 ms /   107 tokens (  127.85 ms per token,     7.82 tokens per second)

llama_perf_context_print:        eval time =   10769.14 ms /    67 runs   (  160.73 ms per token,     6.22 tokens per second)

llama_perf_context_print:       total time =   24512.39 ms /   174 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 574, 'total_tokens': 660}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 5, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 238, 'total_tokens': 323}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 137, 'completion_tokens': 67, 'total_tokens': 204}}
