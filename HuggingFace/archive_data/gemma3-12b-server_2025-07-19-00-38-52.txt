llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =     978.74 ms /    17 tokens (   57.57 ms per token,    17.37 tokens per second)

llama_perf_context_print:        eval time =    9302.10 ms /    36 runs   (  258.39 ms per token,     3.87 tokens per second)

llama_perf_context_print:       total time =   10358.67 ms /    53 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1103.26 ms /    20 tokens (   55.16 ms per token,    18.13 tokens per second)

llama_perf_context_print:        eval time =   32125.37 ms /   124 runs   (  259.08 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   33445.76 ms /   144 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1101.95 ms /    20 tokens (   55.10 ms per token,    18.15 tokens per second)

llama_perf_context_print:        eval time =   56406.51 ms /   217 runs   (  259.94 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   57915.48 ms /   237 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1661.15 ms /    26 tokens (   63.89 ms per token,    15.65 tokens per second)

llama_perf_context_print:        eval time =    8293.09 ms /    32 runs   (  259.16 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   10010.38 ms /    58 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =     877.80 ms /    16 tokens (   54.86 ms per token,    18.23 tokens per second)

llama_perf_context_print:        eval time =   29569.07 ms /   114 runs   (  259.38 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   30647.55 ms /   130 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 36, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 124, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 217, 'total_tokens': 241}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 32, 'total_tokens': 62}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1107.78 ms /    14 tokens (   79.13 ms per token,    12.64 tokens per second)

llama_perf_context_print:        eval time =   28797.75 ms /   111 runs   (  259.44 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   30101.15 ms /   125 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1025.82 ms /    17 tokens (   60.34 ms per token,    16.57 tokens per second)

llama_perf_context_print:        eval time =    5696.86 ms /    22 runs   (  258.95 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    6761.62 ms /    39 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1124.46 ms /    14 tokens (   80.32 ms per token,    12.45 tokens per second)

llama_perf_context_print:        eval time =    6210.50 ms /    24 runs   (  258.77 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    7377.32 ms /    38 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1367.84 ms /    24 tokens (   56.99 ms per token,    17.55 tokens per second)

llama_perf_context_print:        eval time =   28314.07 ms /   109 runs   (  259.76 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   29873.92 ms /   133 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1125.14 ms /    20 tokens (   56.26 ms per token,    17.78 tokens per second)

llama_perf_context_print:        eval time =   27508.14 ms /   106 runs   (  259.51 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   28820.18 ms /   126 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    5015.93 ms /    93 tokens (   53.93 ms per token,    18.54 tokens per second)

llama_perf_context_print:        eval time =    7024.94 ms /    27 runs   (  260.18 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   12089.14 ms /   120 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2246.06 ms /    38 tokens (   59.11 ms per token,    16.92 tokens per second)

llama_perf_context_print:        eval time =    2855.64 ms /    11 runs   (  259.60 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =    5122.17 ms /    49 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 114, 'total_tokens': 134}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 111, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 22, 'total_tokens': 43}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 24, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 109, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 106, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 27, 'total_tokens': 124}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2841.62 ms /    47 tokens (   60.46 ms per token,    16.54 tokens per second)

llama_perf_context_print:        eval time =     262.91 ms /     1 runs   (  262.91 ms per token,     3.80 tokens per second)

llama_perf_context_print:       total time =    3108.21 ms /    48 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3154.71 ms /    55 tokens (   57.36 ms per token,    17.43 tokens per second)

llama_perf_context_print:        eval time =    1560.54 ms /     6 runs   (  260.09 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =    4727.35 ms /    61 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1507.77 ms /    25 tokens (   60.31 ms per token,    16.58 tokens per second)

llama_perf_context_print:        eval time =    6993.33 ms /    27 runs   (  259.01 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    8548.81 ms /    52 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1560.17 ms /    23 tokens (   67.83 ms per token,    14.74 tokens per second)

llama_perf_context_print:        eval time =    1554.12 ms /     6 runs   (  259.02 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    3126.44 ms /    29 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2771.98 ms /    50 tokens (   55.44 ms per token,    18.04 tokens per second)

llama_perf_context_print:        eval time =    1564.20 ms /     6 runs   (  260.70 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =    4348.30 ms /    56 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2991.62 ms /    56 tokens (   53.42 ms per token,    18.72 tokens per second)

llama_perf_context_print:        eval time =    2596.09 ms /    10 runs   (  259.61 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =    5606.43 ms /    66 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3580.48 ms /    68 tokens (   52.65 ms per token,    18.99 tokens per second)

llama_perf_context_print:        eval time =    2086.24 ms /     8 runs   (  260.78 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =    5682.12 ms /    76 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    5452.68 ms /   102 tokens (   53.46 ms per token,    18.71 tokens per second)

llama_perf_context_print:        eval time =    4941.99 ms /    19 runs   (  260.10 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   10428.70 ms /   121 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2881.53 ms /    53 tokens (   54.37 ms per token,    18.39 tokens per second)

llama_perf_context_print:        eval time =   51307.47 ms /   197 runs   (  260.44 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   54544.43 ms /   250 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 11, 'total_tokens': 53}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 1, 'total_tokens': 52}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 27, 'total_tokens': 56}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 6, 'total_tokens': 33}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 6, 'total_tokens': 60}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 10, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 8, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 19, 'total_tokens': 125}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3008.73 ms /    54 tokens (   55.72 ms per token,    17.95 tokens per second)

llama_perf_context_print:        eval time =   42948.06 ms /   165 runs   (  260.29 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   46251.29 ms /   219 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1965.38 ms /    34 tokens (   57.81 ms per token,    17.30 tokens per second)

llama_perf_context_print:        eval time =   34303.74 ms /   132 runs   (  259.88 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   36503.62 ms /   166 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2822.55 ms /    47 tokens (   60.05 ms per token,    16.65 tokens per second)

llama_perf_context_print:        eval time =   89409.46 ms /   342 runs   (  261.43 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =   92878.10 ms /   389 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4207.42 ms /    75 tokens (   56.10 ms per token,    17.83 tokens per second)

llama_perf_context_print:        eval time =   97732.94 ms /   373 runs   (  262.02 ms per token,     3.82 tokens per second)

llama_perf_context_print:       total time =  102663.65 ms /   448 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 197, 'total_tokens': 254}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 165, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 132, 'total_tokens': 170}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 342, 'total_tokens': 393}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2572.87 ms /    45 tokens (   57.17 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =   31704.03 ms /   122 runs   (  259.87 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   34492.06 ms /   167 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2038.46 ms /    31 tokens (   65.76 ms per token,    15.21 tokens per second)

llama_perf_context_print:        eval time =   32976.84 ms /   127 runs   (  259.66 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   35240.27 ms /   158 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2437.63 ms /    44 tokens (   55.40 ms per token,    18.05 tokens per second)

llama_perf_context_print:        eval time =   33272.85 ms /   128 runs   (  259.94 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   35936.18 ms /   172 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2112.48 ms /    35 tokens (   60.36 ms per token,    16.57 tokens per second)

llama_perf_context_print:        eval time =   56242.54 ms /   216 runs   (  260.38 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   58746.18 ms /   251 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 373, 'total_tokens': 452}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 122, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 127, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 128, 'total_tokens': 176}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1747.93 ms /    29 tokens (   60.27 ms per token,    16.59 tokens per second)

llama_perf_context_print:        eval time =  100121.19 ms /   383 runs   (  261.41 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =  102601.82 ms /   412 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1416.56 ms /    22 tokens (   64.39 ms per token,    15.53 tokens per second)

llama_perf_context_print:        eval time =    5433.18 ms /    21 runs   (  258.72 ms per token,     3.87 tokens per second)

llama_perf_context_print:       total time =    6886.92 ms /    43 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1771.20 ms /    29 tokens (   61.08 ms per token,    16.37 tokens per second)

llama_perf_context_print:        eval time =  120271.55 ms /   459 runs   (  262.03 ms per token,     3.82 tokens per second)

llama_perf_context_print:       total time =  122939.25 ms /   488 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2105.03 ms /    35 tokens (   60.14 ms per token,    16.63 tokens per second)

llama_perf_context_print:        eval time =   33262.44 ms /   128 runs   (  259.86 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   35593.47 ms /   163 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 216, 'total_tokens': 255}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 383, 'total_tokens': 416}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 21, 'total_tokens': 48}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 459, 'total_tokens': 492}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1313.51 ms /    19 tokens (   69.13 ms per token,    14.47 tokens per second)

llama_perf_context_print:        eval time =   52020.36 ms /   200 runs   (  260.10 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   53695.58 ms /   219 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1266.89 ms /    15 tokens (   84.46 ms per token,    11.84 tokens per second)

llama_perf_context_print:        eval time =   40519.75 ms /   156 runs   (  259.74 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   42065.52 ms /   171 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1033.10 ms /    17 tokens (   60.77 ms per token,    16.46 tokens per second)

llama_perf_context_print:        eval time =  266172.82 ms /   999 runs   (  266.44 ms per token,     3.75 tokens per second)

llama_perf_context_print:       total time =  269518.70 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 128, 'total_tokens': 167}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 200, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 156, 'total_tokens': 175}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =     879.98 ms /    16 tokens (   55.00 ms per token,    18.18 tokens per second)

llama_perf_context_print:        eval time =    8031.27 ms /    31 runs   (  259.07 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    8965.57 ms /    47 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1409.09 ms /    22 tokens (   64.05 ms per token,    15.61 tokens per second)

llama_perf_context_print:        eval time =    5956.29 ms /    23 runs   (  258.97 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    7406.17 ms /    45 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1028.07 ms /    17 tokens (   60.47 ms per token,    16.54 tokens per second)

llama_perf_context_print:        eval time =  266180.24 ms /   999 runs   (  266.45 ms per token,     3.75 tokens per second)

llama_perf_context_print:       total time =  269526.29 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 23, 'total_tokens': 49}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2071.45 ms /    37 tokens (   55.99 ms per token,    17.86 tokens per second)

llama_perf_context_print:        eval time =   21539.73 ms /    83 runs   (  259.51 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   23756.32 ms /   120 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4863.61 ms /    90 tokens (   54.04 ms per token,    18.50 tokens per second)

llama_perf_context_print:        eval time =    8585.09 ms /    33 runs   (  260.15 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   13506.60 ms /   123 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    6009.26 ms /   114 tokens (   52.71 ms per token,    18.97 tokens per second)

llama_perf_context_print:        eval time =   20058.61 ms /    77 runs   (  260.50 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   26203.37 ms /   191 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 83, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 33, 'total_tokens': 127}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    6967.70 ms /   131 tokens (   53.19 ms per token,    18.80 tokens per second)

llama_perf_context_print:        eval time =   11471.78 ms /    44 runs   (  260.72 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   18516.64 ms /   175 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    6378.67 ms /   119 tokens (   53.60 ms per token,    18.66 tokens per second)

llama_perf_context_print:        eval time =   24768.55 ms /    95 runs   (  260.72 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   31314.29 ms /   214 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4047.54 ms /    76 tokens (   53.26 ms per token,    18.78 tokens per second)

llama_perf_context_print:        eval time =    4672.52 ms /    18 runs   (  259.58 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =    8752.41 ms /    94 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    6899.27 ms /   127 tokens (   54.32 ms per token,    18.41 tokens per second)

llama_perf_context_print:        eval time =   41791.52 ms /   160 runs   (  261.20 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =   48978.85 ms /   287 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 77, 'total_tokens': 195}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 44, 'total_tokens': 179}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 95, 'total_tokens': 218}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 18, 'total_tokens': 98}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    5443.12 ms /   104 tokens (   52.34 ms per token,    19.11 tokens per second)

llama_perf_context_print:        eval time =   18227.34 ms /    70 runs   (  260.39 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   23792.62 ms /   174 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1371.18 ms /    24 tokens (   57.13 ms per token,    17.50 tokens per second)

llama_perf_context_print:        eval time =   23611.32 ms /    91 runs   (  259.47 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   25142.00 ms /   115 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3580.20 ms /    66 tokens (   54.25 ms per token,    18.43 tokens per second)

llama_perf_context_print:        eval time =   17401.02 ms /    67 runs   (  259.72 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   21099.65 ms /   133 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1311.85 ms /    19 tokens (   69.04 ms per token,    14.48 tokens per second)

llama_perf_context_print:        eval time =   11135.44 ms /    43 runs   (  258.96 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   12522.46 ms /    62 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2351.46 ms /    41 tokens (   57.35 ms per token,    17.44 tokens per second)

llama_perf_context_print:        eval time =    9334.91 ms /    36 runs   (  259.30 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   11749.96 ms /    77 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3396.53 ms /    59 tokens (   57.57 ms per token,    17.37 tokens per second)

llama_perf_context_print:        eval time =   12718.41 ms /    49 runs   (  259.56 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   16200.48 ms /   108 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 160, 'total_tokens': 291}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 70, 'total_tokens': 178}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 91, 'total_tokens': 119}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 67, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 43, 'total_tokens': 66}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 36, 'total_tokens': 81}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3148.95 ms /    55 tokens (   57.25 ms per token,    17.47 tokens per second)

llama_perf_context_print:        eval time =   10896.50 ms /    42 runs   (  259.44 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   14118.75 ms /    97 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4323.38 ms /    78 tokens (   55.43 ms per token,    18.04 tokens per second)

llama_perf_context_print:        eval time =   21577.79 ms /    83 runs   (  259.97 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   26046.21 ms /   161 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3572.88 ms /    66 tokens (   54.13 ms per token,    18.47 tokens per second)

llama_perf_context_print:        eval time =   23912.42 ms /    92 runs   (  259.92 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   27646.43 ms /   158 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3227.18 ms /    60 tokens (   53.79 ms per token,    18.59 tokens per second)

llama_perf_context_print:        eval time =   16620.66 ms /    64 runs   (  259.70 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   19959.45 ms /   124 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3150.45 ms /    55 tokens (   57.28 ms per token,    17.46 tokens per second)

llama_perf_context_print:        eval time =   15574.64 ms /    60 runs   (  259.58 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   18829.62 ms /   115 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2991.44 ms /    56 tokens (   53.42 ms per token,    18.72 tokens per second)

llama_perf_context_print:        eval time =   12194.00 ms /    47 runs   (  259.45 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   15267.46 ms /   103 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 49, 'total_tokens': 112}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 42, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 83, 'total_tokens': 165}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 92, 'total_tokens': 162}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 64, 'total_tokens': 128}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 60, 'total_tokens': 119}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2702.94 ms /    46 tokens (   58.76 ms per token,    17.02 tokens per second)

llama_perf_context_print:        eval time =   10380.43 ms /    40 runs   (  259.51 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   13153.03 ms /    86 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3567.96 ms /    68 tokens (   52.47 ms per token,    19.06 tokens per second)

llama_perf_context_print:        eval time =   12983.98 ms /    50 runs   (  259.68 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   16639.51 ms /   118 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1111.38 ms /    14 tokens (   79.38 ms per token,    12.60 tokens per second)

llama_perf_context_print:        eval time =   32431.43 ms /   125 runs   (  259.45 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   33765.44 ms /   139 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3373.29 ms /    59 tokens (   57.17 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =    6230.94 ms /    24 runs   (  259.62 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =    9647.87 ms /    83 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =     872.64 ms /    16 tokens (   54.54 ms per token,    18.34 tokens per second)

llama_perf_context_print:        eval time =    5695.86 ms /    22 runs   (  258.90 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    6607.62 ms /    38 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2837.65 ms /    47 tokens (   60.38 ms per token,    16.56 tokens per second)

llama_perf_context_print:        eval time =    7258.10 ms /    28 runs   (  259.22 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   10145.23 ms /    75 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1122.14 ms /    20 tokens (   56.11 ms per token,    17.82 tokens per second)

llama_perf_context_print:        eval time =  266218.91 ms /   999 runs   (  266.49 ms per token,     3.75 tokens per second)

llama_perf_context_print:       total time =  269669.36 ms /  1019 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 47, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 40, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 50, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 125, 'total_tokens': 143}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 24, 'total_tokens': 87}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 22, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 28, 'total_tokens': 79}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2624.59 ms /    49 tokens (   53.56 ms per token,    18.67 tokens per second)

llama_perf_context_print:        eval time =    5195.09 ms /    20 runs   (  259.75 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =    7855.34 ms /    69 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =     877.69 ms /    16 tokens (   54.86 ms per token,    18.23 tokens per second)

llama_perf_context_print:        eval time =   11131.98 ms /    43 runs   (  258.88 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   12084.73 ms /    59 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4196.74 ms /    75 tokens (   55.96 ms per token,    17.87 tokens per second)

llama_perf_context_print:        eval time =    5970.00 ms /    23 runs   (  259.57 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   10207.52 ms /    98 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1123.46 ms /    20 tokens (   56.17 ms per token,    17.80 tokens per second)

llama_perf_context_print:        eval time =   80063.65 ms /   307 runs   (  260.79 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =   81764.97 ms /   327 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 1000, 'total_tokens': 1024}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 20, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 43, 'total_tokens': 63}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 23, 'total_tokens': 102}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3631.93 ms /    63 tokens (   57.65 ms per token,    17.35 tokens per second)

llama_perf_context_print:        eval time =    4689.79 ms /    18 runs   (  260.54 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =    8354.77 ms /    81 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2599.40 ms /    43 tokens (   60.45 ms per token,    16.54 tokens per second)

llama_perf_context_print:        eval time =    8295.78 ms /    32 runs   (  259.24 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   10952.59 ms /    75 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2103.70 ms /    35 tokens (   60.11 ms per token,    16.64 tokens per second)

llama_perf_context_print:        eval time =   21025.28 ms /    81 runs   (  259.57 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   23271.81 ms /   116 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2358.45 ms /    39 tokens (   60.47 ms per token,    16.54 tokens per second)

llama_perf_context_print:        eval time =   42402.09 ms /   163 runs   (  260.14 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   45055.03 ms /   202 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 307, 'total_tokens': 331}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 18, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 32, 'total_tokens': 79}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 81, 'total_tokens': 120}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2201.10 ms /    40 tokens (   55.03 ms per token,    18.17 tokens per second)

llama_perf_context_print:        eval time =   56281.47 ms /   216 runs   (  260.56 ms per token,     3.84 tokens per second)

llama_perf_context_print:       total time =   58876.76 ms /   256 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2997.68 ms /    56 tokens (   53.53 ms per token,    18.68 tokens per second)

llama_perf_context_print:        eval time =   11941.86 ms /    46 runs   (  259.61 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   15019.91 ms /   102 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2435.84 ms /    44 tokens (   55.36 ms per token,    18.06 tokens per second)

llama_perf_context_print:        eval time =   11407.84 ms /    44 runs   (  259.27 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   13920.59 ms /    88 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2317.48 ms /    41 tokens (   56.52 ms per token,    17.69 tokens per second)

llama_perf_context_print:        eval time =   21543.42 ms /    83 runs   (  259.56 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   24005.99 ms /   124 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2448.53 ms /    44 tokens (   55.65 ms per token,    17.97 tokens per second)

llama_perf_context_print:        eval time =    9590.56 ms /    37 runs   (  259.20 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   12105.01 ms /    81 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 163, 'total_tokens': 206}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 216, 'total_tokens': 260}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 46, 'total_tokens': 106}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 44, 'total_tokens': 92}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 83, 'total_tokens': 128}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2572.58 ms /    45 tokens (   57.17 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =   13490.03 ms /    52 runs   (  259.42 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   16153.37 ms /    97 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2225.56 ms /    38 tokens (   58.57 ms per token,    17.07 tokens per second)

llama_perf_context_print:        eval time =    8555.16 ms /    33 runs   (  259.25 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =   10840.15 ms /    71 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3390.69 ms /    61 tokens (   55.59 ms per token,    17.99 tokens per second)

llama_perf_context_print:        eval time =  214545.73 ms /   808 runs   (  265.53 ms per token,     3.77 tokens per second)

llama_perf_context_print:       total time =  219730.26 ms /   869 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 37, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 52, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 33, 'total_tokens': 75}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    2510.30 ms /    48 tokens (   52.30 ms per token,    19.12 tokens per second)

llama_perf_context_print:        eval time =   54778.81 ms /   210 runs   (  260.85 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =   57674.48 ms /   258 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3191.49 ms /    55 tokens (   58.03 ms per token,    17.23 tokens per second)

llama_perf_context_print:        eval time =   30161.27 ms /   116 runs   (  260.01 ms per token,     3.85 tokens per second)

llama_perf_context_print:       total time =   33557.28 ms /   171 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    4465.20 ms /    79 tokens (   56.52 ms per token,    17.69 tokens per second)

llama_perf_context_print:        eval time =  267121.36 ms /   999 runs   (  267.39 ms per token,     3.74 tokens per second)

llama_perf_context_print:       total time =  273917.71 ms /  1078 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 808, 'total_tokens': 873}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 210, 'total_tokens': 262}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 116, 'total_tokens': 175}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3526.48 ms /    62 tokens (   56.88 ms per token,    17.58 tokens per second)

llama_perf_context_print:        eval time =   58413.67 ms /   224 runs   (  260.78 ms per token,     3.83 tokens per second)

llama_perf_context_print:       total time =   62349.10 ms /   286 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3643.26 ms /    63 tokens (   57.83 ms per token,    17.29 tokens per second)

llama_perf_context_print:        eval time =   99777.37 ms /   381 runs   (  261.88 ms per token,     3.82 tokens per second)

llama_perf_context_print:       total time =  104152.71 ms /   444 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 1000, 'total_tokens': 1083}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 224, 'total_tokens': 290}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3237.78 ms /    60 tokens (   53.96 ms per token,    18.53 tokens per second)

llama_perf_context_print:        eval time =  266826.57 ms /   999 runs   (  267.09 ms per token,     3.74 tokens per second)

llama_perf_context_print:       total time =  272404.03 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 381, 'total_tokens': 449}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    1836.19 ms /    33 tokens (   55.64 ms per token,    17.97 tokens per second)

llama_perf_context_print:        eval time =    1813.92 ms /     7 runs   (  259.13 ms per token,     3.86 tokens per second)

llama_perf_context_print:       total time =    3663.83 ms /    40 tokens

llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    3268.81 ms /    58 tokens (   56.36 ms per token,    17.74 tokens per second)

llama_perf_context_print:        eval time =  169723.58 ms /   643 runs   (  263.96 ms per token,     3.79 tokens per second)

llama_perf_context_print:       total time =  174342.83 ms /   701 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 7, 'total_tokens': 44}}
llama_perf_context_print:        load time =     990.75 ms

llama_perf_context_print: prompt eval time =    6055.99 ms /   111 tokens (   54.56 ms per token,    18.33 tokens per second)

llama_perf_context_print:        eval time =  160274.80 ms /   606 runs   (  264.48 ms per token,     3.78 tokens per second)

llama_perf_context_print:       total time =  167586.71 ms /   717 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 643, 'total_tokens': 705}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 606, 'total_tokens': 721}}
