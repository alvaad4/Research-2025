llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3297.08 ms /    55 tokens (   59.95 ms per token,    16.68 tokens per second)

llama_perf_context_print:        eval time =    1001.75 ms /     7 runs   (  143.11 ms per token,     6.99 tokens per second)

llama_perf_context_print:       total time =    4315.55 ms /    62 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     871.48 ms /    21 tokens (   41.50 ms per token,    24.10 tokens per second)

llama_perf_context_print:        eval time =    7132.00 ms /    49 runs   (  145.55 ms per token,     6.87 tokens per second)

llama_perf_context_print:       total time =    8091.54 ms /    70 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     857.87 ms /    21 tokens (   40.85 ms per token,    24.48 tokens per second)

llama_perf_context_print:        eval time =    1897.30 ms /    13 runs   (  145.95 ms per token,     6.85 tokens per second)

llama_perf_context_print:       total time =    2780.13 ms /    34 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1122.61 ms /    28 tokens (   40.09 ms per token,    24.94 tokens per second)

llama_perf_context_print:        eval time =    6704.60 ms /    46 runs   (  145.75 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =    7909.14 ms /    74 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     692.32 ms /    14 tokens (   49.45 ms per token,    20.22 tokens per second)

llama_perf_context_print:        eval time =   28978.28 ms /   195 runs   (  148.61 ms per token,     6.73 tokens per second)

llama_perf_context_print:       total time =   30033.46 ms /   209 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     755.02 ms /    16 tokens (   47.19 ms per token,    21.19 tokens per second)

llama_perf_context_print:        eval time =    7342.04 ms /    51 runs   (  143.96 ms per token,     6.95 tokens per second)

llama_perf_context_print:       total time =    8189.10 ms /    67 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     737.21 ms /    17 tokens (   43.37 ms per token,    23.06 tokens per second)

llama_perf_context_print:        eval time =    3746.39 ms /    26 runs   (  144.09 ms per token,     6.94 tokens per second)

llama_perf_context_print:       total time =    4531.55 ms /    43 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 7, 'total_tokens': 62}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 49, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 13, 'total_tokens': 75}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 46, 'total_tokens': 115}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 195, 'total_tokens': 250}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 51, 'total_tokens': 108}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     719.73 ms /    15 tokens (   47.98 ms per token,    20.84 tokens per second)

llama_perf_context_print:        eval time =    1134.51 ms /     8 runs   (  141.81 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =    1870.96 ms /    23 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1085.84 ms /    27 tokens (   40.22 ms per token,    24.87 tokens per second)

llama_perf_context_print:        eval time =    1877.44 ms /    13 runs   (  144.42 ms per token,     6.92 tokens per second)

llama_perf_context_print:       total time =    2989.43 ms /    40 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     878.19 ms /    21 tokens (   41.82 ms per token,    23.91 tokens per second)

llama_perf_context_print:        eval time =   14150.99 ms /    97 runs   (  145.89 ms per token,     6.85 tokens per second)

llama_perf_context_print:       total time =   15202.74 ms /   118 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3191.57 ms /    90 tokens (   35.46 ms per token,    28.20 tokens per second)

llama_perf_context_print:        eval time =   43870.67 ms /   296 runs   (  148.21 ms per token,     6.75 tokens per second)

llama_perf_context_print:       total time =   47655.32 ms /   386 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1503.23 ms /    40 tokens (   37.58 ms per token,    26.61 tokens per second)

llama_perf_context_print:        eval time =   19717.53 ms /   135 runs   (  146.06 ms per token,     6.85 tokens per second)

llama_perf_context_print:       total time =   21457.09 ms /   175 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1892.24 ms /    51 tokens (   37.10 ms per token,    26.95 tokens per second)

llama_perf_context_print:        eval time =   58056.77 ms /   392 runs   (  148.10 ms per token,     6.75 tokens per second)

llama_perf_context_print:       total time =   60728.36 ms /   443 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 26, 'total_tokens': 84}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 8, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 13, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 97, 'total_tokens': 159}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 296, 'total_tokens': 427}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 135, 'total_tokens': 216}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2147.13 ms /    58 tokens (   37.02 ms per token,    27.01 tokens per second)

llama_perf_context_print:        eval time =   18676.54 ms /   127 runs   (  147.06 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =   21038.18 ms /   185 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1163.28 ms /    29 tokens (   40.11 ms per token,    24.93 tokens per second)

llama_perf_context_print:        eval time =   12206.09 ms /    84 runs   (  145.31 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =   13514.59 ms /   113 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     990.63 ms /    24 tokens (   41.28 ms per token,    24.23 tokens per second)

llama_perf_context_print:        eval time =   83235.23 ms /   558 runs   (  149.17 ms per token,     6.70 tokens per second)

llama_perf_context_print:       total time =   85419.74 ms /   582 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 392, 'total_tokens': 484}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 127, 'total_tokens': 226}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 84, 'total_tokens': 153}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1920.54 ms /    51 tokens (   37.66 ms per token,    26.56 tokens per second)

llama_perf_context_print:        eval time =   88712.79 ms /   592 runs   (  149.85 ms per token,     6.67 tokens per second)

llama_perf_context_print:       total time =   91953.88 ms /   643 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2166.88 ms /    58 tokens (   37.36 ms per token,    26.77 tokens per second)

llama_perf_context_print:        eval time =   36693.94 ms /   249 runs   (  147.37 ms per token,     6.79 tokens per second)

llama_perf_context_print:       total time =   39322.02 ms /   307 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 558, 'total_tokens': 622}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 592, 'total_tokens': 684}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2332.85 ms /    63 tokens (   37.03 ms per token,    27.01 tokens per second)

llama_perf_context_print:        eval time =  135011.51 ms /   896 runs   (  150.68 ms per token,     6.64 tokens per second)

llama_perf_context_print:       total time =  139660.62 ms /   959 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 249, 'total_tokens': 351}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3675.19 ms /   102 tokens (   36.03 ms per token,    27.75 tokens per second)

llama_perf_context_print:        eval time =   31310.43 ms /   212 runs   (  147.69 ms per token,     6.77 tokens per second)

llama_perf_context_print:       total time =   35378.55 ms /   314 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1948.77 ms /    51 tokens (   38.21 ms per token,    26.17 tokens per second)

llama_perf_context_print:        eval time =   28251.42 ms /   192 runs   (  147.14 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =   30530.83 ms /   243 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2050.66 ms /    54 tokens (   37.98 ms per token,    26.33 tokens per second)

llama_perf_context_print:        eval time =   23548.32 ms /   161 runs   (  146.26 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =   25873.58 ms /   215 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1364.31 ms /    34 tokens (   40.13 ms per token,    24.92 tokens per second)

llama_perf_context_print:        eval time =   17826.13 ms /   122 runs   (  146.12 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =   19395.58 ms /   156 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 896, 'total_tokens': 1003}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 143, 'completion_tokens': 212, 'total_tokens': 355}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 91, 'completion_tokens': 192, 'total_tokens': 283}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 161, 'total_tokens': 255}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1766.04 ms /    45 tokens (   39.25 ms per token,    25.48 tokens per second)

llama_perf_context_print:        eval time =   39503.76 ms /   268 runs   (  147.40 ms per token,     6.78 tokens per second)

llama_perf_context_print:       total time =   41748.91 ms /   313 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2768.52 ms /    75 tokens (   36.91 ms per token,    27.09 tokens per second)

llama_perf_context_print:        eval time =   40326.37 ms /   272 runs   (  148.26 ms per token,     6.74 tokens per second)

llama_perf_context_print:       total time =   43605.17 ms /   347 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1645.66 ms /    42 tokens (   39.18 ms per token,    25.52 tokens per second)

llama_perf_context_print:        eval time =   30021.48 ms /   204 runs   (  147.16 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =   32008.95 ms /   246 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 122, 'total_tokens': 197}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 268, 'total_tokens': 354}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 116, 'completion_tokens': 272, 'total_tokens': 388}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 204, 'total_tokens': 287}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1184.76 ms /    29 tokens (   40.85 ms per token,    24.48 tokens per second)

llama_perf_context_print:        eval time =  158616.34 ms /   999 runs   (  158.78 ms per token,     6.30 tokens per second)

llama_perf_context_print:       total time =  162408.81 ms /  1028 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1650.29 ms /    43 tokens (   38.38 ms per token,    26.06 tokens per second)

llama_perf_context_print:        eval time =   18819.94 ms /   129 runs   (  145.89 ms per token,     6.85 tokens per second)

llama_perf_context_print:       total time =   20683.51 ms /   172 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1376.13 ms /    35 tokens (   39.32 ms per token,    25.43 tokens per second)

llama_perf_context_print:        eval time =   21340.18 ms /   146 runs   (  146.17 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =   22957.43 ms /   181 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1140.56 ms /    28 tokens (   40.73 ms per token,    24.55 tokens per second)

llama_perf_context_print:        eval time =   24334.00 ms /   166 runs   (  146.59 ms per token,     6.82 tokens per second)

llama_perf_context_print:       total time =   25759.82 ms /   194 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     896.82 ms /    21 tokens (   42.71 ms per token,    23.42 tokens per second)

llama_perf_context_print:        eval time =    2148.47 ms /    15 runs   (  143.23 ms per token,     6.98 tokens per second)

llama_perf_context_print:       total time =    3070.46 ms /    36 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1078.05 ms /    26 tokens (   41.46 ms per token,    24.12 tokens per second)

llama_perf_context_print:        eval time =   65394.10 ms /   440 runs   (  148.62 ms per token,     6.73 tokens per second)

llama_perf_context_print:       total time =   67360.28 ms /   466 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 1000, 'total_tokens': 1070}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 129, 'total_tokens': 213}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 146, 'total_tokens': 222}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 166, 'total_tokens': 235}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 15, 'total_tokens': 78}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1298.73 ms /    33 tokens (   39.36 ms per token,    25.41 tokens per second)

llama_perf_context_print:        eval time =   10859.86 ms /    74 runs   (  146.75 ms per token,     6.81 tokens per second)

llama_perf_context_print:       total time =   12276.42 ms /   107 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     863.06 ms /    20 tokens (   43.15 ms per token,    23.17 tokens per second)

llama_perf_context_print:        eval time =   54096.45 ms /   367 runs   (  147.40 ms per token,     6.78 tokens per second)

llama_perf_context_print:       total time =   55673.24 ms /   387 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     735.32 ms /    15 tokens (   49.02 ms per token,    20.40 tokens per second)

llama_perf_context_print:        eval time =    7519.77 ms /    52 runs   (  144.61 ms per token,     6.92 tokens per second)

llama_perf_context_print:       total time =    8339.88 ms /    67 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     836.84 ms /    19 tokens (   44.04 ms per token,    22.70 tokens per second)

llama_perf_context_print:        eval time =   46623.38 ms /   317 runs   (  147.08 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =   48051.78 ms /   336 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 440, 'total_tokens': 506}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 74, 'total_tokens': 147}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 367, 'total_tokens': 428}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 52, 'total_tokens': 108}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     698.84 ms /    14 tokens (   49.92 ms per token,    20.03 tokens per second)

llama_perf_context_print:        eval time =    1441.83 ms /    10 runs   (  144.18 ms per token,     6.94 tokens per second)

llama_perf_context_print:       total time =    2158.95 ms /    24 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     965.96 ms /    23 tokens (   42.00 ms per token,    23.81 tokens per second)

llama_perf_context_print:        eval time =    3034.24 ms /    21 runs   (  144.49 ms per token,     6.92 tokens per second)

llama_perf_context_print:       total time =    4035.30 ms /    44 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     792.43 ms /    18 tokens (   44.02 ms per token,    22.71 tokens per second)

llama_perf_context_print:        eval time =   51873.58 ms /   352 runs   (  147.37 ms per token,     6.79 tokens per second)

llama_perf_context_print:       total time =   53314.86 ms /   370 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1390.85 ms /    35 tokens (   39.74 ms per token,    25.16 tokens per second)

llama_perf_context_print:        eval time =   11486.94 ms /    79 runs   (  145.40 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =   13009.97 ms /   114 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3433.55 ms /    93 tokens (   36.92 ms per token,    27.09 tokens per second)

llama_perf_context_print:        eval time =    5610.65 ms /    38 runs   (  147.65 ms per token,     6.77 tokens per second)

llama_perf_context_print:       total time =    9107.12 ms /   131 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 317, 'total_tokens': 377}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 21, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 352, 'total_tokens': 411}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 79, 'total_tokens': 155}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 134, 'completion_tokens': 38, 'total_tokens': 172}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    4027.23 ms /   111 tokens (   36.28 ms per token,    27.56 tokens per second)

llama_perf_context_print:        eval time =   10703.04 ms /    73 runs   (  146.62 ms per token,     6.82 tokens per second)

llama_perf_context_print:       total time =   14846.43 ms /   184 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    4803.59 ms /   133 tokens (   36.12 ms per token,    27.69 tokens per second)

llama_perf_context_print:        eval time =   11106.32 ms /    76 runs   (  146.14 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =   16038.99 ms /   209 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    4223.81 ms /   117 tokens (   36.10 ms per token,    27.70 tokens per second)

llama_perf_context_print:        eval time =    4109.92 ms /    28 runs   (  146.78 ms per token,     6.81 tokens per second)

llama_perf_context_print:       total time =    8383.63 ms /   145 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2818.71 ms /    76 tokens (   37.09 ms per token,    26.96 tokens per second)

llama_perf_context_print:        eval time =    2337.70 ms /    16 runs   (  146.11 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =    5186.53 ms /    92 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    4890.40 ms /   137 tokens (   35.70 ms per token,    28.01 tokens per second)

llama_perf_context_print:        eval time =   24692.07 ms /   167 runs   (  147.86 ms per token,     6.76 tokens per second)

llama_perf_context_print:       total time =   29873.11 ms /   304 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 152, 'completion_tokens': 73, 'total_tokens': 225}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 76, 'total_tokens': 250}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 158, 'completion_tokens': 28, 'total_tokens': 186}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 16, 'total_tokens': 133}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3581.91 ms /    98 tokens (   36.55 ms per token,    27.36 tokens per second)

llama_perf_context_print:        eval time =   12161.44 ms /    83 runs   (  146.52 ms per token,     6.82 tokens per second)

llama_perf_context_print:       total time =   15876.72 ms /   181 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1115.98 ms /    27 tokens (   41.33 ms per token,    24.19 tokens per second)

llama_perf_context_print:        eval time =   12357.06 ms /    85 runs   (  145.38 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =   13617.49 ms /   112 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2489.63 ms /    67 tokens (   37.16 ms per token,    26.91 tokens per second)

llama_perf_context_print:        eval time =    3365.41 ms /    23 runs   (  146.32 ms per token,     6.83 tokens per second)

llama_perf_context_print:       total time =    5895.50 ms /    90 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     940.69 ms /    22 tokens (   42.76 ms per token,    23.39 tokens per second)

llama_perf_context_print:        eval time =    5933.12 ms /    41 runs   (  144.71 ms per token,     6.91 tokens per second)

llama_perf_context_print:       total time =    6943.07 ms /    63 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1691.46 ms /    43 tokens (   39.34 ms per token,    25.42 tokens per second)

llama_perf_context_print:        eval time =   11970.26 ms /    82 runs   (  145.98 ms per token,     6.85 tokens per second)

llama_perf_context_print:       total time =   13799.55 ms /   125 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2241.28 ms /    59 tokens (   37.99 ms per token,    26.32 tokens per second)

llama_perf_context_print:        eval time =    4925.63 ms /    34 runs   (  144.87 ms per token,     6.90 tokens per second)

llama_perf_context_print:       total time =    7221.73 ms /    93 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2028.87 ms /    53 tokens (   38.28 ms per token,    26.12 tokens per second)

llama_perf_context_print:        eval time =   36888.54 ms /   250 runs   (  147.55 ms per token,     6.78 tokens per second)

llama_perf_context_print:       total time =   39380.75 ms /   303 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 178, 'completion_tokens': 167, 'total_tokens': 345}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 139, 'completion_tokens': 83, 'total_tokens': 222}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 85, 'total_tokens': 153}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 23, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 41, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 82, 'total_tokens': 166}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 34, 'total_tokens': 134}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2812.79 ms /    76 tokens (   37.01 ms per token,    27.02 tokens per second)

llama_perf_context_print:        eval time =   13167.28 ms /    90 runs   (  146.30 ms per token,     6.84 tokens per second)

llama_perf_context_print:       total time =   16134.04 ms /   166 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2516.09 ms /    67 tokens (   37.55 ms per token,    26.63 tokens per second)

llama_perf_context_print:        eval time =    6440.94 ms /    44 runs   (  146.39 ms per token,     6.83 tokens per second)

llama_perf_context_print:       total time =    9030.66 ms /   111 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2347.29 ms /    61 tokens (   38.48 ms per token,    25.99 tokens per second)

llama_perf_context_print:        eval time =    6794.84 ms /    47 runs   (  144.57 ms per token,     6.92 tokens per second)

llama_perf_context_print:       total time =    9218.69 ms /   108 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2002.11 ms /    52 tokens (   38.50 ms per token,    25.97 tokens per second)

llama_perf_context_print:        eval time =    5529.58 ms /    38 runs   (  145.52 ms per token,     6.87 tokens per second)

llama_perf_context_print:       total time =    7594.30 ms /    90 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2109.73 ms /    55 tokens (   38.36 ms per token,    26.07 tokens per second)

llama_perf_context_print:        eval time =    5666.23 ms /    39 runs   (  145.29 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =    7842.41 ms /    94 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 250, 'total_tokens': 344}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 90, 'total_tokens': 207}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 44, 'total_tokens': 152}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 47, 'total_tokens': 149}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 93, 'completion_tokens': 38, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 39, 'total_tokens': 135}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1761.45 ms /    45 tokens (   39.14 ms per token,    25.55 tokens per second)

llama_perf_context_print:        eval time =   44686.04 ms /   303 runs   (  147.48 ms per token,     6.78 tokens per second)

llama_perf_context_print:       total time =   47014.56 ms /   348 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2318.35 ms /    61 tokens (   38.01 ms per token,    26.31 tokens per second)

llama_perf_context_print:        eval time =   53308.49 ms /   360 runs   (  148.08 ms per token,     6.75 tokens per second)

llama_perf_context_print:       total time =   56334.12 ms /   421 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     751.28 ms /    15 tokens (   50.09 ms per token,    19.97 tokens per second)

llama_perf_context_print:        eval time =    6197.84 ms /    43 runs   (  144.14 ms per token,     6.94 tokens per second)

llama_perf_context_print:       total time =    7022.09 ms /    58 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2274.35 ms /    59 tokens (   38.55 ms per token,    25.94 tokens per second)

llama_perf_context_print:        eval time =   23221.34 ms /   158 runs   (  146.97 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =   25772.55 ms /   217 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 303, 'total_tokens': 389}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 360, 'total_tokens': 462}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 43, 'total_tokens': 99}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     762.78 ms /    17 tokens (   44.87 ms per token,    22.29 tokens per second)

llama_perf_context_print:        eval time =    2307.08 ms /    16 runs   (  144.19 ms per token,     6.94 tokens per second)

llama_perf_context_print:       total time =    3098.64 ms /    33 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1835.67 ms /    47 tokens (   39.06 ms per token,    25.60 tokens per second)

llama_perf_context_print:        eval time =    3373.83 ms /    23 runs   (  146.69 ms per token,     6.82 tokens per second)

llama_perf_context_print:       total time =    5250.07 ms /    70 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     900.57 ms /    21 tokens (   42.88 ms per token,    23.32 tokens per second)

llama_perf_context_print:        eval time =    2303.66 ms /    16 runs   (  143.98 ms per token,     6.95 tokens per second)

llama_perf_context_print:       total time =    3232.95 ms /    37 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1899.84 ms /    49 tokens (   38.77 ms per token,    25.79 tokens per second)

llama_perf_context_print:        eval time =    2622.15 ms /    18 runs   (  145.67 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =    4553.86 ms /    67 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     768.88 ms /    17 tokens (   45.23 ms per token,    22.11 tokens per second)

llama_perf_context_print:        eval time =    1727.53 ms /    12 runs   (  143.96 ms per token,     6.95 tokens per second)

llama_perf_context_print:       total time =    2518.80 ms /    29 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2675.29 ms /    71 tokens (   37.68 ms per token,    26.54 tokens per second)

llama_perf_context_print:        eval time =    2940.88 ms /    20 runs   (  147.04 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =    5651.86 ms /    91 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =     865.20 ms /    20 tokens (   43.26 ms per token,    23.12 tokens per second)

llama_perf_context_print:        eval time =    2454.55 ms /    17 runs   (  144.39 ms per token,     6.93 tokens per second)

llama_perf_context_print:       total time =    3351.24 ms /    37 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2374.66 ms /    62 tokens (   38.30 ms per token,    26.11 tokens per second)

llama_perf_context_print:        eval time =    1318.92 ms /     9 runs   (  146.55 ms per token,     6.82 tokens per second)

llama_perf_context_print:       total time =    3711.89 ms /    71 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1731.26 ms /    44 tokens (   39.35 ms per token,    25.42 tokens per second)

llama_perf_context_print:        eval time =    3482.06 ms /    24 runs   (  145.09 ms per token,     6.89 tokens per second)

llama_perf_context_print:       total time =    5254.66 ms /    68 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 158, 'total_tokens': 258}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 16, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 88, 'completion_tokens': 23, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 16, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 18, 'total_tokens': 108}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 12, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 20, 'total_tokens': 132}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 9, 'total_tokens': 111}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1475.98 ms /    37 tokens (   39.89 ms per token,    25.07 tokens per second)

llama_perf_context_print:        eval time =    6524.40 ms /    45 runs   (  144.99 ms per token,     6.90 tokens per second)

llama_perf_context_print:       total time =    8079.61 ms /    82 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1573.63 ms /    40 tokens (   39.34 ms per token,    25.42 tokens per second)

llama_perf_context_print:        eval time =   13710.40 ms /    94 runs   (  145.86 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =   15448.65 ms /   134 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1689.19 ms /    43 tokens (   39.28 ms per token,    25.46 tokens per second)

llama_perf_context_print:        eval time =   11913.38 ms /    82 runs   (  145.29 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =   13744.44 ms /   125 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2140.32 ms /    56 tokens (   38.22 ms per token,    26.16 tokens per second)

llama_perf_context_print:        eval time =    1038.45 ms /     7 runs   (  148.35 ms per token,     6.74 tokens per second)

llama_perf_context_print:       total time =    3192.84 ms /    63 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1684.54 ms /    43 tokens (   39.18 ms per token,    25.53 tokens per second)

llama_perf_context_print:        eval time =    5632.83 ms /    39 runs   (  144.43 ms per token,     6.92 tokens per second)

llama_perf_context_print:       total time =    7382.82 ms /    82 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1686.59 ms /    43 tokens (   39.22 ms per token,    25.50 tokens per second)

llama_perf_context_print:        eval time =    5541.06 ms /    38 runs   (  145.82 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =    7292.75 ms /    81 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1766.52 ms /    45 tokens (   39.26 ms per token,    25.47 tokens per second)

llama_perf_context_print:        eval time =   13958.29 ms /    96 runs   (  145.40 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =   15883.89 ms /   141 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 24, 'total_tokens': 109}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 45, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 94, 'total_tokens': 175}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 82, 'total_tokens': 166}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 7, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 39, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 38, 'total_tokens': 122}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1784.21 ms /    46 tokens (   38.79 ms per token,    25.78 tokens per second)

llama_perf_context_print:        eval time =   12978.39 ms /    89 runs   (  145.82 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =   14913.02 ms /   135 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1457.98 ms /    37 tokens (   39.40 ms per token,    25.38 tokens per second)

llama_perf_context_print:        eval time =   10778.44 ms /    74 runs   (  145.65 ms per token,     6.87 tokens per second)

llama_perf_context_print:       total time =   12354.65 ms /   111 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2180.67 ms /    57 tokens (   38.26 ms per token,    26.14 tokens per second)

llama_perf_context_print:        eval time =  157804.21 ms /   999 runs   (  157.96 ms per token,     6.33 tokens per second)

llama_perf_context_print:       total time =  162622.66 ms /  1056 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 96, 'total_tokens': 182}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 89, 'total_tokens': 176}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 74, 'total_tokens': 152}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1659.99 ms /    44 tokens (   37.73 ms per token,    26.51 tokens per second)

llama_perf_context_print:        eval time =   35269.22 ms /   242 runs   (  145.74 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =   37389.58 ms /   286 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1998.96 ms /    51 tokens (   39.20 ms per token,    25.51 tokens per second)

llama_perf_context_print:        eval time =   15000.53 ms /   101 runs   (  148.52 ms per token,     6.73 tokens per second)

llama_perf_context_print:       total time =   17172.13 ms /   152 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2707.69 ms /    76 tokens (   35.63 ms per token,    28.07 tokens per second)

llama_perf_context_print:        eval time =   61490.22 ms /   406 runs   (  151.45 ms per token,     6.60 tokens per second)

llama_perf_context_print:       total time =   65033.66 ms /   482 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 1000, 'total_tokens': 1087}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 74, 'completion_tokens': 242, 'total_tokens': 316}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 101, 'total_tokens': 182}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2088.09 ms /    56 tokens (   37.29 ms per token,    26.82 tokens per second)

llama_perf_context_print:        eval time =   29036.11 ms /   194 runs   (  149.67 ms per token,     6.68 tokens per second)

llama_perf_context_print:       total time =   31473.73 ms /   250 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2145.52 ms /    58 tokens (   36.99 ms per token,    27.03 tokens per second)

llama_perf_context_print:        eval time =   33380.09 ms /   223 runs   (  149.69 ms per token,     6.68 tokens per second)

llama_perf_context_print:       total time =   35935.59 ms /   281 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2103.61 ms /    56 tokens (   37.56 ms per token,    26.62 tokens per second)

llama_perf_context_print:        eval time =   93772.17 ms /   606 runs   (  154.74 ms per token,     6.46 tokens per second)

llama_perf_context_print:       total time =   97220.69 ms /   662 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 406, 'total_tokens': 512}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 194, 'total_tokens': 280}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 89, 'completion_tokens': 223, 'total_tokens': 312}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    1149.45 ms /    29 tokens (   39.64 ms per token,    25.23 tokens per second)

llama_perf_context_print:        eval time =     735.55 ms /     5 runs   (  147.11 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =    1895.68 ms /    34 tokens

llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    2020.51 ms /    55 tokens (   36.74 ms per token,    27.22 tokens per second)

llama_perf_context_print:        eval time =   56036.28 ms /   371 runs   (  151.04 ms per token,     6.62 tokens per second)

llama_perf_context_print:       total time =   58777.61 ms /   426 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 606, 'total_tokens': 692}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 5, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 371, 'total_tokens': 456}}
llama_perf_context_print:        load time =    3297.28 ms

llama_perf_context_print: prompt eval time =    3703.56 ms /   107 tokens (   34.61 ms per token,    28.89 tokens per second)

llama_perf_context_print:        eval time =    8989.52 ms /    60 runs   (  149.83 ms per token,     6.67 tokens per second)

llama_perf_context_print:       total time =   12790.50 ms /   167 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 137, 'completion_tokens': 60, 'total_tokens': 197}}
