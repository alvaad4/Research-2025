llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     475.76 ms /    10 tokens (   47.58 ms per token,    21.02 tokens per second)

llama_perf_context_print:        eval time =    1537.20 ms /    11 runs   (  139.75 ms per token,     7.16 tokens per second)

llama_perf_context_print:       total time =    2024.65 ms /    21 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     708.88 ms /    15 tokens (   47.26 ms per token,    21.16 tokens per second)

llama_perf_context_print:        eval time =   30793.08 ms /   218 runs   (  141.25 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   31759.11 ms /   233 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     774.60 ms /    15 tokens (   51.64 ms per token,    19.36 tokens per second)

llama_perf_context_print:        eval time =  133995.61 ms /   938 runs   (  142.85 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =  136323.42 ms /   953 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 10, 'completion_tokens': 11, 'total_tokens': 21}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 218, 'total_tokens': 235}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     896.38 ms /    22 tokens (   40.74 ms per token,    24.54 tokens per second)

llama_perf_context_print:        eval time =   72392.39 ms /   510 runs   (  141.95 ms per token,     7.04 tokens per second)

llama_perf_context_print:       total time =   73980.19 ms /   532 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 938, 'total_tokens': 955}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     602.58 ms /    11 tokens (   54.78 ms per token,    18.25 tokens per second)

llama_perf_context_print:        eval time =   37763.25 ms /   267 runs   (  141.44 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   38684.85 ms /   278 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     532.45 ms /    10 tokens (   53.25 ms per token,    18.78 tokens per second)

llama_perf_context_print:        eval time =   74934.01 ms /   528 runs   (  141.92 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   76186.63 ms /   538 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 510, 'total_tokens': 534}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 267, 'total_tokens': 280}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     523.02 ms /    12 tokens (   43.59 ms per token,    22.94 tokens per second)

llama_perf_context_print:        eval time =   40039.55 ms /   283 runs   (  141.48 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   40904.04 ms /   295 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     440.30 ms /     9 tokens (   48.92 ms per token,    20.44 tokens per second)

llama_perf_context_print:        eval time =   26970.80 ms /   191 runs   (  141.21 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   27630.53 ms /   200 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 528, 'total_tokens': 540}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 283, 'total_tokens': 297}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'completion_tokens': 191, 'total_tokens': 202}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     816.50 ms /    21 tokens (   38.88 ms per token,    25.72 tokens per second)

llama_perf_context_print:        eval time =   58975.20 ms /   416 runs   (  141.77 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   60329.83 ms /   437 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     555.27 ms /    16 tokens (   34.70 ms per token,    28.82 tokens per second)

llama_perf_context_print:        eval time =  120498.45 ms /   845 runs   (  142.60 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =  122382.21 ms /   861 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 416, 'total_tokens': 439}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2951.63 ms /    85 tokens (   34.73 ms per token,    28.80 tokens per second)

llama_perf_context_print:        eval time =   60762.68 ms /   428 runs   (  141.97 ms per token,     7.04 tokens per second)

llama_perf_context_print:       total time =   64271.52 ms /   513 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 845, 'total_tokens': 863}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1341.91 ms /    35 tokens (   38.34 ms per token,    26.08 tokens per second)

llama_perf_context_print:        eval time =   41012.86 ms /   290 runs   (  141.42 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   42705.28 ms /   325 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1758.71 ms /    46 tokens (   38.23 ms per token,    26.16 tokens per second)

llama_perf_context_print:        eval time =   42296.63 ms /   299 runs   (  141.46 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   44419.85 ms /   345 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 428, 'total_tokens': 515}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 290, 'total_tokens': 327}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1883.25 ms /    53 tokens (   35.53 ms per token,    28.14 tokens per second)

llama_perf_context_print:        eval time =   49988.18 ms /   353 runs   (  141.61 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   52310.92 ms /   406 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     896.87 ms /    22 tokens (   40.77 ms per token,    24.53 tokens per second)

llama_perf_context_print:        eval time =   50081.00 ms /   354 runs   (  141.47 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   51421.58 ms /   376 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 299, 'total_tokens': 347}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 353, 'total_tokens': 408}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     751.62 ms /    18 tokens (   41.76 ms per token,    23.95 tokens per second)

llama_perf_context_print:        eval time =   27246.21 ms /   193 runs   (  141.17 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   28219.92 ms /   211 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1608.26 ms /    44 tokens (   36.55 ms per token,    27.36 tokens per second)

llama_perf_context_print:        eval time =   49163.33 ms /   347 runs   (  141.68 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   51204.73 ms /   391 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 354, 'total_tokens': 378}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 193, 'total_tokens': 213}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 46, 'completion_tokens': 347, 'total_tokens': 393}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1876.56 ms /    53 tokens (   35.41 ms per token,    28.24 tokens per second)

llama_perf_context_print:        eval time =   48159.21 ms /   340 runs   (  141.64 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   50458.81 ms /   393 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2144.90 ms /    60 tokens (   35.75 ms per token,    27.97 tokens per second)

llama_perf_context_print:        eval time =  112208.77 ms /   787 runs   (  142.58 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =  115556.83 ms /   847 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 340, 'total_tokens': 398}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    3331.33 ms /    97 tokens (   34.34 ms per token,    29.12 tokens per second)

llama_perf_context_print:        eval time =   46042.85 ms /   325 runs   (  141.67 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   49775.77 ms /   422 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 787, 'total_tokens': 852}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 325, 'total_tokens': 424}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1836.10 ms /    47 tokens (   39.07 ms per token,    25.60 tokens per second)

llama_perf_context_print:        eval time =   71509.70 ms /   504 runs   (  141.88 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   74019.23 ms /   551 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1721.52 ms /    49 tokens (   35.13 ms per token,    28.46 tokens per second)

llama_perf_context_print:        eval time =   65110.65 ms /   459 runs   (  141.85 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   67435.85 ms /   508 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1143.24 ms /    29 tokens (   39.42 ms per token,    25.37 tokens per second)

llama_perf_context_print:        eval time =   48516.24 ms /   343 runs   (  141.45 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   50100.84 ms /   372 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 504, 'total_tokens': 553}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 459, 'total_tokens': 510}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1583.57 ms /    42 tokens (   37.70 ms per token,    26.52 tokens per second)

llama_perf_context_print:        eval time =   61808.08 ms /   436 runs   (  141.76 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   63965.12 ms /   478 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2491.83 ms /    70 tokens (   35.60 ms per token,    28.09 tokens per second)

llama_perf_context_print:        eval time =  120635.38 ms /   844 runs   (  142.93 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =  124449.74 ms /   914 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 31, 'completion_tokens': 343, 'total_tokens': 374}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 436, 'total_tokens': 480}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1448.25 ms /    40 tokens (   36.21 ms per token,    27.62 tokens per second)

llama_perf_context_print:        eval time =   38756.59 ms /   274 runs   (  141.45 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   40531.81 ms /   314 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 844, 'total_tokens': 916}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1059.11 ms /    26 tokens (   40.73 ms per token,    24.55 tokens per second)

llama_perf_context_print:        eval time =   65659.75 ms /   463 runs   (  141.81 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   67326.80 ms /   489 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1512.30 ms /    39 tokens (   38.78 ms per token,    25.79 tokens per second)

llama_perf_context_print:        eval time =   47295.47 ms /   334 runs   (  141.60 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   49221.06 ms /   373 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 274, 'total_tokens': 316}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 463, 'total_tokens': 491}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1238.96 ms /    30 tokens (   41.30 ms per token,    24.21 tokens per second)

llama_perf_context_print:        eval time =   57253.81 ms /   404 runs   (  141.72 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   59020.51 ms /   434 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     898.18 ms /    24 tokens (   37.42 ms per token,    26.72 tokens per second)

llama_perf_context_print:        eval time =   55539.36 ms /   392 runs   (  141.68 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   56940.66 ms /   416 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     657.06 ms /    17 tokens (   38.65 ms per token,    25.87 tokens per second)

llama_perf_context_print:        eval time =   57797.67 ms /   408 runs   (  141.66 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   58982.32 ms /   425 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 334, 'total_tokens': 375}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 32, 'completion_tokens': 404, 'total_tokens': 436}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 392, 'total_tokens': 418}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     970.28 ms /    23 tokens (   42.19 ms per token,    23.70 tokens per second)

llama_perf_context_print:        eval time =  130368.60 ms /   913 runs   (  142.79 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =  132813.88 ms /   936 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 408, 'total_tokens': 428}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1146.38 ms /    29 tokens (   39.53 ms per token,    25.30 tokens per second)

llama_perf_context_print:        eval time =   45435.26 ms /   321 runs   (  141.54 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   46979.39 ms /   350 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     700.81 ms /    14 tokens (   50.06 ms per token,    19.98 tokens per second)

llama_perf_context_print:        eval time =   11414.12 ms /    81 runs   (  140.92 ms per token,     7.10 tokens per second)

llama_perf_context_print:       total time =   12202.79 ms /    95 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     537.54 ms /    10 tokens (   53.75 ms per token,    18.60 tokens per second)

llama_perf_context_print:        eval time =  142736.12 ms /   999 runs   (  142.88 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =  144958.73 ms /  1009 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 25, 'completion_tokens': 913, 'total_tokens': 938}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 31, 'completion_tokens': 321, 'total_tokens': 352}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 81, 'total_tokens': 97}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     619.13 ms /    13 tokens (   47.63 ms per token,    21.00 tokens per second)

llama_perf_context_print:        eval time =  142676.33 ms /   999 runs   (  142.82 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =  144972.40 ms /  1012 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 1000, 'total_tokens': 1012}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     616.74 ms /    11 tokens (   56.07 ms per token,    17.84 tokens per second)

llama_perf_context_print:        eval time =   40568.27 ms /   287 runs   (  141.35 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   41530.86 ms /   298 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     669.86 ms /    17 tokens (   39.40 ms per token,    25.38 tokens per second)

llama_perf_context_print:        eval time =   92280.93 ms /   645 runs   (  143.07 ms per token,     6.99 tokens per second)

llama_perf_context_print:       total time =   93917.57 ms /   662 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 15, 'completion_tokens': 1000, 'total_tokens': 1015}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 287, 'total_tokens': 300}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     544.64 ms /    12 tokens (   45.39 ms per token,    22.03 tokens per second)

llama_perf_context_print:        eval time =   54097.37 ms /   380 runs   (  142.36 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   55148.87 ms /   392 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 645, 'total_tokens': 664}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1150.25 ms /    32 tokens (   35.95 ms per token,    27.82 tokens per second)

llama_perf_context_print:        eval time =   28427.81 ms /   200 runs   (  142.14 ms per token,     7.04 tokens per second)

llama_perf_context_print:       total time =   29813.19 ms /   232 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    3183.08 ms /    88 tokens (   36.17 ms per token,    27.65 tokens per second)

llama_perf_context_print:        eval time =   47485.99 ms /   333 runs   (  142.60 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   51092.22 ms /   421 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 380, 'total_tokens': 394}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 34, 'completion_tokens': 200, 'total_tokens': 234}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    3977.41 ms /   107 tokens (   37.17 ms per token,    26.90 tokens per second)

llama_perf_context_print:        eval time =   60129.99 ms /   421 runs   (  142.83 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =   64667.90 ms /   528 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    4538.22 ms /   128 tokens (   35.45 ms per token,    28.20 tokens per second)

llama_perf_context_print:        eval time =   88565.76 ms /   618 runs   (  143.31 ms per token,     6.98 tokens per second)

llama_perf_context_print:       total time =   94010.43 ms /   746 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 333, 'total_tokens': 423}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 109, 'completion_tokens': 421, 'total_tokens': 530}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    4040.87 ms /   113 tokens (   35.76 ms per token,    27.96 tokens per second)

llama_perf_context_print:        eval time =   55103.24 ms /   386 runs   (  142.75 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   59649.34 ms /   499 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 130, 'completion_tokens': 618, 'total_tokens': 748}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2684.44 ms /    71 tokens (   37.81 ms per token,    26.45 tokens per second)

llama_perf_context_print:        eval time =   30443.16 ms /   214 runs   (  142.26 ms per token,     7.03 tokens per second)

llama_perf_context_print:       total time =   33383.53 ms /   285 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    4714.93 ms /   127 tokens (   37.13 ms per token,    26.94 tokens per second)

llama_perf_context_print:        eval time =   72544.47 ms /   507 runs   (  143.09 ms per token,     6.99 tokens per second)

llama_perf_context_print:       total time =   77969.69 ms /   634 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 386, 'total_tokens': 501}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 214, 'total_tokens': 287}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    3596.98 ms /   100 tokens (   35.97 ms per token,    27.80 tokens per second)

llama_perf_context_print:        eval time =   59295.34 ms /   415 runs   (  142.88 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =   63444.46 ms /   515 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 129, 'completion_tokens': 507, 'total_tokens': 636}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     932.91 ms /    22 tokens (   42.40 ms per token,    23.58 tokens per second)

llama_perf_context_print:        eval time =   91532.00 ms /   640 runs   (  143.02 ms per token,     6.99 tokens per second)

llama_perf_context_print:       total time =   93416.92 ms /   662 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 415, 'total_tokens': 517}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2226.49 ms /    58 tokens (   38.39 ms per token,    26.05 tokens per second)

llama_perf_context_print:        eval time =   51436.44 ms /   361 runs   (  142.48 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   54128.28 ms /   419 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     593.89 ms /    16 tokens (   37.12 ms per token,    26.94 tokens per second)

llama_perf_context_print:        eval time =   41536.48 ms /   292 runs   (  142.25 ms per token,     7.03 tokens per second)

llama_perf_context_print:       total time =   42494.04 ms /   308 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 640, 'total_tokens': 664}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 361, 'total_tokens': 421}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1401.16 ms /    37 tokens (   37.87 ms per token,    26.41 tokens per second)

llama_perf_context_print:        eval time =   55302.79 ms /   388 runs   (  142.53 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   57211.28 ms /   425 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2077.73 ms /    56 tokens (   37.10 ms per token,    26.95 tokens per second)

llama_perf_context_print:        eval time =   45868.35 ms /   322 runs   (  142.45 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   48353.10 ms /   378 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 292, 'total_tokens': 310}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 388, 'total_tokens': 427}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1804.75 ms /    49 tokens (   36.83 ms per token,    27.15 tokens per second)

llama_perf_context_print:        eval time =   47591.60 ms /   334 runs   (  142.49 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   49820.89 ms /   383 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2702.72 ms /    73 tokens (   37.02 ms per token,    27.01 tokens per second)

llama_perf_context_print:        eval time =   71889.42 ms /   503 runs   (  142.92 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =   75292.12 ms /   576 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 322, 'total_tokens': 380}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 334, 'total_tokens': 385}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2351.85 ms /    65 tokens (   36.18 ms per token,    27.64 tokens per second)

llama_perf_context_print:        eval time =   42305.08 ms /   297 runs   (  142.44 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   45027.67 ms /   362 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 503, 'total_tokens': 578}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2122.79 ms /    55 tokens (   38.60 ms per token,    25.91 tokens per second)

llama_perf_context_print:        eval time =   60771.75 ms /   426 runs   (  142.66 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   63463.09 ms /   481 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1832.59 ms /    46 tokens (   39.84 ms per token,    25.10 tokens per second)

llama_perf_context_print:        eval time =   70066.88 ms /   491 runs   (  142.70 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   72574.57 ms /   537 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 297, 'total_tokens': 364}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 426, 'total_tokens': 483}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1946.66 ms /    51 tokens (   38.17 ms per token,    26.20 tokens per second)

llama_perf_context_print:        eval time =   65061.77 ms /   456 runs   (  142.68 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   67626.20 ms /   507 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 491, 'total_tokens': 539}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1582.33 ms /    41 tokens (   38.59 ms per token,    25.91 tokens per second)

llama_perf_context_print:        eval time =   59459.71 ms /   417 runs   (  142.59 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   61601.75 ms /   458 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2385.19 ms /    62 tokens (   38.47 ms per token,    25.99 tokens per second)

llama_perf_context_print:        eval time =   43738.29 ms /   307 runs   (  142.47 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   46506.41 ms /   369 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 456, 'total_tokens': 509}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 417, 'total_tokens': 460}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     470.06 ms /     9 tokens (   52.23 ms per token,    19.15 tokens per second)

llama_perf_context_print:        eval time =   75308.28 ms /   528 runs   (  142.63 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   76516.73 ms /   537 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 307, 'total_tokens': 371}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'completion_tokens': 528, 'total_tokens': 539}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1951.87 ms /    51 tokens (   38.27 ms per token,    26.13 tokens per second)

llama_perf_context_print:        eval time =   37127.79 ms /   261 runs   (  142.25 ms per token,     7.03 tokens per second)

llama_perf_context_print:       total time =   39397.86 ms /   312 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     632.66 ms /    11 tokens (   57.51 ms per token,    17.39 tokens per second)

llama_perf_context_print:        eval time =   62428.80 ms /   438 runs   (  142.53 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   63656.06 ms /   449 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1763.93 ms /    45 tokens (   39.20 ms per token,    25.51 tokens per second)

llama_perf_context_print:        eval time =   71967.04 ms /   504 runs   (  142.79 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =   74438.38 ms /   549 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 261, 'total_tokens': 314}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 438, 'total_tokens': 451}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     802.30 ms /    15 tokens (   53.49 ms per token,    18.70 tokens per second)

llama_perf_context_print:        eval time =  136496.15 ms /   950 runs   (  143.68 ms per token,     6.96 tokens per second)

llama_perf_context_print:       total time =  138942.61 ms /   965 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 504, 'total_tokens': 551}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1737.85 ms /    43 tokens (   40.42 ms per token,    24.74 tokens per second)

llama_perf_context_print:        eval time =   32571.32 ms /   229 runs   (  142.23 ms per token,     7.03 tokens per second)

llama_perf_context_print:       total time =   34585.49 ms /   272 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     636.20 ms /    11 tokens (   57.84 ms per token,    17.29 tokens per second)

llama_perf_context_print:        eval time =   75597.23 ms /   530 runs   (  142.64 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   76976.51 ms /   541 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 950, 'total_tokens': 967}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 229, 'total_tokens': 274}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2610.49 ms /    70 tokens (   37.29 ms per token,    26.81 tokens per second)

llama_perf_context_print:        eval time =  143759.28 ms /   999 runs   (  143.90 ms per token,     6.95 tokens per second)

llama_perf_context_print:       total time =  148067.60 ms /  1069 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 530, 'total_tokens': 543}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     725.95 ms /    14 tokens (   51.85 ms per token,    19.29 tokens per second)

llama_perf_context_print:        eval time =   71302.83 ms /   500 runs   (  142.61 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =   72724.41 ms /   514 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 1000, 'total_tokens': 1072}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2136.07 ms /    57 tokens (   37.47 ms per token,    26.68 tokens per second)

llama_perf_context_print:        eval time =   60058.77 ms /   425 runs   (  141.31 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   62740.62 ms /   482 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1414.50 ms /    38 tokens (   37.22 ms per token,    26.86 tokens per second)

llama_perf_context_print:        eval time =   49248.78 ms /   349 runs   (  141.11 ms per token,     7.09 tokens per second)

llama_perf_context_print:       total time =   51090.52 ms /   387 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 500, 'total_tokens': 516}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 425, 'total_tokens': 484}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1291.34 ms /    31 tokens (   41.66 ms per token,    24.01 tokens per second)

llama_perf_context_print:        eval time =   45822.03 ms /   325 runs   (  140.99 ms per token,     7.09 tokens per second)

llama_perf_context_print:       total time =   47506.26 ms /   356 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 40, 'completion_tokens': 349, 'total_tokens': 389}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 325, 'total_tokens': 358}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1240.46 ms /    34 tokens (   36.48 ms per token,    27.41 tokens per second)

llama_perf_context_print:        eval time =   63278.29 ms /   448 runs   (  141.25 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   65097.84 ms /   482 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1317.96 ms /    37 tokens (   35.62 ms per token,    28.07 tokens per second)

llama_perf_context_print:        eval time =   57050.55 ms /   404 runs   (  141.21 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   58876.75 ms /   441 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 36, 'completion_tokens': 448, 'total_tokens': 484}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1782.76 ms /    52 tokens (   34.28 ms per token,    29.17 tokens per second)

llama_perf_context_print:        eval time =   53357.53 ms /   378 runs   (  141.16 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   55610.38 ms /   430 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1472.36 ms /    39 tokens (   37.75 ms per token,    26.49 tokens per second)

llama_perf_context_print:        eval time =   41772.87 ms /   296 runs   (  141.12 ms per token,     7.09 tokens per second)

llama_perf_context_print:       total time =   43598.25 ms /   335 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 404, 'total_tokens': 443}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 378, 'total_tokens': 432}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1409.27 ms /    38 tokens (   37.09 ms per token,    26.96 tokens per second)

llama_perf_context_print:        eval time =   50819.35 ms /   360 runs   (  141.16 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   52693.39 ms /   398 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1477.36 ms /    39 tokens (   37.88 ms per token,    26.40 tokens per second)

llama_perf_context_print:        eval time =   54554.28 ms /   386 runs   (  141.33 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   56517.15 ms /   425 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 296, 'total_tokens': 337}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 40, 'completion_tokens': 360, 'total_tokens': 400}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1488.90 ms /    39 tokens (   38.18 ms per token,    26.19 tokens per second)

llama_perf_context_print:        eval time =   38926.76 ms /   276 runs   (  141.04 ms per token,     7.09 tokens per second)

llama_perf_context_print:       total time =   40750.10 ms /   315 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1160.45 ms /    33 tokens (   35.17 ms per token,    28.44 tokens per second)

llama_perf_context_print:        eval time =   83570.23 ms /   590 runs   (  141.64 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   85570.58 ms /   623 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 386, 'total_tokens': 427}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 276, 'total_tokens': 317}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1730.50 ms /    46 tokens (   37.62 ms per token,    26.58 tokens per second)

llama_perf_context_print:        eval time =   82008.96 ms /   579 runs   (  141.64 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =   84549.89 ms /   625 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 590, 'total_tokens': 625}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1173.37 ms /    33 tokens (   35.56 ms per token,    28.12 tokens per second)

llama_perf_context_print:        eval time =   99019.82 ms /   698 runs   (  141.86 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =  101230.39 ms /   731 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 579, 'total_tokens': 627}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1403.50 ms /    40 tokens (   35.09 ms per token,    28.50 tokens per second)

llama_perf_context_print:        eval time =   33992.09 ms /   241 runs   (  141.05 ms per token,     7.09 tokens per second)

llama_perf_context_print:       total time =   35677.30 ms /   281 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 698, 'total_tokens': 733}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    2216.92 ms /    65 tokens (   34.11 ms per token,    29.32 tokens per second)

llama_perf_context_print:        eval time =  142520.19 ms /   999 runs   (  142.66 ms per token,     7.01 tokens per second)

llama_perf_context_print:       total time =  146437.84 ms /  1064 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 241, 'total_tokens': 283}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1806.86 ms /    47 tokens (   38.44 ms per token,    26.01 tokens per second)

llama_perf_context_print:        eval time =   51111.95 ms /   362 runs   (  141.19 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   53385.16 ms /   409 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 1000, 'total_tokens': 1067}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1801.31 ms /    47 tokens (   38.33 ms per token,    26.09 tokens per second)

llama_perf_context_print:        eval time =   66066.50 ms /   467 runs   (  141.47 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   68480.34 ms /   514 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1640.40 ms /    45 tokens (   36.45 ms per token,    27.43 tokens per second)

llama_perf_context_print:        eval time =  136563.35 ms /   951 runs   (  143.60 ms per token,     6.96 tokens per second)

llama_perf_context_print:       total time =  139803.42 ms /   996 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 362, 'total_tokens': 411}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 467, 'total_tokens': 517}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =     734.31 ms /    18 tokens (   40.79 ms per token,    24.51 tokens per second)

llama_perf_context_print:        eval time =   27407.83 ms /   194 runs   (  141.28 ms per token,     7.08 tokens per second)

llama_perf_context_print:       total time =   28366.43 ms /   212 tokens

llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    1591.31 ms /    44 tokens (   36.17 ms per token,    27.65 tokens per second)

llama_perf_context_print:        eval time =   97271.06 ms /   683 runs   (  142.42 ms per token,     7.02 tokens per second)

llama_perf_context_print:       total time =   99869.87 ms /   727 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 951, 'total_tokens': 998}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 194, 'total_tokens': 214}}
llama_perf_context_print:        load time =     475.85 ms

llama_perf_context_print: prompt eval time =    3274.63 ms /    96 tokens (   34.11 ms per token,    29.32 tokens per second)

llama_perf_context_print:        eval time =   76133.77 ms /   535 runs   (  142.31 ms per token,     7.03 tokens per second)

llama_perf_context_print:       total time =   80146.48 ms /   631 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 46, 'completion_tokens': 683, 'total_tokens': 729}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 98, 'completion_tokens': 535, 'total_tokens': 633}}
