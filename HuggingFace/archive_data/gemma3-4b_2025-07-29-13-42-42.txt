llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     718.12 ms /    17 tokens (   42.24 ms per token,    23.67 tokens per second)

llama_perf_context_print:        eval time =    3911.16 ms /    55 runs   (   71.11 ms per token,    14.06 tokens per second)

llama_perf_context_print:       total time =    4831.36 ms /    72 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     221.68 ms /    20 tokens (   11.08 ms per token,    90.22 tokens per second)

llama_perf_context_print:        eval time =   12832.02 ms /   179 runs   (   71.69 ms per token,    13.95 tokens per second)

llama_perf_context_print:       total time =   13721.72 ms /   199 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     242.97 ms /    20 tokens (   12.15 ms per token,    82.32 tokens per second)

llama_perf_context_print:        eval time =   13990.69 ms /   195 runs   (   71.75 ms per token,    13.94 tokens per second)

llama_perf_context_print:       total time =   14981.94 ms /   215 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     256.15 ms /    26 tokens (    9.85 ms per token,   101.50 tokens per second)

llama_perf_context_print:        eval time =    3576.22 ms /    50 runs   (   71.52 ms per token,    13.98 tokens per second)

llama_perf_context_print:       total time =    4025.52 ms /    76 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 55, 'total_tokens': 72}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 179, 'total_tokens': 203}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 195, 'total_tokens': 219}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     198.32 ms /    16 tokens (   12.40 ms per token,    80.68 tokens per second)

llama_perf_context_print:        eval time =    8332.89 ms /   117 runs   (   71.22 ms per token,    14.04 tokens per second)

llama_perf_context_print:       total time =    8962.10 ms /   133 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     216.82 ms /    14 tokens (   15.49 ms per token,    64.57 tokens per second)

llama_perf_context_print:        eval time =   10158.49 ms /   142 runs   (   71.54 ms per token,    13.98 tokens per second)

llama_perf_context_print:       total time =   10905.71 ms /   156 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     206.87 ms /    17 tokens (   12.17 ms per token,    82.18 tokens per second)

llama_perf_context_print:        eval time =    1642.05 ms /    23 runs   (   71.39 ms per token,    14.01 tokens per second)

llama_perf_context_print:       total time =    1936.40 ms /    40 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     233.43 ms /    14 tokens (   16.67 ms per token,    59.97 tokens per second)

llama_perf_context_print:        eval time =    1857.71 ms /    26 runs   (   71.45 ms per token,    14.00 tokens per second)

llama_perf_context_print:       total time =    2189.80 ms /    40 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     274.62 ms /    24 tokens (   11.44 ms per token,    87.39 tokens per second)

llama_perf_context_print:        eval time =    1357.79 ms /    19 runs   (   71.46 ms per token,    13.99 tokens per second)

llama_perf_context_print:       total time =    1704.54 ms /    43 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     261.07 ms /    20 tokens (   13.05 ms per token,    76.61 tokens per second)

llama_perf_context_print:        eval time =    7871.67 ms /   110 runs   (   71.56 ms per token,    13.97 tokens per second)

llama_perf_context_print:       total time =    8537.98 ms /   130 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     663.77 ms /    93 tokens (    7.14 ms per token,   140.11 tokens per second)

llama_perf_context_print:        eval time =    1939.62 ms /    27 runs   (   71.84 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =    2704.24 ms /   120 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     310.83 ms /    38 tokens (    8.18 ms per token,   122.25 tokens per second)

llama_perf_context_print:        eval time =     517.94 ms /     7 runs   (   73.99 ms per token,    13.52 tokens per second)

llama_perf_context_print:       total time =     859.39 ms /    45 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 50, 'total_tokens': 80}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 117, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 142, 'total_tokens': 160}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 23, 'total_tokens': 44}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 19, 'total_tokens': 47}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 110, 'total_tokens': 134}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 27, 'total_tokens': 124}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     458.45 ms /    47 tokens (    9.75 ms per token,   102.52 tokens per second)

llama_perf_context_print:        eval time =     301.42 ms /     4 runs   (   75.36 ms per token,    13.27 tokens per second)

llama_perf_context_print:       total time =     779.62 ms /    51 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     442.58 ms /    55 tokens (    8.05 ms per token,   124.27 tokens per second)

llama_perf_context_print:        eval time =    2933.65 ms /    41 runs   (   71.55 ms per token,    13.98 tokens per second)

llama_perf_context_print:       total time =    3527.86 ms /    96 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     263.10 ms /    25 tokens (   10.52 ms per token,    95.02 tokens per second)

llama_perf_context_print:        eval time =    2925.42 ms /    41 runs   (   71.35 ms per token,    14.02 tokens per second)

llama_perf_context_print:       total time =    3338.27 ms /    66 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     242.03 ms /    23 tokens (   10.52 ms per token,    95.03 tokens per second)

llama_perf_context_print:        eval time =     160.45 ms /     2 runs   (   80.23 ms per token,    12.46 tokens per second)

llama_perf_context_print:       total time =     414.85 ms /    25 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     368.20 ms /    50 tokens (    7.36 ms per token,   135.80 tokens per second)

llama_perf_context_print:        eval time =    2450.91 ms /    34 runs   (   72.09 ms per token,    13.87 tokens per second)

llama_perf_context_print:       total time =    2944.38 ms /    84 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     460.60 ms /    56 tokens (    8.23 ms per token,   121.58 tokens per second)

llama_perf_context_print:        eval time =     819.13 ms /    11 runs   (   74.47 ms per token,    13.43 tokens per second)

llama_perf_context_print:       total time =    1324.55 ms /    67 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     451.23 ms /    68 tokens (    6.64 ms per token,   150.70 tokens per second)

llama_perf_context_print:        eval time =     661.00 ms /     9 runs   (   73.44 ms per token,    13.62 tokens per second)

llama_perf_context_print:       total time =    1149.67 ms /    77 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     715.39 ms /   102 tokens (    7.01 ms per token,   142.58 tokens per second)

llama_perf_context_print:        eval time =     890.29 ms /    12 runs   (   74.19 ms per token,    13.48 tokens per second)

llama_perf_context_print:       total time =    1653.08 ms /   114 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     440.86 ms /    53 tokens (    8.32 ms per token,   120.22 tokens per second)

llama_perf_context_print:        eval time =   16009.32 ms /   222 runs   (   72.11 ms per token,    13.87 tokens per second)

llama_perf_context_print:       total time =   17280.34 ms /   275 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 7, 'total_tokens': 49}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 4, 'total_tokens': 55}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 41, 'total_tokens': 100}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 41, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 2, 'total_tokens': 29}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 34, 'total_tokens': 88}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 11, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 9, 'total_tokens': 84}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 12, 'total_tokens': 118}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     392.57 ms /    54 tokens (    7.27 ms per token,   137.56 tokens per second)

llama_perf_context_print:        eval time =    9691.05 ms /   135 runs   (   71.79 ms per token,    13.93 tokens per second)

llama_perf_context_print:       total time =   10572.50 ms /   189 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     359.01 ms /    34 tokens (   10.56 ms per token,    94.70 tokens per second)

llama_perf_context_print:        eval time =    9239.07 ms /   129 runs   (   71.62 ms per token,    13.96 tokens per second)

llama_perf_context_print:       total time =   10058.83 ms /   163 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     396.67 ms /    47 tokens (    8.44 ms per token,   118.49 tokens per second)

llama_perf_context_print:        eval time =   64943.91 ms /   871 runs   (   74.56 ms per token,    13.41 tokens per second)

llama_perf_context_print:       total time =   68985.15 ms /   918 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 222, 'total_tokens': 279}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 135, 'total_tokens': 193}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 129, 'total_tokens': 167}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     568.87 ms /    75 tokens (    7.58 ms per token,   131.84 tokens per second)

llama_perf_context_print:        eval time =   28230.58 ms /   388 runs   (   72.76 ms per token,    13.74 tokens per second)

llama_perf_context_print:       total time =   30240.15 ms /   463 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     376.34 ms /    45 tokens (    8.36 ms per token,   119.57 tokens per second)

llama_perf_context_print:        eval time =    8569.77 ms /   119 runs   (   72.01 ms per token,    13.89 tokens per second)

llama_perf_context_print:       total time =    9356.54 ms /   164 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     304.52 ms /    31 tokens (    9.82 ms per token,   101.80 tokens per second)

llama_perf_context_print:        eval time =    9269.52 ms /   129 runs   (   71.86 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =   10014.87 ms /   160 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     366.60 ms /    44 tokens (    8.33 ms per token,   120.02 tokens per second)

llama_perf_context_print:        eval time =    7766.28 ms /   108 runs   (   71.91 ms per token,    13.91 tokens per second)

llama_perf_context_print:       total time =    8498.87 ms /   152 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 871, 'total_tokens': 922}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 388, 'total_tokens': 467}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 119, 'total_tokens': 168}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 129, 'total_tokens': 164}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     359.38 ms /    35 tokens (   10.27 ms per token,    97.39 tokens per second)

llama_perf_context_print:        eval time =   11590.81 ms /   162 runs   (   71.55 ms per token,    13.98 tokens per second)

llama_perf_context_print:       total time =   12509.54 ms /   197 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     307.10 ms /    29 tokens (   10.59 ms per token,    94.43 tokens per second)

llama_perf_context_print:        eval time =   23857.72 ms /   327 runs   (   72.96 ms per token,    13.71 tokens per second)

llama_perf_context_print:       total time =   25327.23 ms /   356 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     229.55 ms /    22 tokens (   10.43 ms per token,    95.84 tokens per second)

llama_perf_context_print:        eval time =    1504.87 ms /    21 runs   (   71.66 ms per token,    13.95 tokens per second)

llama_perf_context_print:       total time =    1810.59 ms /    43 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     291.89 ms /    29 tokens (   10.07 ms per token,    99.35 tokens per second)

llama_perf_context_print:        eval time =   68319.88 ms /   926 runs   (   73.78 ms per token,    13.55 tokens per second)

llama_perf_context_print:       total time =   72552.72 ms /   955 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 108, 'total_tokens': 156}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 162, 'total_tokens': 201}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 327, 'total_tokens': 360}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     297.30 ms /    35 tokens (    8.49 ms per token,   117.73 tokens per second)

llama_perf_context_print:        eval time =   10255.39 ms /   143 runs   (   71.72 ms per token,    13.94 tokens per second)

llama_perf_context_print:       total time =   11059.84 ms /   178 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     224.21 ms /    19 tokens (   11.80 ms per token,    84.74 tokens per second)

llama_perf_context_print:        eval time =   12869.42 ms /   179 runs   (   71.90 ms per token,    13.91 tokens per second)

llama_perf_context_print:       total time =   13741.36 ms /   198 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     234.27 ms /    15 tokens (   15.62 ms per token,    64.03 tokens per second)

llama_perf_context_print:        eval time =   10094.17 ms /   141 runs   (   71.59 ms per token,    13.97 tokens per second)

llama_perf_context_print:       total time =   10829.34 ms /   156 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     227.24 ms /    17 tokens (   13.37 ms per token,    74.81 tokens per second)

llama_perf_context_print:        eval time =   73088.03 ms /   985 runs   (   74.20 ms per token,    13.48 tokens per second)

llama_perf_context_print:       total time =   77670.55 ms /  1002 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 926, 'total_tokens': 959}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 143, 'total_tokens': 182}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 179, 'total_tokens': 202}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 141, 'total_tokens': 160}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     201.74 ms /    16 tokens (   12.61 ms per token,    79.31 tokens per second)

llama_perf_context_print:        eval time =    2254.72 ms /    31 runs   (   72.73 ms per token,    13.75 tokens per second)

llama_perf_context_print:       total time =    2564.26 ms /    47 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     262.14 ms /    22 tokens (   11.92 ms per token,    83.92 tokens per second)

llama_perf_context_print:        eval time =    2706.29 ms /    38 runs   (   71.22 ms per token,    14.04 tokens per second)

llama_perf_context_print:       total time =    3098.46 ms /    60 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     209.57 ms /    17 tokens (   12.33 ms per token,    81.12 tokens per second)

llama_perf_context_print:        eval time =   74654.80 ms /   999 runs   (   74.73 ms per token,    13.38 tokens per second)

llama_perf_context_print:       total time =   79402.90 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 985, 'total_tokens': 1006}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 38, 'total_tokens': 64}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     345.75 ms /    37 tokens (    9.34 ms per token,   107.01 tokens per second)

llama_perf_context_print:        eval time =    6200.05 ms /    85 runs   (   72.94 ms per token,    13.71 tokens per second)

llama_perf_context_print:       total time =    6851.95 ms /   122 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     662.47 ms /    90 tokens (    7.36 ms per token,   135.86 tokens per second)

llama_perf_context_print:        eval time =    2689.83 ms /    37 runs   (   72.70 ms per token,    13.76 tokens per second)

llama_perf_context_print:       total time =    3480.76 ms /   127 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     766.67 ms /   114 tokens (    6.73 ms per token,   148.70 tokens per second)

llama_perf_context_print:        eval time =    4911.85 ms /    68 runs   (   72.23 ms per token,    13.84 tokens per second)

llama_perf_context_print:       total time =    5903.41 ms /   182 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 85, 'total_tokens': 126}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 37, 'total_tokens': 131}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     800.50 ms /   131 tokens (    6.11 ms per token,   163.65 tokens per second)

llama_perf_context_print:        eval time =    3772.73 ms /    52 runs   (   72.55 ms per token,    13.78 tokens per second)

llama_perf_context_print:       total time =    4746.06 ms /   183 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     781.66 ms /   119 tokens (    6.57 ms per token,   152.24 tokens per second)

llama_perf_context_print:        eval time =   10229.85 ms /   141 runs   (   72.55 ms per token,    13.78 tokens per second)

llama_perf_context_print:       total time =   11488.81 ms /   260 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     531.37 ms /    76 tokens (    6.99 ms per token,   143.03 tokens per second)

llama_perf_context_print:        eval time =    4464.13 ms /    62 runs   (   72.00 ms per token,    13.89 tokens per second)

llama_perf_context_print:       total time =    5200.34 ms /   138 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     847.38 ms /   129 tokens (    6.57 ms per token,   152.23 tokens per second)

llama_perf_context_print:        eval time =   11400.05 ms /   157 runs   (   72.61 ms per token,    13.77 tokens per second)

llama_perf_context_print:       total time =   12766.69 ms /   286 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 68, 'total_tokens': 186}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 52, 'total_tokens': 187}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 141, 'total_tokens': 264}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 62, 'total_tokens': 142}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     661.27 ms /   104 tokens (    6.36 ms per token,   157.27 tokens per second)

llama_perf_context_print:        eval time =    6704.77 ms /    93 runs   (   72.09 ms per token,    13.87 tokens per second)

llama_perf_context_print:       total time =    7667.55 ms /   197 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     272.49 ms /    24 tokens (   11.35 ms per token,    88.08 tokens per second)

llama_perf_context_print:        eval time =    5486.61 ms /    77 runs   (   71.25 ms per token,    14.03 tokens per second)

llama_perf_context_print:       total time =    6012.93 ms /   101 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     562.58 ms /    66 tokens (    8.52 ms per token,   117.32 tokens per second)

llama_perf_context_print:        eval time =    3519.35 ms /    49 runs   (   71.82 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =    4243.09 ms /   115 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     258.80 ms /    19 tokens (   13.62 ms per token,    73.42 tokens per second)

llama_perf_context_print:        eval time =    2746.41 ms /    38 runs   (   72.27 ms per token,    13.84 tokens per second)

llama_perf_context_print:       total time =    3135.12 ms /    57 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     425.62 ms /    41 tokens (   10.38 ms per token,    96.33 tokens per second)

llama_perf_context_print:        eval time =    2053.61 ms /    28 runs   (   73.34 ms per token,    13.63 tokens per second)

llama_perf_context_print:       total time =    2605.60 ms /    69 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     493.10 ms /    59 tokens (    8.36 ms per token,   119.65 tokens per second)

llama_perf_context_print:        eval time =    3478.68 ms /    48 runs   (   72.47 ms per token,    13.80 tokens per second)

llama_perf_context_print:       total time =    4142.70 ms /   107 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     520.24 ms /    55 tokens (    9.46 ms per token,   105.72 tokens per second)

llama_perf_context_print:        eval time =    2457.59 ms /    34 runs   (   72.28 ms per token,    13.83 tokens per second)

llama_perf_context_print:       total time =    3092.16 ms /    89 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 133, 'completion_tokens': 157, 'total_tokens': 290}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 93, 'total_tokens': 201}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 77, 'total_tokens': 105}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 49, 'total_tokens': 119}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 38, 'total_tokens': 61}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 28, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 48, 'total_tokens': 111}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     600.41 ms /    78 tokens (    7.70 ms per token,   129.91 tokens per second)

llama_perf_context_print:        eval time =    8716.51 ms /   121 runs   (   72.04 ms per token,    13.88 tokens per second)

llama_perf_context_print:       total time =    9719.10 ms /   199 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     495.03 ms /    68 tokens (    7.28 ms per token,   137.37 tokens per second)

llama_perf_context_print:        eval time =    3591.03 ms /    50 runs   (   71.82 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =    4252.81 ms /   118 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     484.35 ms /    60 tokens (    8.07 ms per token,   123.88 tokens per second)

llama_perf_context_print:        eval time =    2451.26 ms /    34 runs   (   72.10 ms per token,    13.87 tokens per second)

llama_perf_context_print:       total time =    3049.16 ms /    94 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     472.97 ms /    55 tokens (    8.60 ms per token,   116.29 tokens per second)

llama_perf_context_print:        eval time =    3447.17 ms /    48 runs   (   71.82 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =    4078.63 ms /   103 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     440.14 ms /    56 tokens (    7.86 ms per token,   127.23 tokens per second)

llama_perf_context_print:        eval time =    3376.69 ms /    47 runs   (   71.84 ms per token,    13.92 tokens per second)

llama_perf_context_print:       total time =    3973.28 ms /   103 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     429.55 ms /    46 tokens (    9.34 ms per token,   107.09 tokens per second)

llama_perf_context_print:        eval time =    2313.06 ms /    32 runs   (   72.28 ms per token,    13.83 tokens per second)

llama_perf_context_print:       total time =    2849.43 ms /    78 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     578.22 ms /    68 tokens (    8.50 ms per token,   117.60 tokens per second)

llama_perf_context_print:        eval time =    3612.35 ms /    50 runs   (   72.25 ms per token,    13.84 tokens per second)

llama_perf_context_print:       total time =    4359.89 ms /   118 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 34, 'total_tokens': 93}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 121, 'total_tokens': 203}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 50, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 34, 'total_tokens': 98}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 48, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 47, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 32, 'total_tokens': 82}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     237.89 ms /    14 tokens (   16.99 ms per token,    58.85 tokens per second)

llama_perf_context_print:        eval time =    4463.62 ms /    62 runs   (   71.99 ms per token,    13.89 tokens per second)

llama_perf_context_print:       total time =    4909.79 ms /    76 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     480.07 ms /    59 tokens (    8.14 ms per token,   122.90 tokens per second)

llama_perf_context_print:        eval time =    1675.69 ms /    23 runs   (   72.86 ms per token,    13.73 tokens per second)

llama_perf_context_print:       total time =    2233.93 ms /    82 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     202.41 ms /    16 tokens (   12.65 ms per token,    79.05 tokens per second)

llama_perf_context_print:        eval time =    2989.03 ms /    42 runs   (   71.17 ms per token,    14.05 tokens per second)

llama_perf_context_print:       total time =    3331.13 ms /    58 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     432.94 ms /    47 tokens (    9.21 ms per token,   108.56 tokens per second)

llama_perf_context_print:        eval time =    1722.36 ms /    24 runs   (   71.77 ms per token,    13.93 tokens per second)

llama_perf_context_print:       total time =    2237.18 ms /    71 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     218.38 ms /    20 tokens (   10.92 ms per token,    91.58 tokens per second)

llama_perf_context_print:        eval time =   67297.28 ms /   910 runs   (   73.95 ms per token,    13.52 tokens per second)

llama_perf_context_print:       total time =   71270.54 ms /   930 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     383.83 ms /    49 tokens (    7.83 ms per token,   127.66 tokens per second)

llama_perf_context_print:        eval time =    2666.69 ms /    37 runs   (   72.07 ms per token,    13.87 tokens per second)

llama_perf_context_print:       total time =    3173.50 ms /    86 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     196.15 ms /    16 tokens (   12.26 ms per token,    81.57 tokens per second)

llama_perf_context_print:        eval time =    2778.23 ms /    39 runs   (   71.24 ms per token,    14.04 tokens per second)

llama_perf_context_print:       total time =    3100.60 ms /    55 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     549.08 ms /    75 tokens (    7.32 ms per token,   136.59 tokens per second)

llama_perf_context_print:        eval time =    1238.13 ms /    17 runs   (   72.83 ms per token,    13.73 tokens per second)

llama_perf_context_print:       total time =    1846.64 ms /    92 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     229.39 ms /    20 tokens (   11.47 ms per token,    87.19 tokens per second)

llama_perf_context_print:        eval time =   29260.38 ms /   403 runs   (   72.61 ms per token,    13.77 tokens per second)

llama_perf_context_print:       total time =   30943.13 ms /   423 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 50, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 62, 'total_tokens': 80}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 23, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 24, 'total_tokens': 75}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 37, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 39, 'total_tokens': 59}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 17, 'total_tokens': 96}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     459.11 ms /    64 tokens (    7.17 ms per token,   139.40 tokens per second)

llama_perf_context_print:        eval time =     949.51 ms /    13 runs   (   73.04 ms per token,    13.69 tokens per second)

llama_perf_context_print:       total time =    1453.88 ms /    77 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     389.95 ms /    43 tokens (    9.07 ms per token,   110.27 tokens per second)

llama_perf_context_print:        eval time =    1667.71 ms /    23 runs   (   72.51 ms per token,    13.79 tokens per second)

llama_perf_context_print:       total time =    2135.62 ms /    66 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     339.66 ms /    35 tokens (    9.70 ms per token,   103.05 tokens per second)

llama_perf_context_print:        eval time =    3021.68 ms /    42 runs   (   71.94 ms per token,    13.90 tokens per second)

llama_perf_context_print:       total time =    3497.20 ms /    77 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     399.29 ms /    39 tokens (   10.24 ms per token,    97.67 tokens per second)

llama_perf_context_print:        eval time =    9836.30 ms /   136 runs   (   72.33 ms per token,    13.83 tokens per second)

llama_perf_context_print:       total time =   10685.64 ms /   175 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     323.96 ms /    40 tokens (    8.10 ms per token,   123.47 tokens per second)

llama_perf_context_print:        eval time =   20545.28 ms /   282 runs   (   72.86 ms per token,    13.73 tokens per second)

llama_perf_context_print:       total time =   21838.92 ms /   322 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 403, 'total_tokens': 427}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 13, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 23, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 42, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 136, 'total_tokens': 179}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     413.06 ms /    57 tokens (    7.25 ms per token,   137.99 tokens per second)

llama_perf_context_print:        eval time =    1822.40 ms /    25 runs   (   72.90 ms per token,    13.72 tokens per second)

llama_perf_context_print:       total time =    2319.69 ms /    82 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     327.18 ms /    44 tokens (    7.44 ms per token,   134.48 tokens per second)

llama_perf_context_print:        eval time =    3497.01 ms /    49 runs   (   71.37 ms per token,    14.01 tokens per second)

llama_perf_context_print:       total time =    3982.03 ms /    93 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     366.93 ms /    41 tokens (    8.95 ms per token,   111.74 tokens per second)

llama_perf_context_print:        eval time =    8314.37 ms /   116 runs   (   71.68 ms per token,    13.95 tokens per second)

llama_perf_context_print:       total time =    9057.63 ms /   157 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     403.99 ms /    44 tokens (    9.18 ms per token,   108.91 tokens per second)

llama_perf_context_print:        eval time =    1512.18 ms /    21 runs   (   72.01 ms per token,    13.89 tokens per second)

llama_perf_context_print:       total time =    1986.96 ms /    65 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     342.59 ms /    45 tokens (    7.61 ms per token,   131.35 tokens per second)

llama_perf_context_print:        eval time =    9639.08 ms /   132 runs   (   73.02 ms per token,    13.69 tokens per second)

llama_perf_context_print:       total time =   10415.52 ms /   177 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 282, 'total_tokens': 326}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 25, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 49, 'total_tokens': 97}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 116, 'total_tokens': 161}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 21, 'total_tokens': 69}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     356.62 ms /    38 tokens (    9.38 ms per token,   106.56 tokens per second)

llama_perf_context_print:        eval time =    4298.33 ms /    60 runs   (   71.64 ms per token,    13.96 tokens per second)

llama_perf_context_print:       total time =    4849.87 ms /    98 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     445.67 ms /    61 tokens (    7.31 ms per token,   136.87 tokens per second)

llama_perf_context_print:        eval time =   35418.85 ms /   484 runs   (   73.18 ms per token,    13.67 tokens per second)

llama_perf_context_print:       total time =   37641.89 ms /   545 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     428.29 ms /    48 tokens (    8.92 ms per token,   112.07 tokens per second)

llama_perf_context_print:        eval time =   15447.96 ms /   213 runs   (   72.53 ms per token,    13.79 tokens per second)

llama_perf_context_print:       total time =   16601.56 ms /   261 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 132, 'total_tokens': 181}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 60, 'total_tokens': 102}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 484, 'total_tokens': 549}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     463.07 ms /    55 tokens (    8.42 ms per token,   118.77 tokens per second)

llama_perf_context_print:        eval time =   21224.40 ms /   290 runs   (   73.19 ms per token,    13.66 tokens per second)

llama_perf_context_print:       total time =   22671.88 ms /   345 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     574.59 ms /    79 tokens (    7.27 ms per token,   137.49 tokens per second)

llama_perf_context_print:        eval time =   52442.83 ms /   713 runs   (   73.55 ms per token,    13.60 tokens per second)

llama_perf_context_print:       total time =   55831.45 ms /   792 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 213, 'total_tokens': 265}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 290, 'total_tokens': 349}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     447.29 ms /    62 tokens (    7.21 ms per token,   138.61 tokens per second)

llama_perf_context_print:        eval time =   14610.47 ms /   202 runs   (   72.33 ms per token,    13.83 tokens per second)

llama_perf_context_print:       total time =   15738.65 ms /   264 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     460.18 ms /    63 tokens (    7.30 ms per token,   136.90 tokens per second)

llama_perf_context_print:        eval time =   21264.99 ms /   293 runs   (   72.58 ms per token,    13.78 tokens per second)

llama_perf_context_print:       total time =   22745.42 ms /   356 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     433.01 ms /    60 tokens (    7.22 ms per token,   138.56 tokens per second)

llama_perf_context_print:        eval time =   74277.85 ms /   999 runs   (   74.35 ms per token,    13.45 tokens per second)

llama_perf_context_print:       total time =   78917.99 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 713, 'total_tokens': 796}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 202, 'total_tokens': 268}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 293, 'total_tokens': 361}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     328.11 ms /    33 tokens (    9.94 ms per token,   100.58 tokens per second)

llama_perf_context_print:        eval time =    1366.55 ms /    19 runs   (   71.92 ms per token,    13.90 tokens per second)

llama_perf_context_print:       total time =    1758.88 ms /    52 tokens

llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     413.17 ms /    58 tokens (    7.12 ms per token,   140.38 tokens per second)

llama_perf_context_print:        eval time =   25020.89 ms /   344 runs   (   72.74 ms per token,    13.75 tokens per second)

llama_perf_context_print:       total time =   26641.21 ms /   402 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
llama_perf_context_print:        load time =     718.28 ms

llama_perf_context_print: prompt eval time =     713.86 ms /   111 tokens (    6.43 ms per token,   155.49 tokens per second)

llama_perf_context_print:        eval time =   37747.50 ms /   516 runs   (   73.15 ms per token,    13.67 tokens per second)

llama_perf_context_print:       total time =   40380.53 ms /   627 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 344, 'total_tokens': 406}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 516, 'total_tokens': 631}}
