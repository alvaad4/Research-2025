llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     641.31 ms /    10 tokens (   64.13 ms per token,    15.59 tokens per second)

llama_perf_context_print:        eval time =     882.35 ms /    11 runs   (   80.21 ms per token,    12.47 tokens per second)

llama_perf_context_print:       total time =    1549.37 ms /    21 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     378.51 ms /    15 tokens (   25.23 ms per token,    39.63 tokens per second)

llama_perf_context_print:        eval time =   34161.55 ms /   359 runs   (   95.16 ms per token,    10.51 tokens per second)

llama_perf_context_print:       total time =   35428.39 ms /   374 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     349.67 ms /    15 tokens (   23.31 ms per token,    42.90 tokens per second)

llama_perf_context_print:        eval time =   59052.03 ms /   725 runs   (   81.45 ms per token,    12.28 tokens per second)

llama_perf_context_print:       total time =   61418.04 ms /   740 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 10, 'completion_tokens': 11, 'total_tokens': 21}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 359, 'total_tokens': 376}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     340.75 ms /    22 tokens (   15.49 ms per token,    64.56 tokens per second)

llama_perf_context_print:        eval time =   20657.81 ms /   265 runs   (   77.95 ms per token,    12.83 tokens per second)

llama_perf_context_print:       total time =   21586.12 ms /   287 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     309.43 ms /    11 tokens (   28.13 ms per token,    35.55 tokens per second)

llama_perf_context_print:        eval time =   26992.49 ms /   339 runs   (   79.62 ms per token,    12.56 tokens per second)

llama_perf_context_print:       total time =   28072.65 ms /   350 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 725, 'total_tokens': 742}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 265, 'total_tokens': 289}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     316.16 ms /    10 tokens (   31.62 ms per token,    31.63 tokens per second)

llama_perf_context_print:        eval time =   35119.61 ms /   448 runs   (   78.39 ms per token,    12.76 tokens per second)

llama_perf_context_print:       total time =   36505.28 ms /   458 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     278.21 ms /    12 tokens (   23.18 ms per token,    43.13 tokens per second)

llama_perf_context_print:        eval time =   26257.10 ms /   335 runs   (   78.38 ms per token,    12.76 tokens per second)

llama_perf_context_print:       total time =   27306.48 ms /   347 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 339, 'total_tokens': 352}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 448, 'total_tokens': 460}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     280.96 ms /     9 tokens (   31.22 ms per token,    32.03 tokens per second)

llama_perf_context_print:        eval time =    9903.00 ms /   128 runs   (   77.37 ms per token,    12.93 tokens per second)

llama_perf_context_print:       total time =   10448.48 ms /   137 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     338.96 ms /    21 tokens (   16.14 ms per token,    61.95 tokens per second)

llama_perf_context_print:        eval time =   91855.21 ms /   999 runs   (   91.95 ms per token,    10.88 tokens per second)

llama_perf_context_print:       total time =   95125.63 ms /  1020 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 335, 'total_tokens': 349}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'completion_tokens': 128, 'total_tokens': 139}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     259.94 ms /    16 tokens (   16.25 ms per token,    61.55 tokens per second)

llama_perf_context_print:        eval time =   66255.35 ms /   826 runs   (   80.21 ms per token,    12.47 tokens per second)

llama_perf_context_print:       total time =   68848.44 ms /   842 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 1000, 'total_tokens': 1023}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     919.15 ms /    85 tokens (   10.81 ms per token,    92.48 tokens per second)

llama_perf_context_print:        eval time =   37470.58 ms /   459 runs   (   81.64 ms per token,    12.25 tokens per second)

llama_perf_context_print:       total time =   39517.59 ms /   544 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     480.64 ms /    35 tokens (   13.73 ms per token,    72.82 tokens per second)

llama_perf_context_print:        eval time =   61132.93 ms /   648 runs   (   94.34 ms per token,    10.60 tokens per second)

llama_perf_context_print:       total time =   63234.97 ms /   683 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 826, 'total_tokens': 844}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 459, 'total_tokens': 546}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     635.01 ms /    46 tokens (   13.80 ms per token,    72.44 tokens per second)

llama_perf_context_print:        eval time =   23789.96 ms /   296 runs   (   80.37 ms per token,    12.44 tokens per second)

llama_perf_context_print:       total time =   25091.96 ms /   342 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     612.16 ms /    53 tokens (   11.55 ms per token,    86.58 tokens per second)

llama_perf_context_print:        eval time =   30177.24 ms /   373 runs   (   80.90 ms per token,    12.36 tokens per second)

llama_perf_context_print:       total time =   31657.15 ms /   426 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     343.48 ms /    22 tokens (   15.61 ms per token,    64.05 tokens per second)

llama_perf_context_print:        eval time =   31484.71 ms /   392 runs   (   80.32 ms per token,    12.45 tokens per second)

llama_perf_context_print:       total time =   32758.97 ms /   414 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 648, 'total_tokens': 685}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 296, 'total_tokens': 344}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 373, 'total_tokens': 428}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     303.79 ms /    18 tokens (   16.88 ms per token,    59.25 tokens per second)

llama_perf_context_print:        eval time =     894.13 ms /    11 runs   (   81.28 ms per token,    12.30 tokens per second)

llama_perf_context_print:       total time =    1222.27 ms /    29 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     481.92 ms /    44 tokens (   10.95 ms per token,    91.30 tokens per second)

llama_perf_context_print:        eval time =   27537.45 ms /   341 runs   (   80.75 ms per token,    12.38 tokens per second)

llama_perf_context_print:       total time =   28806.95 ms /   385 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     584.89 ms /    53 tokens (   11.04 ms per token,    90.62 tokens per second)

llama_perf_context_print:        eval time =   21222.79 ms /   263 runs   (   80.70 ms per token,    12.39 tokens per second)

llama_perf_context_print:       total time =   22394.82 ms /   316 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 392, 'total_tokens': 416}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 11, 'total_tokens': 31}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 46, 'completion_tokens': 341, 'total_tokens': 387}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     620.46 ms /    60 tokens (   10.34 ms per token,    96.70 tokens per second)

llama_perf_context_print:        eval time =   90800.87 ms /   999 runs   (   90.89 ms per token,    11.00 tokens per second)

llama_perf_context_print:       total time =   94370.97 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 263, 'total_tokens': 321}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     950.60 ms /    97 tokens (    9.80 ms per token,   102.04 tokens per second)

llama_perf_context_print:        eval time =   41245.45 ms /   502 runs   (   82.16 ms per token,    12.17 tokens per second)

llama_perf_context_print:       total time =   43453.22 ms /   599 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     535.32 ms /    47 tokens (   11.39 ms per token,    87.80 tokens per second)

llama_perf_context_print:        eval time =   37576.28 ms /   461 runs   (   81.51 ms per token,    12.27 tokens per second)

llama_perf_context_print:       total time =   39222.45 ms /   508 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 1000, 'total_tokens': 1065}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 502, 'total_tokens': 601}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     529.00 ms /    49 tokens (   10.80 ms per token,    92.63 tokens per second)

llama_perf_context_print:        eval time =   35308.51 ms /   435 runs   (   81.17 ms per token,    12.32 tokens per second)

llama_perf_context_print:       total time =   36878.09 ms /   484 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     420.64 ms /    29 tokens (   14.50 ms per token,    68.94 tokens per second)

llama_perf_context_print:        eval time =   30822.14 ms /   382 runs   (   80.69 ms per token,    12.39 tokens per second)

llama_perf_context_print:       total time =   32139.11 ms /   411 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     516.38 ms /    42 tokens (   12.29 ms per token,    81.34 tokens per second)

llama_perf_context_print:        eval time =   38481.52 ms /   473 runs   (   81.36 ms per token,    12.29 tokens per second)

llama_perf_context_print:       total time =   40157.82 ms /   515 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 461, 'total_tokens': 510}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 435, 'total_tokens': 486}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 31, 'completion_tokens': 382, 'total_tokens': 413}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     712.01 ms /    70 tokens (   10.17 ms per token,    98.31 tokens per second)

llama_perf_context_print:        eval time =   71185.61 ms /   856 runs   (   83.16 ms per token,    12.02 tokens per second)

llama_perf_context_print:       total time =   74364.46 ms /   926 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 473, 'total_tokens': 517}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     445.95 ms /    40 tokens (   11.15 ms per token,    89.70 tokens per second)

llama_perf_context_print:        eval time =   27450.67 ms /   340 runs   (   80.74 ms per token,    12.39 tokens per second)

llama_perf_context_print:       total time =   28676.13 ms /   380 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     393.60 ms /    26 tokens (   15.14 ms per token,    66.06 tokens per second)

llama_perf_context_print:        eval time =   33257.49 ms /   412 runs   (   80.72 ms per token,    12.39 tokens per second)

llama_perf_context_print:       total time =   34634.69 ms /   438 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     514.61 ms /    39 tokens (   13.20 ms per token,    75.79 tokens per second)

llama_perf_context_print:        eval time =   36671.48 ms /   453 runs   (   80.95 ms per token,    12.35 tokens per second)

llama_perf_context_print:       total time =   38275.22 ms /   492 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 856, 'total_tokens': 928}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 340, 'total_tokens': 382}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 412, 'total_tokens': 440}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     439.70 ms /    30 tokens (   14.66 ms per token,    68.23 tokens per second)

llama_perf_context_print:        eval time =   29841.03 ms /   371 runs   (   80.43 ms per token,    12.43 tokens per second)

llama_perf_context_print:       total time =   31141.15 ms /   401 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     338.23 ms /    24 tokens (   14.09 ms per token,    70.96 tokens per second)

llama_perf_context_print:        eval time =   27946.27 ms /   349 runs   (   80.08 ms per token,    12.49 tokens per second)

llama_perf_context_print:       total time =   29073.94 ms /   373 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     317.87 ms /    17 tokens (   18.70 ms per token,    53.48 tokens per second)

llama_perf_context_print:        eval time =   43746.50 ms /   538 runs   (   81.31 ms per token,    12.30 tokens per second)

llama_perf_context_print:       total time =   45405.79 ms /   555 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 453, 'total_tokens': 494}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 32, 'completion_tokens': 371, 'total_tokens': 403}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 349, 'total_tokens': 375}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     377.53 ms /    23 tokens (   16.41 ms per token,    60.92 tokens per second)

llama_perf_context_print:        eval time =   46944.05 ms /   578 runs   (   81.22 ms per token,    12.31 tokens per second)

llama_perf_context_print:       total time =   48784.11 ms /   601 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     435.06 ms /    29 tokens (   15.00 ms per token,    66.66 tokens per second)

llama_perf_context_print:        eval time =   26897.42 ms /   333 runs   (   80.77 ms per token,    12.38 tokens per second)

llama_perf_context_print:       total time =   28090.84 ms /   362 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 538, 'total_tokens': 558}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 25, 'completion_tokens': 578, 'total_tokens': 603}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     340.56 ms /    14 tokens (   24.33 ms per token,    41.11 tokens per second)

llama_perf_context_print:        eval time =    6441.39 ms /    81 runs   (   79.52 ms per token,    12.57 tokens per second)

llama_perf_context_print:       total time =    6943.03 ms /    95 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     295.41 ms /    10 tokens (   29.54 ms per token,    33.85 tokens per second)

llama_perf_context_print:        eval time =   51630.89 ms /   634 runs   (   81.44 ms per token,    12.28 tokens per second)

llama_perf_context_print:       total time =   53593.36 ms /   644 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 31, 'completion_tokens': 333, 'total_tokens': 364}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 81, 'total_tokens': 97}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     327.22 ms /    13 tokens (   25.17 ms per token,    39.73 tokens per second)

llama_perf_context_print:        eval time =   83337.07 ms /   999 runs   (   83.42 ms per token,    11.99 tokens per second)

llama_perf_context_print:       total time =   86708.30 ms /  1012 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 634, 'total_tokens': 646}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     312.44 ms /    11 tokens (   28.40 ms per token,    35.21 tokens per second)

llama_perf_context_print:        eval time =   18702.34 ms /   234 runs   (   79.92 ms per token,    12.51 tokens per second)

llama_perf_context_print:       total time =   19521.56 ms /   245 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     286.72 ms /    17 tokens (   16.87 ms per token,    59.29 tokens per second)

llama_perf_context_print:        eval time =   62328.31 ms /   709 runs   (   87.91 ms per token,    11.38 tokens per second)

llama_perf_context_print:       total time =   64497.25 ms /   726 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 15, 'completion_tokens': 1000, 'total_tokens': 1015}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 234, 'total_tokens': 247}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     285.91 ms /    12 tokens (   23.83 ms per token,    41.97 tokens per second)

llama_perf_context_print:        eval time =   30253.70 ms /   376 runs   (   80.46 ms per token,    12.43 tokens per second)

llama_perf_context_print:       total time =   31425.42 ms /   388 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     402.62 ms /    32 tokens (   12.58 ms per token,    79.48 tokens per second)

llama_perf_context_print:        eval time =   19430.32 ms /   241 runs   (   80.62 ms per token,    12.40 tokens per second)

llama_perf_context_print:       total time =   20356.00 ms /   273 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     850.70 ms /    88 tokens (    9.67 ms per token,   103.44 tokens per second)

llama_perf_context_print:        eval time =   34052.98 ms /   376 runs   (   90.57 ms per token,    11.04 tokens per second)

llama_perf_context_print:       total time =   35753.08 ms /   464 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 709, 'total_tokens': 728}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 376, 'total_tokens': 390}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 34, 'completion_tokens': 241, 'total_tokens': 275}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     982.17 ms /   107 tokens (    9.18 ms per token,   108.94 tokens per second)

llama_perf_context_print:        eval time =   40729.14 ms /   496 runs   (   82.12 ms per token,    12.18 tokens per second)

llama_perf_context_print:       total time =   42951.92 ms /   603 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 376, 'total_tokens': 466}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =    1125.08 ms /   128 tokens (    8.79 ms per token,   113.77 tokens per second)

llama_perf_context_print:        eval time =   39652.48 ms /   485 runs   (   81.76 ms per token,    12.23 tokens per second)

llama_perf_context_print:       total time =   41965.91 ms /   613 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =    1014.64 ms /   113 tokens (    8.98 ms per token,   111.37 tokens per second)

llama_perf_context_print:        eval time =   31202.81 ms /   372 runs   (   83.88 ms per token,    11.92 tokens per second)

llama_perf_context_print:       total time =   33086.41 ms /   485 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 109, 'completion_tokens': 496, 'total_tokens': 605}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 130, 'completion_tokens': 485, 'total_tokens': 615}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     707.89 ms /    71 tokens (    9.97 ms per token,   100.30 tokens per second)

llama_perf_context_print:        eval time =   53094.93 ms /   647 runs   (   82.06 ms per token,    12.19 tokens per second)

llama_perf_context_print:       total time =   55535.08 ms /   718 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =    1186.82 ms /   131 tokens (    9.06 ms per token,   110.38 tokens per second)

llama_perf_context_print:        eval time =   32535.11 ms /   397 runs   (   81.95 ms per token,    12.20 tokens per second)

llama_perf_context_print:       total time =   34677.68 ms /   528 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 372, 'total_tokens': 487}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 647, 'total_tokens': 720}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     910.91 ms /   100 tokens (    9.11 ms per token,   109.78 tokens per second)

llama_perf_context_print:        eval time =   55849.15 ms /   674 runs   (   82.86 ms per token,    12.07 tokens per second)

llama_perf_context_print:       total time =   58586.10 ms /   774 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 133, 'completion_tokens': 397, 'total_tokens': 530}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     341.99 ms /    22 tokens (   15.54 ms per token,    64.33 tokens per second)

llama_perf_context_print:        eval time =   54763.16 ms /   649 runs   (   84.38 ms per token,    11.85 tokens per second)

llama_perf_context_print:       total time =   56824.36 ms /   671 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     641.61 ms /    58 tokens (   11.06 ms per token,    90.40 tokens per second)

llama_perf_context_print:        eval time =   29798.51 ms /   367 runs   (   81.19 ms per token,    12.32 tokens per second)

llama_perf_context_print:       total time =   31303.20 ms /   425 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 674, 'total_tokens': 776}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 649, 'total_tokens': 673}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     266.56 ms /    16 tokens (   16.66 ms per token,    60.02 tokens per second)

llama_perf_context_print:        eval time =   40355.52 ms /   497 runs   (   81.20 ms per token,    12.32 tokens per second)

llama_perf_context_print:       total time =   41877.73 ms /   513 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     455.47 ms /    37 tokens (   12.31 ms per token,    81.23 tokens per second)

llama_perf_context_print:        eval time =   42294.47 ms /   518 runs   (   81.65 ms per token,    12.25 tokens per second)

llama_perf_context_print:       total time =   44056.76 ms /   555 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 367, 'total_tokens': 427}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 497, 'total_tokens': 515}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     594.56 ms /    56 tokens (   10.62 ms per token,    94.19 tokens per second)

llama_perf_context_print:        eval time =   27293.78 ms /   338 runs   (   80.75 ms per token,    12.38 tokens per second)

llama_perf_context_print:       total time =   28669.88 ms /   394 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     552.85 ms /    49 tokens (   11.28 ms per token,    88.63 tokens per second)

llama_perf_context_print:        eval time =   41345.04 ms /   507 runs   (   81.55 ms per token,    12.26 tokens per second)

llama_perf_context_print:       total time =   43171.01 ms /   556 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 518, 'total_tokens': 557}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 338, 'total_tokens': 396}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     698.23 ms /    73 tokens (    9.56 ms per token,   104.55 tokens per second)

llama_perf_context_print:        eval time =   41459.01 ms /   507 runs   (   81.77 ms per token,    12.23 tokens per second)

llama_perf_context_print:       total time =   43451.92 ms /   580 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 507, 'total_tokens': 558}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     659.35 ms /    66 tokens (    9.99 ms per token,   100.10 tokens per second)

llama_perf_context_print:        eval time =   23415.28 ms /   289 runs   (   81.02 ms per token,    12.34 tokens per second)

llama_perf_context_print:       total time =   24729.92 ms /   355 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     665.39 ms /    55 tokens (   12.10 ms per token,    82.66 tokens per second)

llama_perf_context_print:        eval time =   20701.94 ms /   257 runs   (   80.55 ms per token,    12.41 tokens per second)

llama_perf_context_print:       total time =   21941.65 ms /   312 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     520.99 ms /    46 tokens (   11.33 ms per token,    88.29 tokens per second)

llama_perf_context_print:        eval time =   39635.74 ms /   487 runs   (   81.39 ms per token,    12.29 tokens per second)

llama_perf_context_print:       total time =   41373.83 ms /   533 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 507, 'total_tokens': 582}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 289, 'total_tokens': 357}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 257, 'total_tokens': 314}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     553.13 ms /    51 tokens (   10.85 ms per token,    92.20 tokens per second)

llama_perf_context_print:        eval time =   34397.08 ms /   424 runs   (   81.13 ms per token,    12.33 tokens per second)

llama_perf_context_print:       total time =   35979.48 ms /   475 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     506.65 ms /    41 tokens (   12.36 ms per token,    80.92 tokens per second)

llama_perf_context_print:        eval time =   17316.73 ms /   217 runs   (   79.80 ms per token,    12.53 tokens per second)

llama_perf_context_print:       total time =   18298.06 ms /   258 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 487, 'total_tokens': 535}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 424, 'total_tokens': 477}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     740.86 ms /    62 tokens (   11.95 ms per token,    83.69 tokens per second)

llama_perf_context_print:        eval time =   23793.38 ms /   296 runs   (   80.38 ms per token,    12.44 tokens per second)

llama_perf_context_print:       total time =   25197.99 ms /   358 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     282.07 ms /     9 tokens (   31.34 ms per token,    31.91 tokens per second)

llama_perf_context_print:        eval time =   33354.95 ms /   414 runs   (   80.57 ms per token,    12.41 tokens per second)

llama_perf_context_print:       total time =   34641.19 ms /   423 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 217, 'total_tokens': 260}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 296, 'total_tokens': 360}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     664.56 ms /    51 tokens (   13.03 ms per token,    76.74 tokens per second)

llama_perf_context_print:        eval time =   40618.45 ms /   497 runs   (   81.73 ms per token,    12.24 tokens per second)

llama_perf_context_print:       total time =   42523.73 ms /   548 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     307.35 ms /    11 tokens (   27.94 ms per token,    35.79 tokens per second)

llama_perf_context_print:        eval time =   42824.61 ms /   526 runs   (   81.42 ms per token,    12.28 tokens per second)

llama_perf_context_print:       total time =   44468.80 ms /   537 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'completion_tokens': 414, 'total_tokens': 425}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 497, 'total_tokens': 550}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     586.34 ms /    45 tokens (   13.03 ms per token,    76.75 tokens per second)

llama_perf_context_print:        eval time =   53862.99 ms /   654 runs   (   82.36 ms per token,    12.14 tokens per second)

llama_perf_context_print:       total time =   56216.48 ms /   699 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     385.95 ms /    15 tokens (   25.73 ms per token,    38.87 tokens per second)

llama_perf_context_print:        eval time =   83241.38 ms /   999 runs   (   83.32 ms per token,    12.00 tokens per second)

llama_perf_context_print:       total time =   86753.22 ms /  1014 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 526, 'total_tokens': 539}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 654, 'total_tokens': 701}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     542.79 ms /    43 tokens (   12.62 ms per token,    79.22 tokens per second)

llama_perf_context_print:        eval time =   24034.60 ms /   298 runs   (   80.65 ms per token,    12.40 tokens per second)

llama_perf_context_print:       total time =   25277.09 ms /   341 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 1000, 'total_tokens': 1017}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     351.20 ms /    11 tokens (   31.93 ms per token,    31.32 tokens per second)

llama_perf_context_print:        eval time =   44955.13 ms /   551 runs   (   81.59 ms per token,    12.26 tokens per second)

llama_perf_context_print:       total time =   46766.78 ms /   562 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     742.05 ms /    70 tokens (   10.60 ms per token,    94.33 tokens per second)

llama_perf_context_print:        eval time =   83852.06 ms /   999 runs   (   83.94 ms per token,    11.91 tokens per second)

llama_perf_context_print:       total time =   87656.23 ms /  1069 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 298, 'total_tokens': 343}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 551, 'total_tokens': 564}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     326.64 ms /    14 tokens (   23.33 ms per token,    42.86 tokens per second)

llama_perf_context_print:        eval time =   52071.51 ms /   638 runs   (   81.62 ms per token,    12.25 tokens per second)

llama_perf_context_print:       total time =   54139.45 ms /   652 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     623.27 ms /    58 tokens (   10.75 ms per token,    93.06 tokens per second)

llama_perf_context_print:        eval time =   25200.25 ms /   312 runs   (   80.77 ms per token,    12.38 tokens per second)

llama_perf_context_print:       total time =   26559.20 ms /   370 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     504.05 ms /    38 tokens (   13.26 ms per token,    75.39 tokens per second)

llama_perf_context_print:        eval time =   26874.01 ms /   335 runs   (   80.22 ms per token,    12.47 tokens per second)

llama_perf_context_print:       total time =   28174.14 ms /   373 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 1000, 'total_tokens': 1072}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 312, 'total_tokens': 372}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     453.98 ms /    31 tokens (   14.64 ms per token,    68.29 tokens per second)

llama_perf_context_print:        eval time =   23928.64 ms /   288 runs   (   83.09 ms per token,    12.04 tokens per second)

llama_perf_context_print:       total time =   25052.23 ms /   319 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     409.77 ms /    34 tokens (   12.05 ms per token,    82.97 tokens per second)

llama_perf_context_print:        eval time =   46795.58 ms /   572 runs   (   81.81 ms per token,    12.22 tokens per second)

llama_perf_context_print:       total time =   48764.51 ms /   606 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 40, 'completion_tokens': 335, 'total_tokens': 375}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 288, 'total_tokens': 321}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     477.19 ms /    37 tokens (   12.90 ms per token,    77.54 tokens per second)

llama_perf_context_print:        eval time =   40602.44 ms /   499 runs   (   81.37 ms per token,    12.29 tokens per second)

llama_perf_context_print:       total time =   42373.41 ms /   536 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 36, 'completion_tokens': 572, 'total_tokens': 608}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     586.61 ms /    53 tokens (   11.07 ms per token,    90.35 tokens per second)

llama_perf_context_print:        eval time =   28157.47 ms /   350 runs   (   80.45 ms per token,    12.43 tokens per second)

llama_perf_context_print:       total time =   29562.48 ms /   403 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     493.97 ms /    39 tokens (   12.67 ms per token,    78.95 tokens per second)

llama_perf_context_print:        eval time =   30462.11 ms /   376 runs   (   81.02 ms per token,    12.34 tokens per second)

llama_perf_context_print:       total time =   31855.86 ms /   415 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 499, 'total_tokens': 538}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 350, 'total_tokens': 405}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     471.52 ms /    38 tokens (   12.41 ms per token,    80.59 tokens per second)

llama_perf_context_print:        eval time =   27737.80 ms /   335 runs   (   82.80 ms per token,    12.08 tokens per second)

llama_perf_context_print:       total time =   28993.61 ms /   373 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     545.82 ms /    39 tokens (   14.00 ms per token,    71.45 tokens per second)

llama_perf_context_print:        eval time =   24050.96 ms /   300 runs   (   80.17 ms per token,    12.47 tokens per second)

llama_perf_context_print:       total time =   25297.36 ms /   339 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     490.35 ms /    39 tokens (   12.57 ms per token,    79.54 tokens per second)

llama_perf_context_print:        eval time =   24219.49 ms /   303 runs   (   79.93 ms per token,    12.51 tokens per second)

llama_perf_context_print:       total time =   25404.12 ms /   342 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 376, 'total_tokens': 417}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 40, 'completion_tokens': 335, 'total_tokens': 375}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 300, 'total_tokens': 341}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     401.54 ms /    33 tokens (   12.17 ms per token,    82.18 tokens per second)

llama_perf_context_print:        eval time =   40144.66 ms /   493 runs   (   81.43 ms per token,    12.28 tokens per second)

llama_perf_context_print:       total time =   41794.74 ms /   526 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     528.41 ms /    46 tokens (   11.49 ms per token,    87.05 tokens per second)

llama_perf_context_print:        eval time =   44095.84 ms /   542 runs   (   81.36 ms per token,    12.29 tokens per second)

llama_perf_context_print:       total time =   46035.57 ms /   588 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 303, 'total_tokens': 344}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 493, 'total_tokens': 528}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     425.10 ms /    33 tokens (   12.88 ms per token,    77.63 tokens per second)

llama_perf_context_print:        eval time =   47542.19 ms /   582 runs   (   81.69 ms per token,    12.24 tokens per second)

llama_perf_context_print:       total time =   49504.94 ms /   615 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 542, 'total_tokens': 590}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     473.49 ms /    40 tokens (   11.84 ms per token,    84.48 tokens per second)

llama_perf_context_print:        eval time =   32241.31 ms /   398 runs   (   81.01 ms per token,    12.34 tokens per second)

llama_perf_context_print:       total time =   33689.64 ms /   438 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     645.24 ms /    65 tokens (    9.93 ms per token,   100.74 tokens per second)

llama_perf_context_print:        eval time =   83694.88 ms /   999 runs   (   83.78 ms per token,    11.94 tokens per second)

llama_perf_context_print:       total time =   87473.16 ms /  1064 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 582, 'total_tokens': 617}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 398, 'total_tokens': 440}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     543.09 ms /    47 tokens (   11.56 ms per token,    86.54 tokens per second)

llama_perf_context_print:        eval time =   51882.41 ms /   632 runs   (   82.09 ms per token,    12.18 tokens per second)

llama_perf_context_print:       total time =   54138.62 ms /   679 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 67, 'completion_tokens': 1000, 'total_tokens': 1067}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     533.44 ms /    47 tokens (   11.35 ms per token,    88.11 tokens per second)

llama_perf_context_print:        eval time =   47081.53 ms /   577 runs   (   81.60 ms per token,    12.26 tokens per second)

llama_perf_context_print:       total time =   49137.92 ms /   624 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     509.28 ms /    45 tokens (   11.32 ms per token,    88.36 tokens per second)

llama_perf_context_print:        eval time =   83291.00 ms /   999 runs   (   83.37 ms per token,    11.99 tokens per second)

llama_perf_context_print:       total time =   86920.57 ms /  1044 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 632, 'total_tokens': 681}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     325.50 ms /    18 tokens (   18.08 ms per token,    55.30 tokens per second)

llama_perf_context_print:        eval time =   14867.75 ms /   187 runs   (   79.51 ms per token,    12.58 tokens per second)

llama_perf_context_print:       total time =   15604.14 ms /   205 tokens

llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =     495.36 ms /    44 tokens (   11.26 ms per token,    88.83 tokens per second)

llama_perf_context_print:        eval time =   67240.66 ms /   813 runs   (   82.71 ms per token,    12.09 tokens per second)

llama_perf_context_print:       total time =   70144.46 ms /   857 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 1000, 'total_tokens': 1047}}
llama_perf_context_print:        load time =     641.89 ms

llama_perf_context_print: prompt eval time =    1022.41 ms /    96 tokens (   10.65 ms per token,    93.90 tokens per second)

llama_perf_context_print:        eval time =   25997.99 ms /   318 runs   (   81.75 ms per token,    12.23 tokens per second)

llama_perf_context_print:       total time =   27786.39 ms /   414 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 46, 'completion_tokens': 813, 'total_tokens': 859}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 98, 'completion_tokens': 318, 'total_tokens': 416}}
