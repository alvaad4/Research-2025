llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1134.62 ms /    17 tokens (   66.74 ms per token,    14.98 tokens per second)

llama_perf_context_print:        eval time =    4731.75 ms /    34 runs   (  139.17 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =    5992.96 ms /    51 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     553.53 ms /    20 tokens (   27.68 ms per token,    36.13 tokens per second)

llama_perf_context_print:        eval time =   18136.22 ms /   132 runs   (  137.40 ms per token,     7.28 tokens per second)

llama_perf_context_print:       total time =   19180.38 ms /   152 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     563.10 ms /    20 tokens (   28.16 ms per token,    35.52 tokens per second)

llama_perf_context_print:        eval time =   24118.20 ms /   174 runs   (  138.61 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =   25335.09 ms /   194 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     707.55 ms /    26 tokens (   27.21 ms per token,    36.75 tokens per second)

llama_perf_context_print:        eval time =    4590.26 ms /    33 runs   (  139.10 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =    5420.52 ms /    59 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     458.33 ms /    16 tokens (   28.65 ms per token,    34.91 tokens per second)

llama_perf_context_print:        eval time =   15714.44 ms /   115 runs   (  136.65 ms per token,     7.32 tokens per second)

llama_perf_context_print:       total time =   16598.17 ms /   131 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 34, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 132, 'total_tokens': 156}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 174, 'total_tokens': 198}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 33, 'total_tokens': 63}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     585.23 ms /    14 tokens (   41.80 ms per token,    23.92 tokens per second)

llama_perf_context_print:        eval time =   15307.07 ms /   111 runs   (  137.90 ms per token,     7.25 tokens per second)

llama_perf_context_print:       total time =   16311.40 ms /   125 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     536.41 ms /    17 tokens (   31.55 ms per token,    31.69 tokens per second)

llama_perf_context_print:        eval time =    3052.11 ms /    22 runs   (  138.73 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =    3673.18 ms /    39 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     559.10 ms /    14 tokens (   39.94 ms per token,    25.04 tokens per second)

llama_perf_context_print:        eval time =    3373.89 ms /    24 runs   (  140.58 ms per token,     7.11 tokens per second)

llama_perf_context_print:       total time =    4024.46 ms /    38 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     645.62 ms /    24 tokens (   26.90 ms per token,    37.17 tokens per second)

llama_perf_context_print:        eval time =   14993.39 ms /   109 runs   (  137.55 ms per token,     7.27 tokens per second)

llama_perf_context_print:       total time =   16036.94 ms /   133 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     543.98 ms /    20 tokens (   27.20 ms per token,    36.77 tokens per second)

llama_perf_context_print:        eval time =   11051.89 ms /    80 runs   (  138.15 ms per token,     7.24 tokens per second)

llama_perf_context_print:       total time =   11884.75 ms /   100 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1808.12 ms /    93 tokens (   19.44 ms per token,    51.43 tokens per second)

llama_perf_context_print:        eval time =    3936.34 ms /    28 runs   (  140.58 ms per token,     7.11 tokens per second)

llama_perf_context_print:       total time =    5851.26 ms /   121 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     871.18 ms /    38 tokens (   22.93 ms per token,    43.62 tokens per second)

llama_perf_context_print:        eval time =    1829.78 ms /    13 runs   (  140.75 ms per token,     7.10 tokens per second)

llama_perf_context_print:       total time =    2754.38 ms /    51 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1047.00 ms /    47 tokens (   22.28 ms per token,    44.89 tokens per second)

llama_perf_context_print:        eval time =     203.57 ms /     1 runs   (  203.57 ms per token,     4.91 tokens per second)

llama_perf_context_print:       total time =    1260.73 ms /    48 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 115, 'total_tokens': 135}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 111, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 22, 'total_tokens': 43}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 24, 'total_tokens': 42}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 109, 'total_tokens': 137}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 80, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 28, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 13, 'total_tokens': 55}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1193.65 ms /    55 tokens (   21.70 ms per token,    46.08 tokens per second)

llama_perf_context_print:        eval time =     884.94 ms /     6 runs   (  147.49 ms per token,     6.78 tokens per second)

llama_perf_context_print:       total time =    2105.96 ms /    61 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     685.56 ms /    25 tokens (   27.42 ms per token,    36.47 tokens per second)

llama_perf_context_print:        eval time =   10198.19 ms /    74 runs   (  137.81 ms per token,     7.26 tokens per second)

llama_perf_context_print:       total time =   11156.22 ms /    99 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     633.13 ms /    23 tokens (   27.53 ms per token,    36.33 tokens per second)

llama_perf_context_print:        eval time =     880.78 ms /     6 runs   (  146.80 ms per token,     6.81 tokens per second)

llama_perf_context_print:       total time =    1540.23 ms /    29 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1021.54 ms /    50 tokens (   20.43 ms per token,    48.95 tokens per second)

llama_perf_context_print:        eval time =     890.34 ms /     6 runs   (  148.39 ms per token,     6.74 tokens per second)

llama_perf_context_print:       total time =    1939.39 ms /    56 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1087.08 ms /    56 tokens (   19.41 ms per token,    51.51 tokens per second)

llama_perf_context_print:        eval time =    1454.23 ms /    10 runs   (  145.42 ms per token,     6.88 tokens per second)

llama_perf_context_print:       total time =    2582.06 ms /    66 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1340.87 ms /    68 tokens (   19.72 ms per token,    50.71 tokens per second)

llama_perf_context_print:        eval time =    1165.64 ms /     8 runs   (  145.70 ms per token,     6.86 tokens per second)

llama_perf_context_print:       total time =    2540.83 ms /    76 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1937.90 ms /   102 tokens (   19.00 ms per token,    52.63 tokens per second)

llama_perf_context_print:        eval time =    2676.47 ms /    19 runs   (  140.87 ms per token,     7.10 tokens per second)

llama_perf_context_print:       total time =    4688.23 ms /   121 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1130.85 ms /    53 tokens (   21.34 ms per token,    46.87 tokens per second)

llama_perf_context_print:        eval time =   27610.64 ms /   198 runs   (  139.45 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =   29465.11 ms /   251 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 1, 'total_tokens': 52}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 74, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 6, 'total_tokens': 33}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 6, 'total_tokens': 60}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 10, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 8, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 19, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 198, 'total_tokens': 255}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1403.94 ms /    54 tokens (   26.00 ms per token,    38.46 tokens per second)

llama_perf_context_print:        eval time =   25708.18 ms /   165 runs   (  155.81 ms per token,     6.42 tokens per second)

llama_perf_context_print:       total time =   27716.14 ms /   219 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     910.75 ms /    34 tokens (   26.79 ms per token,    37.33 tokens per second)

llama_perf_context_print:        eval time =   19739.90 ms /   143 runs   (  138.04 ms per token,     7.24 tokens per second)

llama_perf_context_print:       total time =   21142.42 ms /   177 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1042.95 ms /    47 tokens (   22.19 ms per token,    45.06 tokens per second)

llama_perf_context_print:        eval time =   46766.99 ms /   336 runs   (  139.19 ms per token,     7.18 tokens per second)

llama_perf_context_print:       total time =   49000.67 ms /   383 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1604.87 ms /    75 tokens (   21.40 ms per token,    46.73 tokens per second)

llama_perf_context_print:        eval time =   67738.15 ms /   409 runs   (  165.62 ms per token,     6.04 tokens per second)

llama_perf_context_print:       total time =   70838.93 ms /   484 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 165, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 143, 'total_tokens': 181}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 336, 'total_tokens': 387}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     976.11 ms /    45 tokens (   21.69 ms per token,    46.10 tokens per second)

llama_perf_context_print:        eval time =   18250.40 ms /   122 runs   (  149.59 ms per token,     6.68 tokens per second)

llama_perf_context_print:       total time =   19655.82 ms /   167 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     826.91 ms /    31 tokens (   26.67 ms per token,    37.49 tokens per second)

llama_perf_context_print:        eval time =   19645.70 ms /   128 runs   (  153.48 ms per token,     6.52 tokens per second)

llama_perf_context_print:       total time =   20918.24 ms /   159 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     949.03 ms /    44 tokens (   21.57 ms per token,    46.36 tokens per second)

llama_perf_context_print:        eval time =   17678.98 ms /   128 runs   (  138.12 ms per token,     7.24 tokens per second)

llama_perf_context_print:       total time =   19075.55 ms /   172 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     862.51 ms /    35 tokens (   24.64 ms per token,    40.58 tokens per second)

llama_perf_context_print:        eval time =   36840.93 ms /   265 runs   (  139.02 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =   38637.95 ms /   300 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 409, 'total_tokens': 488}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 122, 'total_tokens': 171}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 128, 'total_tokens': 163}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 128, 'total_tokens': 176}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     766.95 ms /    29 tokens (   26.45 ms per token,    37.81 tokens per second)

llama_perf_context_print:        eval time =   56995.15 ms /   384 runs   (  148.42 ms per token,     6.74 tokens per second)

llama_perf_context_print:       total time =   59116.56 ms /   413 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     612.79 ms /    22 tokens (   27.85 ms per token,    35.90 tokens per second)

llama_perf_context_print:        eval time =    2930.18 ms /    21 runs   (  139.53 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    3612.60 ms /    43 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     715.57 ms /    29 tokens (   24.67 ms per token,    40.53 tokens per second)

llama_perf_context_print:        eval time =   64574.51 ms /   461 runs   (  140.07 ms per token,     7.14 tokens per second)

llama_perf_context_print:       total time =   66959.43 ms /   490 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     783.41 ms /    35 tokens (   22.38 ms per token,    44.68 tokens per second)

llama_perf_context_print:        eval time =   17720.48 ms /   128 runs   (  138.44 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   18920.93 ms /   163 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     539.68 ms /    19 tokens (   28.40 ms per token,    35.21 tokens per second)

llama_perf_context_print:        eval time =   31128.26 ms /   200 runs   (  155.64 ms per token,     6.43 tokens per second)

llama_perf_context_print:       total time =   32331.36 ms /   219 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 265, 'total_tokens': 304}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 384, 'total_tokens': 417}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 21, 'total_tokens': 48}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 461, 'total_tokens': 494}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 128, 'total_tokens': 167}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     655.93 ms /    15 tokens (   43.73 ms per token,    22.87 tokens per second)

llama_perf_context_print:        eval time =   21885.47 ms /   158 runs   (  138.52 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   23092.54 ms /   173 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     507.31 ms /    17 tokens (   29.84 ms per token,    33.51 tokens per second)

llama_perf_context_print:        eval time =  160245.27 ms /   999 runs   (  160.41 ms per token,     6.23 tokens per second)

llama_perf_context_print:       total time =  164928.54 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 200, 'total_tokens': 223}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 158, 'total_tokens': 177}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     446.15 ms /    16 tokens (   27.88 ms per token,    35.86 tokens per second)

llama_perf_context_print:        eval time =    4296.92 ms /    31 runs   (  138.61 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =    4847.14 ms /    47 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     580.31 ms /    22 tokens (   26.38 ms per token,    37.91 tokens per second)

llama_perf_context_print:        eval time =    3143.04 ms /    22 runs   (  142.87 ms per token,     7.00 tokens per second)

llama_perf_context_print:       total time =    3797.99 ms /    44 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     519.61 ms /    17 tokens (   30.57 ms per token,    32.72 tokens per second)

llama_perf_context_print:        eval time =  164143.02 ms /   999 runs   (  164.31 ms per token,     6.09 tokens per second)

llama_perf_context_print:       total time =  169196.18 ms /  1016 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 22, 'total_tokens': 48}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     824.57 ms /    37 tokens (   22.29 ms per token,    44.87 tokens per second)

llama_perf_context_print:        eval time =   11478.50 ms /    83 runs   (  138.30 ms per token,     7.23 tokens per second)

llama_perf_context_print:       total time =   12613.94 ms /   120 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1775.26 ms /    90 tokens (   19.73 ms per token,    50.70 tokens per second)

llama_perf_context_print:        eval time =    4603.91 ms /    33 runs   (  139.51 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    6508.38 ms /   123 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    2080.84 ms /   114 tokens (   18.25 ms per token,    54.79 tokens per second)

llama_perf_context_print:        eval time =   10106.47 ms /    73 runs   (  138.44 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   12456.92 ms /   187 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    2497.10 ms /   131 tokens (   19.06 ms per token,    52.46 tokens per second)

llama_perf_context_print:        eval time =    6141.16 ms /    44 runs   (  139.57 ms per token,     7.16 tokens per second)

llama_perf_context_print:       total time =    8803.12 ms /   175 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    2215.66 ms /   119 tokens (   18.62 ms per token,    53.71 tokens per second)

llama_perf_context_print:        eval time =   13660.15 ms /    98 runs   (  139.39 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =   16241.01 ms /   217 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 83, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 33, 'total_tokens': 127}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 73, 'total_tokens': 191}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 44, 'total_tokens': 179}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 98, 'total_tokens': 221}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1628.44 ms /    76 tokens (   21.43 ms per token,    46.67 tokens per second)

llama_perf_context_print:        eval time =    2266.09 ms /    16 runs   (  141.63 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =    3957.15 ms /    92 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    2357.66 ms /   129 tokens (   18.28 ms per token,    54.72 tokens per second)

llama_perf_context_print:        eval time =   22368.45 ms /   161 runs   (  138.93 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =   25313.47 ms /   290 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1913.45 ms /   104 tokens (   18.40 ms per token,    54.35 tokens per second)

llama_perf_context_print:        eval time =    9716.51 ms /    70 runs   (  138.81 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =   11879.43 ms /   174 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     617.60 ms /    24 tokens (   25.73 ms per token,    38.86 tokens per second)

llama_perf_context_print:        eval time =   12705.87 ms /    92 runs   (  138.11 ms per token,     7.24 tokens per second)

llama_perf_context_print:       total time =   13655.78 ms /   116 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1308.11 ms /    66 tokens (   19.82 ms per token,    50.45 tokens per second)

llama_perf_context_print:        eval time =    9549.00 ms /    69 runs   (  138.39 ms per token,     7.23 tokens per second)

llama_perf_context_print:       total time =   11106.66 ms /   135 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 16, 'total_tokens': 96}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 133, 'completion_tokens': 161, 'total_tokens': 294}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 70, 'total_tokens': 178}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 92, 'total_tokens': 120}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     569.02 ms /    19 tokens (   29.95 ms per token,    33.39 tokens per second)

llama_perf_context_print:        eval time =    5958.14 ms /    43 runs   (  138.56 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =    6689.53 ms /    62 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1052.88 ms /    41 tokens (   25.68 ms per token,    38.94 tokens per second)

llama_perf_context_print:        eval time =    5038.41 ms /    36 runs   (  139.96 ms per token,     7.15 tokens per second)

llama_perf_context_print:       total time =    6228.50 ms /    77 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1453.68 ms /    59 tokens (   24.64 ms per token,    40.59 tokens per second)

llama_perf_context_print:        eval time =    7023.15 ms /    49 runs   (  143.33 ms per token,     6.98 tokens per second)

llama_perf_context_print:       total time =    8797.68 ms /   108 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1331.28 ms /    55 tokens (   24.21 ms per token,    41.31 tokens per second)

llama_perf_context_print:        eval time =    5840.75 ms /    42 runs   (  139.07 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =    7309.64 ms /    97 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1571.78 ms /    78 tokens (   20.15 ms per token,    49.63 tokens per second)

llama_perf_context_print:        eval time =    9154.92 ms /    66 runs   (  138.71 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =   10942.27 ms /   144 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1345.09 ms /    68 tokens (   19.78 ms per token,    50.55 tokens per second)

llama_perf_context_print:        eval time =   12772.87 ms /    92 runs   (  138.84 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =   14418.59 ms /   160 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1221.12 ms /    60 tokens (   20.35 ms per token,    49.14 tokens per second)

llama_perf_context_print:        eval time =    9669.90 ms /    65 runs   (  148.77 ms per token,     6.72 tokens per second)

llama_perf_context_print:       total time =   11099.33 ms /   125 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 69, 'total_tokens': 139}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 43, 'total_tokens': 66}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 36, 'total_tokens': 81}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 49, 'total_tokens': 112}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 42, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 66, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 92, 'total_tokens': 164}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1198.26 ms /    55 tokens (   21.79 ms per token,    45.90 tokens per second)

llama_perf_context_print:        eval time =    8337.59 ms /    60 runs   (  138.96 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =    9733.52 ms /   115 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1134.62 ms /    56 tokens (   20.26 ms per token,    49.36 tokens per second)

llama_perf_context_print:        eval time =    6574.38 ms /    47 runs   (  139.88 ms per token,     7.15 tokens per second)

llama_perf_context_print:       total time =    7862.45 ms /   103 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1066.21 ms /    46 tokens (   23.18 ms per token,    43.14 tokens per second)

llama_perf_context_print:        eval time =    5557.12 ms /    40 runs   (  138.93 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =    6760.69 ms /    86 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1391.54 ms /    68 tokens (   20.46 ms per token,    48.87 tokens per second)

llama_perf_context_print:        eval time =    6692.82 ms /    48 runs   (  139.43 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    8239.56 ms /   116 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     538.46 ms /    14 tokens (   38.46 ms per token,    26.00 tokens per second)

llama_perf_context_print:        eval time =   17377.45 ms /   126 runs   (  137.92 ms per token,     7.25 tokens per second)

llama_perf_context_print:       total time =   18334.62 ms /   140 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1241.60 ms /    59 tokens (   21.04 ms per token,    47.52 tokens per second)

llama_perf_context_print:        eval time =    3230.64 ms /    23 runs   (  140.46 ms per token,     7.12 tokens per second)

llama_perf_context_print:       total time =    4548.36 ms /    82 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     530.39 ms /    16 tokens (   33.15 ms per token,    30.17 tokens per second)

llama_perf_context_print:        eval time =    3078.60 ms /    22 runs   (  139.94 ms per token,     7.15 tokens per second)

llama_perf_context_print:       total time =    3681.88 ms /    38 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1004.70 ms /    47 tokens (   21.38 ms per token,    46.78 tokens per second)

llama_perf_context_print:        eval time =    3964.23 ms /    28 runs   (  141.58 ms per token,     7.06 tokens per second)

llama_perf_context_print:       total time =    5060.60 ms /    75 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 65, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 60, 'total_tokens': 119}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 47, 'total_tokens': 107}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 40, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 48, 'total_tokens': 120}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 126, 'total_tokens': 144}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 23, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 22, 'total_tokens': 42}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     546.93 ms /    20 tokens (   27.35 ms per token,    36.57 tokens per second)

llama_perf_context_print:        eval time =  150838.88 ms /   999 runs   (  150.99 ms per token,     6.62 tokens per second)

llama_perf_context_print:       total time =  155570.80 ms /  1019 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1024.38 ms /    49 tokens (   20.91 ms per token,    47.83 tokens per second)

llama_perf_context_print:        eval time =    2806.11 ms /    20 runs   (  140.31 ms per token,     7.13 tokens per second)

llama_perf_context_print:       total time =    3898.16 ms /    69 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     453.51 ms /    16 tokens (   28.34 ms per token,    35.28 tokens per second)

llama_perf_context_print:        eval time =    5954.90 ms /    43 runs   (  138.49 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =    6549.01 ms /    59 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1561.55 ms /    75 tokens (   20.82 ms per token,    48.03 tokens per second)

llama_perf_context_print:        eval time =    3098.98 ms /    22 runs   (  140.86 ms per token,     7.10 tokens per second)

llama_perf_context_print:       total time =    4733.18 ms /    97 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     561.83 ms /    20 tokens (   28.09 ms per token,    35.60 tokens per second)

llama_perf_context_print:        eval time =   35752.94 ms /   258 runs   (  138.58 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   37189.14 ms /   278 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1269.82 ms /    64 tokens (   19.84 ms per token,    50.40 tokens per second)

llama_perf_context_print:        eval time =    2553.09 ms /    18 runs   (  141.84 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =    3884.95 ms /    82 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     980.27 ms /    43 tokens (   22.80 ms per token,    43.87 tokens per second)

llama_perf_context_print:        eval time =    4436.85 ms /    32 runs   (  138.65 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =    5524.78 ms /    75 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     854.12 ms /    35 tokens (   24.40 ms per token,    40.98 tokens per second)

llama_perf_context_print:        eval time =   12466.33 ms /    90 runs   (  138.51 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   13613.63 ms /   125 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 28, 'total_tokens': 79}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 20, 'total_tokens': 73}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 43, 'total_tokens': 63}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 22, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 258, 'total_tokens': 282}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 18, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 32, 'total_tokens': 79}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     902.94 ms /    39 tokens (   23.15 ms per token,    43.19 tokens per second)

llama_perf_context_print:        eval time =   23203.80 ms /   167 runs   (  138.94 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =   24656.24 ms /   206 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     835.52 ms /    40 tokens (   20.89 ms per token,    47.87 tokens per second)

llama_perf_context_print:        eval time =   32659.74 ms /   231 runs   (  141.38 ms per token,     7.07 tokens per second)

llama_perf_context_print:       total time =   34285.05 ms /   271 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1150.25 ms /    57 tokens (   20.18 ms per token,    49.55 tokens per second)

llama_perf_context_print:        eval time =    6540.34 ms /    47 runs   (  139.16 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =    7844.17 ms /   104 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     975.93 ms /    44 tokens (   22.18 ms per token,    45.09 tokens per second)

llama_perf_context_print:        eval time =    6139.12 ms /    44 runs   (  139.53 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    7257.51 ms /    88 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 90, 'total_tokens': 129}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 167, 'total_tokens': 210}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 231, 'total_tokens': 275}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 47, 'total_tokens': 108}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     919.97 ms /    41 tokens (   22.44 ms per token,    44.57 tokens per second)

llama_perf_context_print:        eval time =    8891.74 ms /    64 runs   (  138.93 ms per token,     7.20 tokens per second)

llama_perf_context_print:       total time =   10020.69 ms /   105 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     963.37 ms /    44 tokens (   21.89 ms per token,    45.67 tokens per second)

llama_perf_context_print:        eval time =    5021.07 ms /    36 runs   (  139.47 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    6103.95 ms /    80 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     957.89 ms /    45 tokens (   21.29 ms per token,    46.98 tokens per second)

llama_perf_context_print:        eval time =    6260.35 ms /    45 runs   (  139.12 ms per token,     7.19 tokens per second)

llama_perf_context_print:       total time =    7366.60 ms /    90 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     895.61 ms /    38 tokens (   23.57 ms per token,    42.43 tokens per second)

llama_perf_context_print:        eval time =    4602.67 ms /    33 runs   (  139.47 ms per token,     7.17 tokens per second)

llama_perf_context_print:       total time =    5608.78 ms /    71 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1279.10 ms /    61 tokens (   20.97 ms per token,    47.69 tokens per second)

llama_perf_context_print:        eval time =  125770.53 ms /   879 runs   (  143.08 ms per token,     6.99 tokens per second)

llama_perf_context_print:       total time =  130654.07 ms /   940 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 44, 'total_tokens': 92}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 64, 'total_tokens': 109}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 36, 'total_tokens': 84}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 45, 'total_tokens': 94}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 33, 'total_tokens': 75}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     984.88 ms /    48 tokens (   20.52 ms per token,    48.74 tokens per second)

llama_perf_context_print:        eval time =   44285.47 ms /   318 runs   (  139.26 ms per token,     7.18 tokens per second)

llama_perf_context_print:       total time =   46377.23 ms /   366 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1160.16 ms /    55 tokens (   21.09 ms per token,    47.41 tokens per second)

llama_perf_context_print:        eval time =   14690.07 ms /   106 runs   (  138.59 ms per token,     7.22 tokens per second)

llama_perf_context_print:       total time =   16193.75 ms /   161 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 879, 'total_tokens': 944}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 318, 'total_tokens': 370}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1660.69 ms /    79 tokens (   21.02 ms per token,    47.57 tokens per second)

llama_perf_context_print:        eval time =  155068.71 ms /   999 runs   (  155.22 ms per token,     6.44 tokens per second)

llama_perf_context_print:       total time =  160927.58 ms /  1078 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 106, 'total_tokens': 165}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1279.36 ms /    62 tokens (   20.63 ms per token,    48.46 tokens per second)

llama_perf_context_print:        eval time =   22900.09 ms /   165 runs   (  138.79 ms per token,     7.21 tokens per second)

llama_perf_context_print:       total time =   24723.68 ms /   227 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1296.85 ms /    63 tokens (   20.58 ms per token,    48.58 tokens per second)

llama_perf_context_print:        eval time =   58675.83 ms /   419 runs   (  140.04 ms per token,     7.14 tokens per second)

llama_perf_context_print:       total time =   61472.81 ms /   482 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1223.67 ms /    60 tokens (   20.39 ms per token,    49.03 tokens per second)

llama_perf_context_print:        eval time =  143906.88 ms /   999 runs   (  144.05 ms per token,     6.94 tokens per second)

llama_perf_context_print:       total time =  149330.01 ms /  1059 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 1000, 'total_tokens': 1083}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 165, 'total_tokens': 231}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 419, 'total_tokens': 487}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =     784.63 ms /    33 tokens (   23.78 ms per token,    42.06 tokens per second)

llama_perf_context_print:        eval time =    1029.44 ms /     7 runs   (  147.06 ms per token,     6.80 tokens per second)

llama_perf_context_print:       total time =    1842.41 ms /    40 tokens

llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    1177.86 ms /    58 tokens (   20.31 ms per token,    49.24 tokens per second)

llama_perf_context_print:        eval time =  152432.69 ms /   999 runs   (  152.59 ms per token,     6.55 tokens per second)

llama_perf_context_print:       total time =  157792.80 ms /  1057 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
llama_perf_context_print:        load time =    1134.94 ms

llama_perf_context_print: prompt eval time =    2060.26 ms /   111 tokens (   18.56 ms per token,    53.88 tokens per second)

llama_perf_context_print:        eval time =   91066.36 ms /   642 runs   (  141.85 ms per token,     7.05 tokens per second)

llama_perf_context_print:       total time =   95574.77 ms /   753 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 1000, 'total_tokens': 1062}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 642, 'total_tokens': 757}}
