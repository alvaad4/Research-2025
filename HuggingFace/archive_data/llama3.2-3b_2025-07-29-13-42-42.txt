llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     560.64 ms /    55 tokens (   10.19 ms per token,    98.10 tokens per second)

llama_perf_context_print:        eval time =     280.22 ms /     7 runs   (   40.03 ms per token,    24.98 tokens per second)

llama_perf_context_print:       total time =     857.23 ms /    62 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     206.39 ms /    21 tokens (    9.83 ms per token,   101.75 tokens per second)

llama_perf_context_print:        eval time =   42202.38 ms /   999 runs   (   42.24 ms per token,    23.67 tokens per second)

llama_perf_context_print:       total time =   45349.80 ms /  1020 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     230.24 ms /    21 tokens (   10.96 ms per token,    91.21 tokens per second)

llama_perf_context_print:        eval time =    1916.81 ms /    50 runs   (   38.34 ms per token,    26.08 tokens per second)

llama_perf_context_print:       total time =    2243.85 ms /    71 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 7, 'total_tokens': 62}}
logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 1000, 'total_tokens': 1062}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     270.45 ms /    28 tokens (    9.66 ms per token,   103.53 tokens per second)

llama_perf_context_print:        eval time =    2792.77 ms /    71 runs   (   39.33 ms per token,    25.42 tokens per second)

llama_perf_context_print:       total time =    3204.31 ms /    99 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     214.47 ms /    14 tokens (   15.32 ms per token,    65.28 tokens per second)

llama_perf_context_print:        eval time =    3103.78 ms /    80 runs   (   38.80 ms per token,    25.78 tokens per second)

llama_perf_context_print:       total time =    3476.81 ms /    94 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     174.34 ms /    16 tokens (   10.90 ms per token,    91.78 tokens per second)

llama_perf_context_print:        eval time =    2184.62 ms /    56 runs   (   39.01 ms per token,    25.63 tokens per second)

llama_perf_context_print:       total time =    2469.93 ms /    72 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     190.74 ms /    17 tokens (   11.22 ms per token,    89.13 tokens per second)

llama_perf_context_print:        eval time =     832.18 ms /    22 runs   (   37.83 ms per token,    26.44 tokens per second)

llama_perf_context_print:       total time =    1065.91 ms /    39 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     210.22 ms /    15 tokens (   14.01 ms per token,    71.35 tokens per second)

llama_perf_context_print:        eval time =     316.35 ms /     8 runs   (   39.54 ms per token,    25.29 tokens per second)

llama_perf_context_print:       total time =     544.25 ms /    23 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     239.80 ms /    27 tokens (    8.88 ms per token,   112.60 tokens per second)

llama_perf_context_print:        eval time =     551.09 ms /    14 runs   (   39.36 ms per token,    25.40 tokens per second)

llama_perf_context_print:       total time =     819.91 ms /    41 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     226.09 ms /    21 tokens (   10.77 ms per token,    92.88 tokens per second)

llama_perf_context_print:        eval time =    4306.58 ms /   110 runs   (   39.15 ms per token,    25.54 tokens per second)

llama_perf_context_print:       total time =    4756.43 ms /   131 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     567.41 ms /    90 tokens (    6.30 ms per token,   158.62 tokens per second)

llama_perf_context_print:        eval time =   11147.59 ms /   279 runs   (   39.96 ms per token,    25.03 tokens per second)

llama_perf_context_print:       total time =   12322.31 ms /   369 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 50, 'total_tokens': 112}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 71, 'total_tokens': 140}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 80, 'total_tokens': 135}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 56, 'total_tokens': 113}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 22, 'total_tokens': 80}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 8, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 14, 'total_tokens': 82}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 110, 'total_tokens': 172}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     310.10 ms /    40 tokens (    7.75 ms per token,   128.99 tokens per second)

llama_perf_context_print:        eval time =    2668.85 ms /    68 runs   (   39.25 ms per token,    25.48 tokens per second)

llama_perf_context_print:       total time =    3114.45 ms /   108 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     354.31 ms /    51 tokens (    6.95 ms per token,   143.94 tokens per second)

llama_perf_context_print:        eval time =    6256.95 ms /   150 runs   (   41.71 ms per token,    23.97 tokens per second)

llama_perf_context_print:       total time =    6914.93 ms /   201 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     472.71 ms /    58 tokens (    8.15 ms per token,   122.70 tokens per second)

llama_perf_context_print:        eval time =    2405.32 ms /    61 runs   (   39.43 ms per token,    25.36 tokens per second)

llama_perf_context_print:       total time =    2996.03 ms /   119 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     261.94 ms /    29 tokens (    9.03 ms per token,   110.71 tokens per second)

llama_perf_context_print:        eval time =    1953.13 ms /    50 runs   (   39.06 ms per token,    25.60 tokens per second)

llama_perf_context_print:       total time =    2315.21 ms /    79 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     243.82 ms /    24 tokens (   10.16 ms per token,    98.43 tokens per second)

llama_perf_context_print:        eval time =    3123.23 ms /    80 runs   (   39.04 ms per token,    25.61 tokens per second)

llama_perf_context_print:       total time =    3525.03 ms /   104 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 131, 'completion_tokens': 279, 'total_tokens': 410}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 68, 'total_tokens': 149}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 150, 'total_tokens': 242}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 99, 'completion_tokens': 61, 'total_tokens': 160}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 50, 'total_tokens': 119}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 80, 'total_tokens': 144}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     378.82 ms /    51 tokens (    7.43 ms per token,   134.63 tokens per second)

llama_perf_context_print:        eval time =    2439.55 ms /    61 runs   (   39.99 ms per token,    25.00 tokens per second)

llama_perf_context_print:       total time =    2940.66 ms /   112 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     418.33 ms /    58 tokens (    7.21 ms per token,   138.65 tokens per second)

llama_perf_context_print:        eval time =   11147.19 ms /   280 runs   (   39.81 ms per token,    25.12 tokens per second)

llama_perf_context_print:       total time =   12166.73 ms /   338 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     408.20 ms /    63 tokens (    6.48 ms per token,   154.33 tokens per second)

llama_perf_context_print:        eval time =   13813.60 ms /   342 runs   (   40.39 ms per token,    24.76 tokens per second)

llama_perf_context_print:       total time =   14984.75 ms /   405 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 92, 'completion_tokens': 61, 'total_tokens': 153}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 280, 'total_tokens': 382}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 107, 'completion_tokens': 342, 'total_tokens': 449}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     589.61 ms /   102 tokens (    5.78 ms per token,   172.99 tokens per second)

llama_perf_context_print:        eval time =    9056.45 ms /   227 runs   (   39.90 ms per token,    25.06 tokens per second)

llama_perf_context_print:       total time =   10110.49 ms /   329 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     387.41 ms /    51 tokens (    7.60 ms per token,   131.64 tokens per second)

llama_perf_context_print:        eval time =    9324.75 ms /   235 runs   (   39.68 ms per token,    25.20 tokens per second)

llama_perf_context_print:       total time =   10188.98 ms /   286 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     362.23 ms /    54 tokens (    6.71 ms per token,   149.08 tokens per second)

llama_perf_context_print:        eval time =    5908.82 ms /   150 runs   (   39.39 ms per token,    25.39 tokens per second)

llama_perf_context_print:       total time =    6559.05 ms /   204 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     264.68 ms /    34 tokens (    7.78 ms per token,   128.46 tokens per second)

llama_perf_context_print:        eval time =    5561.69 ms /   141 runs   (   39.44 ms per token,    25.35 tokens per second)

llama_perf_context_print:       total time =    6094.24 ms /   175 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 143, 'completion_tokens': 227, 'total_tokens': 370}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 91, 'completion_tokens': 235, 'total_tokens': 326}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 150, 'total_tokens': 244}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     322.93 ms /    45 tokens (    7.18 ms per token,   139.35 tokens per second)

llama_perf_context_print:        eval time =    9539.37 ms /   240 runs   (   39.75 ms per token,    25.16 tokens per second)

llama_perf_context_print:       total time =   10343.99 ms /   285 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     452.36 ms /    75 tokens (    6.03 ms per token,   165.80 tokens per second)

llama_perf_context_print:        eval time =   17506.91 ms /   433 runs   (   40.43 ms per token,    24.73 tokens per second)

llama_perf_context_print:       total time =   18909.73 ms /   508 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     335.93 ms /    42 tokens (    8.00 ms per token,   125.02 tokens per second)

llama_perf_context_print:        eval time =    5763.99 ms /   134 runs   (   43.01 ms per token,    23.25 tokens per second)

llama_perf_context_print:       total time =    6337.67 ms /   176 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 141, 'total_tokens': 216}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 240, 'total_tokens': 326}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 116, 'completion_tokens': 433, 'total_tokens': 549}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     251.40 ms /    29 tokens (    8.67 ms per token,   115.36 tokens per second)

llama_perf_context_print:        eval time =    7749.94 ms /   197 runs   (   39.34 ms per token,    25.42 tokens per second)

llama_perf_context_print:       total time =    8386.43 ms /   226 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     346.35 ms /    43 tokens (    8.05 ms per token,   124.15 tokens per second)

llama_perf_context_print:        eval time =    4993.98 ms /   127 runs   (   39.32 ms per token,    25.43 tokens per second)

llama_perf_context_print:       total time =    5578.76 ms /   170 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     317.72 ms /    35 tokens (    9.08 ms per token,   110.16 tokens per second)

llama_perf_context_print:        eval time =    4419.49 ms /   114 runs   (   38.77 ms per token,    25.79 tokens per second)

llama_perf_context_print:       total time =    4947.31 ms /   149 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     258.66 ms /    28 tokens (    9.24 ms per token,   108.25 tokens per second)

llama_perf_context_print:        eval time =    5639.35 ms /   144 runs   (   39.16 ms per token,    25.53 tokens per second)

llama_perf_context_print:       total time =    6172.39 ms /   172 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     233.59 ms /    21 tokens (   11.12 ms per token,    89.90 tokens per second)

llama_perf_context_print:        eval time =    1708.79 ms /    44 runs   (   38.84 ms per token,    25.75 tokens per second)

llama_perf_context_print:       total time =    2023.93 ms /    65 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     242.85 ms /    26 tokens (    9.34 ms per token,   107.06 tokens per second)

llama_perf_context_print:        eval time =    7652.04 ms /   194 runs   (   39.44 ms per token,    25.35 tokens per second)

llama_perf_context_print:       total time =    8275.97 ms /   220 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 134, 'total_tokens': 217}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 197, 'total_tokens': 267}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 127, 'total_tokens': 211}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 114, 'total_tokens': 190}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 69, 'completion_tokens': 144, 'total_tokens': 213}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 44, 'total_tokens': 107}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     247.32 ms /    33 tokens (    7.49 ms per token,   133.43 tokens per second)

llama_perf_context_print:        eval time =    3019.56 ms /    77 runs   (   39.22 ms per token,    25.50 tokens per second)

llama_perf_context_print:       total time =    3408.47 ms /   110 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     213.96 ms /    20 tokens (   10.70 ms per token,    93.48 tokens per second)

llama_perf_context_print:        eval time =    6954.54 ms /   177 runs   (   39.29 ms per token,    25.45 tokens per second)

llama_perf_context_print:       total time =    7513.90 ms /   197 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     212.82 ms /    15 tokens (   14.19 ms per token,    70.48 tokens per second)

llama_perf_context_print:        eval time =    1433.18 ms /    37 runs   (   38.73 ms per token,    25.82 tokens per second)

llama_perf_context_print:       total time =    1714.40 ms /    52 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     202.99 ms /    19 tokens (   10.68 ms per token,    93.60 tokens per second)

llama_perf_context_print:        eval time =   17235.58 ms /   430 runs   (   40.08 ms per token,    24.95 tokens per second)

llama_perf_context_print:       total time =   18395.18 ms /   449 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 194, 'total_tokens': 260}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 73, 'completion_tokens': 77, 'total_tokens': 150}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 177, 'total_tokens': 238}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 37, 'total_tokens': 93}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     192.14 ms /    14 tokens (   13.72 ms per token,    72.86 tokens per second)

llama_perf_context_print:        eval time =     395.41 ms /    10 runs   (   39.54 ms per token,    25.29 tokens per second)

llama_perf_context_print:       total time =     608.19 ms /    24 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     259.25 ms /    23 tokens (   11.27 ms per token,    88.72 tokens per second)

llama_perf_context_print:        eval time =     780.49 ms /    20 runs   (   39.02 ms per token,    25.63 tokens per second)

llama_perf_context_print:       total time =    1077.42 ms /    43 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     202.91 ms /    18 tokens (   11.27 ms per token,    88.71 tokens per second)

llama_perf_context_print:        eval time =   16663.48 ms /   416 runs   (   40.06 ms per token,    24.96 tokens per second)

llama_perf_context_print:       total time =   17789.73 ms /   434 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     268.88 ms /    35 tokens (    7.68 ms per token,   130.17 tokens per second)

llama_perf_context_print:        eval time =    3713.41 ms /    89 runs   (   41.72 ms per token,    23.97 tokens per second)

llama_perf_context_print:       total time =    4151.12 ms /   124 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     576.32 ms /    93 tokens (    6.20 ms per token,   161.37 tokens per second)

llama_perf_context_print:        eval time =    1866.32 ms /    47 runs   (   39.71 ms per token,    25.18 tokens per second)

llama_perf_context_print:       total time =    2531.69 ms /   140 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 430, 'total_tokens': 490}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 10, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 20, 'total_tokens': 84}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 416, 'total_tokens': 475}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 76, 'completion_tokens': 89, 'total_tokens': 165}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     678.46 ms /   111 tokens (    6.11 ms per token,   163.61 tokens per second)

llama_perf_context_print:        eval time =    3098.20 ms /    79 runs   (   39.22 ms per token,    25.50 tokens per second)

llama_perf_context_print:       total time =    3926.68 ms /   190 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     718.74 ms /   133 tokens (    5.40 ms per token,   185.05 tokens per second)

llama_perf_context_print:        eval time =    2507.16 ms /    63 runs   (   39.80 ms per token,    25.13 tokens per second)

llama_perf_context_print:       total time =    3341.55 ms /   196 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     631.98 ms /   117 tokens (    5.40 ms per token,   185.13 tokens per second)

llama_perf_context_print:        eval time =    2419.85 ms /    61 runs   (   39.67 ms per token,    25.21 tokens per second)

llama_perf_context_print:       total time =    3162.26 ms /   178 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     488.10 ms /    76 tokens (    6.42 ms per token,   155.71 tokens per second)

llama_perf_context_print:        eval time =     517.38 ms /    13 runs   (   39.80 ms per token,    25.13 tokens per second)

llama_perf_context_print:       total time =    1029.86 ms /    89 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     744.03 ms /   137 tokens (    5.43 ms per token,   184.13 tokens per second)

llama_perf_context_print:        eval time =    3867.30 ms /    96 runs   (   40.28 ms per token,    24.82 tokens per second)

llama_perf_context_print:       total time =    4789.31 ms /   233 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 134, 'completion_tokens': 47, 'total_tokens': 181}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 152, 'completion_tokens': 79, 'total_tokens': 231}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 63, 'total_tokens': 237}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 158, 'completion_tokens': 61, 'total_tokens': 219}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 13, 'total_tokens': 130}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     581.75 ms /    98 tokens (    5.94 ms per token,   168.46 tokens per second)

llama_perf_context_print:        eval time =    3445.40 ms /    89 runs   (   38.71 ms per token,    25.83 tokens per second)

llama_perf_context_print:       total time =    4186.35 ms /   187 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     282.59 ms /    27 tokens (   10.47 ms per token,    95.55 tokens per second)

llama_perf_context_print:        eval time =    4130.65 ms /   105 runs   (   39.34 ms per token,    25.42 tokens per second)

llama_perf_context_print:       total time =    4606.40 ms /   132 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     464.77 ms /    67 tokens (    6.94 ms per token,   144.16 tokens per second)

llama_perf_context_print:        eval time =    1283.42 ms /    32 runs   (   40.11 ms per token,    24.93 tokens per second)

llama_perf_context_print:       total time =    1807.31 ms /    99 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     213.71 ms /    22 tokens (    9.71 ms per token,   102.95 tokens per second)

llama_perf_context_print:        eval time =    2346.21 ms /    60 runs   (   39.10 ms per token,    25.57 tokens per second)

llama_perf_context_print:       total time =    2669.73 ms /    82 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     340.50 ms /    43 tokens (    7.92 ms per token,   126.28 tokens per second)

llama_perf_context_print:        eval time =    1256.47 ms /    32 runs   (   39.26 ms per token,    25.47 tokens per second)

llama_perf_context_print:       total time =    1654.75 ms /    75 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     380.52 ms /    59 tokens (    6.45 ms per token,   155.05 tokens per second)

llama_perf_context_print:        eval time =    2039.36 ms /    51 runs   (   39.99 ms per token,    25.01 tokens per second)

llama_perf_context_print:       total time =    2513.12 ms /   110 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 178, 'completion_tokens': 96, 'total_tokens': 274}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 139, 'completion_tokens': 89, 'total_tokens': 228}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 105, 'total_tokens': 173}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 32, 'total_tokens': 140}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 60, 'total_tokens': 123}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 32, 'total_tokens': 116}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 51, 'total_tokens': 151}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     385.61 ms /    53 tokens (    7.28 ms per token,   137.44 tokens per second)

llama_perf_context_print:        eval time =    1212.08 ms /    31 runs   (   39.10 ms per token,    25.58 tokens per second)

llama_perf_context_print:       total time =    1655.89 ms /    84 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     462.63 ms /    76 tokens (    6.09 ms per token,   164.28 tokens per second)

llama_perf_context_print:        eval time =    3311.56 ms /    84 runs   (   39.42 ms per token,    25.37 tokens per second)

llama_perf_context_print:       total time =    3927.00 ms /   160 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     471.02 ms /    67 tokens (    7.03 ms per token,   142.25 tokens per second)

llama_perf_context_print:        eval time =    1666.83 ms /    42 runs   (   39.69 ms per token,    25.20 tokens per second)

llama_perf_context_print:       total time =    2213.45 ms /   109 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     437.96 ms /    61 tokens (    7.18 ms per token,   139.28 tokens per second)

llama_perf_context_print:        eval time =    1944.09 ms /    49 runs   (   39.68 ms per token,    25.20 tokens per second)

llama_perf_context_print:       total time =    2471.80 ms /   110 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     375.50 ms /    52 tokens (    7.22 ms per token,   138.48 tokens per second)

llama_perf_context_print:        eval time =    1610.06 ms /    42 runs   (   38.33 ms per token,    26.09 tokens per second)

llama_perf_context_print:       total time =    2060.65 ms /    94 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     406.84 ms /    55 tokens (    7.40 ms per token,   135.19 tokens per second)

llama_perf_context_print:        eval time =    1647.73 ms /    42 runs   (   39.23 ms per token,    25.49 tokens per second)

llama_perf_context_print:       total time =    2131.33 ms /    97 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     360.00 ms /    45 tokens (    8.00 ms per token,   125.00 tokens per second)

llama_perf_context_print:        eval time =    1188.75 ms /    29 runs   (   40.99 ms per token,    24.40 tokens per second)

llama_perf_context_print:       total time =    1602.90 ms /    74 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 31, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 117, 'completion_tokens': 84, 'total_tokens': 201}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 42, 'total_tokens': 150}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 49, 'total_tokens': 151}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 93, 'completion_tokens': 42, 'total_tokens': 135}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 96, 'completion_tokens': 42, 'total_tokens': 138}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 29, 'total_tokens': 115}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     387.48 ms /    61 tokens (    6.35 ms per token,   157.43 tokens per second)

llama_perf_context_print:        eval time =    1587.63 ms /    40 runs   (   39.69 ms per token,    25.19 tokens per second)

llama_perf_context_print:       total time =    2048.63 ms /   101 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     223.64 ms /    15 tokens (   14.91 ms per token,    67.07 tokens per second)

llama_perf_context_print:        eval time =    1624.84 ms /    43 runs   (   37.79 ms per token,    26.46 tokens per second)

llama_perf_context_print:       total time =    1925.61 ms /    58 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     371.63 ms /    59 tokens (    6.30 ms per token,   158.76 tokens per second)

llama_perf_context_print:        eval time =     878.47 ms /    22 runs   (   39.93 ms per token,    25.04 tokens per second)

llama_perf_context_print:       total time =    1291.87 ms /    81 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     204.36 ms /    17 tokens (   12.02 ms per token,    83.19 tokens per second)

llama_perf_context_print:        eval time =     279.26 ms /     7 runs   (   39.89 ms per token,    25.07 tokens per second)

llama_perf_context_print:       total time =     499.37 ms /    24 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     333.99 ms /    47 tokens (    7.11 ms per token,   140.72 tokens per second)

llama_perf_context_print:        eval time =     912.49 ms /    23 runs   (   39.67 ms per token,    25.21 tokens per second)

llama_perf_context_print:       total time =    1287.65 ms /    70 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     203.71 ms /    21 tokens (    9.70 ms per token,   103.09 tokens per second)

llama_perf_context_print:        eval time =     629.00 ms /    16 runs   (   39.31 ms per token,    25.44 tokens per second)

llama_perf_context_print:       total time =     863.11 ms /    37 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     319.44 ms /    49 tokens (    6.52 ms per token,   153.39 tokens per second)

llama_perf_context_print:        eval time =     724.92 ms /    18 runs   (   40.27 ms per token,    24.83 tokens per second)

llama_perf_context_print:       total time =    1079.09 ms /    67 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     173.25 ms /    17 tokens (   10.19 ms per token,    98.13 tokens per second)

llama_perf_context_print:        eval time =     470.70 ms /    12 runs   (   39.23 ms per token,    25.49 tokens per second)

llama_perf_context_print:       total time =     668.04 ms /    29 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     487.97 ms /    71 tokens (    6.87 ms per token,   145.50 tokens per second)

llama_perf_context_print:        eval time =     755.78 ms /    19 runs   (   39.78 ms per token,    25.14 tokens per second)

llama_perf_context_print:       total time =    1278.99 ms /    90 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     202.93 ms /    20 tokens (   10.15 ms per token,    98.56 tokens per second)

llama_perf_context_print:        eval time =     720.11 ms /    18 runs   (   40.01 ms per token,    25.00 tokens per second)

llama_perf_context_print:       total time =     957.11 ms /    38 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 40, 'total_tokens': 142}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 43, 'total_tokens': 99}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 100, 'completion_tokens': 22, 'total_tokens': 122}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 7, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 88, 'completion_tokens': 23, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 16, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 18, 'total_tokens': 108}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 12, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 19, 'total_tokens': 131}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     440.12 ms /    62 tokens (    7.10 ms per token,   140.87 tokens per second)

llama_perf_context_print:        eval time =     726.12 ms /    18 runs   (   40.34 ms per token,    24.79 tokens per second)

llama_perf_context_print:       total time =    1199.62 ms /    80 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     294.69 ms /    44 tokens (    6.70 ms per token,   149.31 tokens per second)

llama_perf_context_print:        eval time =    1107.79 ms /    28 runs   (   39.56 ms per token,    25.28 tokens per second)

llama_perf_context_print:       total time =    1454.18 ms /    72 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     280.34 ms /    37 tokens (    7.58 ms per token,   131.98 tokens per second)

llama_perf_context_print:        eval time =    2434.95 ms /    63 runs   (   38.65 ms per token,    25.87 tokens per second)

llama_perf_context_print:       total time =    2831.42 ms /   100 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     277.06 ms /    40 tokens (    6.93 ms per token,   144.37 tokens per second)

llama_perf_context_print:        eval time =    1910.67 ms /    49 runs   (   38.99 ms per token,    25.65 tokens per second)

llama_perf_context_print:       total time =    2278.62 ms /    89 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     314.45 ms /    43 tokens (    7.31 ms per token,   136.75 tokens per second)

llama_perf_context_print:        eval time =    2331.42 ms /    59 runs   (   39.52 ms per token,    25.31 tokens per second)

llama_perf_context_print:       total time =    2753.26 ms /   102 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     358.77 ms /    56 tokens (    6.41 ms per token,   156.09 tokens per second)

llama_perf_context_print:        eval time =    1374.21 ms /    35 runs   (   39.26 ms per token,    25.47 tokens per second)

llama_perf_context_print:       total time =    1797.71 ms /    91 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     331.84 ms /    43 tokens (    7.72 ms per token,   129.58 tokens per second)

llama_perf_context_print:        eval time =     449.81 ms /    11 runs   (   40.89 ms per token,    24.45 tokens per second)

llama_perf_context_print:       total time =     803.95 ms /    54 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     327.36 ms /    43 tokens (    7.61 ms per token,   131.35 tokens per second)

llama_perf_context_print:        eval time =    1589.45 ms /    40 runs   (   39.74 ms per token,    25.17 tokens per second)

llama_perf_context_print:       total time =    1989.81 ms /    83 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 18, 'total_tokens': 78}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 102, 'completion_tokens': 18, 'total_tokens': 120}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 28, 'total_tokens': 113}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 63, 'total_tokens': 141}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 49, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 59, 'total_tokens': 143}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 35, 'total_tokens': 132}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 11, 'total_tokens': 95}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     309.24 ms /    45 tokens (    6.87 ms per token,   145.52 tokens per second)

llama_perf_context_print:        eval time =    1847.56 ms /    47 runs   (   39.31 ms per token,    25.44 tokens per second)

llama_perf_context_print:       total time =    2242.78 ms /    92 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     333.33 ms /    46 tokens (    7.25 ms per token,   138.00 tokens per second)

llama_perf_context_print:        eval time =    1692.36 ms /    44 runs   (   38.46 ms per token,    26.00 tokens per second)

llama_perf_context_print:       total time =    2103.74 ms /    90 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     292.80 ms /    37 tokens (    7.91 ms per token,   126.37 tokens per second)

llama_perf_context_print:        eval time =    3921.53 ms /    95 runs   (   41.28 ms per token,    24.23 tokens per second)

llama_perf_context_print:       total time =    4383.87 ms /   132 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     370.28 ms /    57 tokens (    6.50 ms per token,   153.94 tokens per second)

llama_perf_context_print:        eval time =   14174.97 ms /   354 runs   (   40.04 ms per token,    24.97 tokens per second)

llama_perf_context_print:       total time =   15302.20 ms /   411 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 84, 'completion_tokens': 40, 'total_tokens': 124}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 47, 'total_tokens': 133}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 44, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 78, 'completion_tokens': 95, 'total_tokens': 173}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     354.38 ms /    44 tokens (    8.05 ms per token,   124.16 tokens per second)

llama_perf_context_print:        eval time =    7410.19 ms /   188 runs   (   39.42 ms per token,    25.37 tokens per second)

llama_perf_context_print:       total time =    8131.20 ms /   232 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     343.97 ms /    51 tokens (    6.74 ms per token,   148.27 tokens per second)

llama_perf_context_print:        eval time =    7234.42 ms /   175 runs   (   41.34 ms per token,    24.19 tokens per second)

llama_perf_context_print:       total time =    7901.72 ms /   226 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     437.60 ms /    76 tokens (    5.76 ms per token,   173.67 tokens per second)

llama_perf_context_print:        eval time =   14379.25 ms /   360 runs   (   39.94 ms per token,    25.04 tokens per second)

llama_perf_context_print:       total time =   15595.41 ms /   436 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 87, 'completion_tokens': 354, 'total_tokens': 441}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 74, 'completion_tokens': 188, 'total_tokens': 262}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 81, 'completion_tokens': 175, 'total_tokens': 256}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     369.53 ms /    56 tokens (    6.60 ms per token,   151.54 tokens per second)

llama_perf_context_print:        eval time =   10430.63 ms /   244 runs   (   42.75 ms per token,    23.39 tokens per second)

llama_perf_context_print:       total time =   11267.26 ms /   300 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     381.85 ms /    58 tokens (    6.58 ms per token,   151.89 tokens per second)

llama_perf_context_print:        eval time =    6600.14 ms /   165 runs   (   40.00 ms per token,    25.00 tokens per second)

llama_perf_context_print:       total time =    7293.59 ms /   223 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     359.43 ms /    56 tokens (    6.42 ms per token,   155.80 tokens per second)

llama_perf_context_print:        eval time =   17434.11 ms /   432 runs   (   40.36 ms per token,    24.78 tokens per second)

llama_perf_context_print:       total time =   18748.25 ms /   488 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 360, 'total_tokens': 466}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 244, 'total_tokens': 330}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 89, 'completion_tokens': 165, 'total_tokens': 254}}
llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     270.61 ms /    29 tokens (    9.33 ms per token,   107.17 tokens per second)

llama_perf_context_print:        eval time =     242.92 ms /     6 runs   (   40.49 ms per token,    24.70 tokens per second)

llama_perf_context_print:       total time =     527.33 ms /    35 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     348.36 ms /    55 tokens (    6.33 ms per token,   157.88 tokens per second)

llama_perf_context_print:        eval time =   12906.99 ms /   322 runs   (   40.08 ms per token,    24.95 tokens per second)

llama_perf_context_print:       total time =   13928.35 ms /   377 tokens

llama_perf_context_print:        load time =     560.83 ms

llama_perf_context_print: prompt eval time =     631.50 ms /   107 tokens (    5.90 ms per token,   169.44 tokens per second)

llama_perf_context_print:        eval time =    8664.49 ms /   220 runs   (   39.38 ms per token,    25.39 tokens per second)

llama_perf_context_print:       total time =    9722.33 ms /   327 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 86, 'completion_tokens': 432, 'total_tokens': 518}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 6, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 85, 'completion_tokens': 322, 'total_tokens': 407}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 137, 'completion_tokens': 220, 'total_tokens': 357}}
