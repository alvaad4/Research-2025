llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1714.42 ms /    17 tokens (  100.85 ms per token,     9.92 tokens per second)

llama_perf_context_print:        eval time =   13358.09 ms /    48 runs   (  278.29 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   15268.77 ms /    65 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1124.92 ms /    20 tokens (   56.25 ms per token,    17.78 tokens per second)

llama_perf_context_print:        eval time =   48052.84 ms /   173 runs   (  277.76 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   49847.74 ms /   193 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1121.77 ms /    20 tokens (   56.09 ms per token,    17.83 tokens per second)

llama_perf_context_print:        eval time =   51986.65 ms /   187 runs   (  278.00 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   53804.95 ms /   207 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1490.67 ms /    26 tokens (   57.33 ms per token,    17.44 tokens per second)

llama_perf_context_print:        eval time =   19275.02 ms /    57 runs   (  338.16 ms per token,     2.96 tokens per second)

llama_perf_context_print:       total time =   20966.03 ms /    83 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 48, 'total_tokens': 65}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 173, 'total_tokens': 197}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 187, 'total_tokens': 211}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 57, 'total_tokens': 87}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =     914.49 ms /    16 tokens (   57.16 ms per token,    17.50 tokens per second)

llama_perf_context_print:        eval time =   32146.73 ms /   116 runs   (  277.13 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =   33463.72 ms /   132 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1263.36 ms /    14 tokens (   90.24 ms per token,    11.08 tokens per second)

llama_perf_context_print:        eval time =   35455.21 ms /   128 runs   (  276.99 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =   37172.44 ms /   142 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1068.34 ms /    17 tokens (   62.84 ms per token,    15.91 tokens per second)

llama_perf_context_print:        eval time =    7860.80 ms /    28 runs   (  280.74 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =    9027.49 ms /    45 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1270.43 ms /    14 tokens (   90.75 ms per token,    11.02 tokens per second)

llama_perf_context_print:        eval time =   14473.88 ms /    52 runs   (  278.34 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   15929.13 ms /    66 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1341.03 ms /    24 tokens (   55.88 ms per token,    17.90 tokens per second)

llama_perf_context_print:        eval time =   27222.26 ms /    98 runs   (  277.78 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   28906.79 ms /   122 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1135.53 ms /    20 tokens (   56.78 ms per token,    17.61 tokens per second)

llama_perf_context_print:        eval time =   41632.65 ms /   130 runs   (  320.25 ms per token,     3.12 tokens per second)

llama_perf_context_print:       total time =   43221.32 ms /   150 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 116, 'total_tokens': 136}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 128, 'total_tokens': 146}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 28, 'total_tokens': 49}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 52, 'total_tokens': 70}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 98, 'total_tokens': 126}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 130, 'total_tokens': 154}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3903.80 ms /    93 tokens (   41.98 ms per token,    23.82 tokens per second)

llama_perf_context_print:        eval time =    7850.11 ms /    28 runs   (  280.36 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   11859.21 ms /   121 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1894.37 ms /    38 tokens (   49.85 ms per token,    20.06 tokens per second)

llama_perf_context_print:        eval time =    7028.38 ms /    25 runs   (  281.14 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =    9016.07 ms /    63 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2283.23 ms /    47 tokens (   48.58 ms per token,    20.58 tokens per second)

llama_perf_context_print:        eval time =    4573.06 ms /    16 runs   (  285.82 ms per token,     3.50 tokens per second)

llama_perf_context_print:       total time =    6916.92 ms /    63 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2488.19 ms /    55 tokens (   45.24 ms per token,    22.10 tokens per second)

llama_perf_context_print:        eval time =    7357.26 ms /    26 runs   (  282.97 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =    9938.15 ms /    81 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1354.69 ms /    25 tokens (   54.19 ms per token,    18.45 tokens per second)

llama_perf_context_print:        eval time =   17261.62 ms /    62 runs   (  278.41 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   18832.36 ms /    87 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1379.85 ms /    23 tokens (   59.99 ms per token,    16.67 tokens per second)

llama_perf_context_print:        eval time =    2619.01 ms /     9 runs   (  291.00 ms per token,     3.44 tokens per second)

llama_perf_context_print:       total time =    4035.69 ms /    32 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2254.39 ms /    50 tokens (   45.09 ms per token,    22.18 tokens per second)

llama_perf_context_print:        eval time =    4829.92 ms /    17 runs   (  284.11 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =    7147.05 ms /    67 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2513.28 ms /    56 tokens (   44.88 ms per token,    22.28 tokens per second)

llama_perf_context_print:        eval time =    3183.13 ms /    11 runs   (  289.38 ms per token,     3.46 tokens per second)

llama_perf_context_print:       total time =    5738.80 ms /    67 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2852.41 ms /    68 tokens (   41.95 ms per token,    23.84 tokens per second)

llama_perf_context_print:        eval time =    2640.77 ms /     9 runs   (  293.42 ms per token,     3.41 tokens per second)

llama_perf_context_print:       total time =    5529.34 ms /    77 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    4219.36 ms /   102 tokens (   41.37 ms per token,    24.17 tokens per second)

llama_perf_context_print:        eval time =   11747.21 ms /    42 runs   (  279.70 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   16117.18 ms /   144 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 97, 'completion_tokens': 28, 'total_tokens': 125}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 25, 'total_tokens': 67}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 16, 'total_tokens': 67}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 26, 'total_tokens': 85}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 29, 'completion_tokens': 62, 'total_tokens': 91}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 9, 'total_tokens': 36}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 17, 'total_tokens': 71}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 11, 'total_tokens': 74}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 75, 'completion_tokens': 9, 'total_tokens': 84}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2344.64 ms /    53 tokens (   44.24 ms per token,    22.60 tokens per second)

llama_perf_context_print:        eval time =   51125.15 ms /   183 runs   (  279.37 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   54141.10 ms /   236 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2333.72 ms /    54 tokens (   43.22 ms per token,    23.14 tokens per second)

llama_perf_context_print:        eval time =   51372.79 ms /   159 runs   (  323.10 ms per token,     3.10 tokens per second)

llama_perf_context_print:       total time =   54289.54 ms /   213 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1846.70 ms /    34 tokens (   54.31 ms per token,    18.41 tokens per second)

llama_perf_context_print:        eval time =   39102.49 ms /   141 runs   (  277.32 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =   41446.80 ms /   175 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2292.89 ms /    47 tokens (   48.78 ms per token,    20.50 tokens per second)

llama_perf_context_print:        eval time =   82429.04 ms /   295 runs   (  279.42 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   85738.29 ms /   342 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 106, 'completion_tokens': 42, 'total_tokens': 148}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 183, 'total_tokens': 240}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 58, 'completion_tokens': 159, 'total_tokens': 217}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 38, 'completion_tokens': 141, 'total_tokens': 179}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 295, 'total_tokens': 346}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3408.36 ms /    75 tokens (   45.44 ms per token,    22.00 tokens per second)

llama_perf_context_print:        eval time =  156162.55 ms /   543 runs   (  287.59 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =  161679.99 ms /   618 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2079.98 ms /    45 tokens (   46.22 ms per token,    21.63 tokens per second)

llama_perf_context_print:        eval time =   33133.37 ms /   117 runs   (  283.19 ms per token,     3.53 tokens per second)

llama_perf_context_print:       total time =   35632.83 ms /   162 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1755.29 ms /    31 tokens (   56.62 ms per token,    17.66 tokens per second)

llama_perf_context_print:        eval time =   36877.88 ms /   133 runs   (  277.28 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =   39123.52 ms /   164 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2008.49 ms /    44 tokens (   45.65 ms per token,    21.91 tokens per second)

llama_perf_context_print:        eval time =   45112.38 ms /   162 runs   (  278.47 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   47724.51 ms /   206 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 543, 'total_tokens': 622}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 117, 'total_tokens': 166}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 35, 'completion_tokens': 133, 'total_tokens': 168}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1820.05 ms /    35 tokens (   52.00 ms per token,    19.23 tokens per second)

llama_perf_context_print:        eval time =   58965.96 ms /   178 runs   (  331.27 ms per token,     3.02 tokens per second)

llama_perf_context_print:       total time =   61439.73 ms /   213 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1591.61 ms /    29 tokens (   54.88 ms per token,    18.22 tokens per second)

llama_perf_context_print:        eval time =  118395.79 ms /   381 runs   (  310.75 ms per token,     3.22 tokens per second)

llama_perf_context_print:       total time =  121395.25 ms /   410 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1330.14 ms /    22 tokens (   60.46 ms per token,    16.54 tokens per second)

llama_perf_context_print:        eval time =   16269.24 ms /    58 runs   (  280.50 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   17797.51 ms /    80 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1528.19 ms /    29 tokens (   52.70 ms per token,    18.98 tokens per second)

llama_perf_context_print:        eval time =  127270.38 ms /   410 runs   (  310.42 ms per token,     3.22 tokens per second)

llama_perf_context_print:       total time =  130361.48 ms /   439 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 162, 'total_tokens': 210}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 178, 'total_tokens': 217}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 381, 'total_tokens': 414}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 58, 'total_tokens': 85}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1760.72 ms /    35 tokens (   50.31 ms per token,    19.88 tokens per second)

llama_perf_context_print:        eval time =   37504.77 ms /   135 runs   (  277.81 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   39750.56 ms /   170 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1231.76 ms /    19 tokens (   64.83 ms per token,    15.43 tokens per second)

llama_perf_context_print:        eval time =   95691.33 ms /   289 runs   (  331.11 ms per token,     3.02 tokens per second)

llama_perf_context_print:       total time =   97973.03 ms /   308 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1338.69 ms /    15 tokens (   89.25 ms per token,    11.21 tokens per second)

llama_perf_context_print:        eval time =  118604.33 ms /   378 runs   (  313.77 ms per token,     3.19 tokens per second)

llama_perf_context_print:       total time =  121396.77 ms /   393 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1077.17 ms /    17 tokens (   63.36 ms per token,    15.78 tokens per second)

llama_perf_context_print:        eval time =  311036.70 ms /   999 runs   (  311.35 ms per token,     3.21 tokens per second)

llama_perf_context_print:       total time =  316626.99 ms /  1016 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 33, 'completion_tokens': 410, 'total_tokens': 443}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 135, 'total_tokens': 174}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 289, 'total_tokens': 312}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 378, 'total_tokens': 397}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =     860.59 ms /    16 tokens (   53.79 ms per token,    18.59 tokens per second)

llama_perf_context_print:        eval time =    8674.95 ms /    31 runs   (  279.84 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =    9647.72 ms /    47 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1325.78 ms /    22 tokens (   60.26 ms per token,    16.59 tokens per second)

llama_perf_context_print:        eval time =   16698.68 ms /    60 runs   (  278.31 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   18235.06 ms /    82 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1100.37 ms /    17 tokens (   64.73 ms per token,    15.45 tokens per second)

llama_perf_context_print:        eval time =  287320.25 ms /   999 runs   (  287.61 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =  292875.35 ms /  1016 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 31, 'total_tokens': 51}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 26, 'completion_tokens': 60, 'total_tokens': 86}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1762.32 ms /    37 tokens (   47.63 ms per token,    21.00 tokens per second)

llama_perf_context_print:        eval time =   20894.76 ms /    75 runs   (  278.60 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   22947.85 ms /   112 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3828.26 ms /    90 tokens (   42.54 ms per token,    23.51 tokens per second)

llama_perf_context_print:        eval time =   11484.55 ms /    41 runs   (  280.11 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   15468.98 ms /   131 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    4676.92 ms /   114 tokens (   41.03 ms per token,    24.38 tokens per second)

llama_perf_context_print:        eval time =   21534.53 ms /    77 runs   (  279.67 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   26494.51 ms /   191 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 21, 'completion_tokens': 1000, 'total_tokens': 1021}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 41, 'completion_tokens': 75, 'total_tokens': 116}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 94, 'completion_tokens': 41, 'total_tokens': 135}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    5202.77 ms /   131 tokens (   39.72 ms per token,    25.18 tokens per second)

llama_perf_context_print:        eval time =   16228.30 ms /    58 runs   (  279.80 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   21656.80 ms /   189 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    5076.67 ms /   119 tokens (   42.66 ms per token,    23.44 tokens per second)

llama_perf_context_print:        eval time =   28270.58 ms /   101 runs   (  279.91 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   33732.59 ms /   220 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3200.95 ms /    76 tokens (   42.12 ms per token,    23.74 tokens per second)

llama_perf_context_print:        eval time =   21182.98 ms /    76 runs   (  278.72 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   24660.82 ms /   152 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    5190.27 ms /   129 tokens (   40.23 ms per token,    24.85 tokens per second)

llama_perf_context_print:        eval time =   36628.72 ms /   131 runs   (  279.61 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   42300.05 ms /   260 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 118, 'completion_tokens': 77, 'total_tokens': 195}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 135, 'completion_tokens': 58, 'total_tokens': 193}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 123, 'completion_tokens': 101, 'total_tokens': 224}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 80, 'completion_tokens': 76, 'total_tokens': 156}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    4145.60 ms /   104 tokens (   39.86 ms per token,    25.09 tokens per second)

llama_perf_context_print:        eval time =   25901.67 ms /    93 runs   (  278.51 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   30385.74 ms /   197 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1290.70 ms /    24 tokens (   53.78 ms per token,    18.59 tokens per second)

llama_perf_context_print:        eval time =   30844.69 ms /   111 runs   (  277.88 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   32541.82 ms /   135 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3059.39 ms /    66 tokens (   46.35 ms per token,    21.57 tokens per second)

llama_perf_context_print:        eval time =   20978.98 ms /    75 runs   (  279.72 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   24312.91 ms /   141 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1241.98 ms /    19 tokens (   65.37 ms per token,    15.30 tokens per second)

llama_perf_context_print:        eval time =   11410.93 ms /    41 runs   (  278.32 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   12805.44 ms /    60 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1914.38 ms /    41 tokens (   46.69 ms per token,    21.42 tokens per second)

llama_perf_context_print:        eval time =   10081.96 ms /    36 runs   (  280.05 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   12128.60 ms /    77 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2677.21 ms /    59 tokens (   45.38 ms per token,    22.04 tokens per second)

llama_perf_context_print:        eval time =   13390.86 ms /    48 runs   (  278.98 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   16247.07 ms /   107 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 133, 'completion_tokens': 131, 'total_tokens': 264}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 108, 'completion_tokens': 93, 'total_tokens': 201}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 28, 'completion_tokens': 111, 'total_tokens': 139}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 70, 'completion_tokens': 75, 'total_tokens': 145}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 23, 'completion_tokens': 41, 'total_tokens': 64}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 36, 'total_tokens': 81}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2473.78 ms /    55 tokens (   44.98 ms per token,    22.23 tokens per second)

llama_perf_context_print:        eval time =   11795.28 ms /    42 runs   (  280.84 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   14423.00 ms /    97 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3294.88 ms /    78 tokens (   42.24 ms per token,    23.67 tokens per second)

llama_perf_context_print:        eval time =   32575.83 ms /   117 runs   (  278.43 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   36294.72 ms /   195 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2864.02 ms /    68 tokens (   42.12 ms per token,    23.74 tokens per second)

llama_perf_context_print:        eval time =   25365.65 ms /    91 runs   (  278.74 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   28557.70 ms /   159 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2564.34 ms /    60 tokens (   42.74 ms per token,    23.40 tokens per second)

llama_perf_context_print:        eval time =   10929.16 ms /    39 runs   (  280.23 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   13636.62 ms /    99 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2520.50 ms /    55 tokens (   45.83 ms per token,    21.82 tokens per second)

llama_perf_context_print:        eval time =   15627.73 ms /    56 runs   (  279.07 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   18352.83 ms /   111 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2404.32 ms /    56 tokens (   42.93 ms per token,    23.29 tokens per second)

llama_perf_context_print:        eval time =   12613.68 ms /    45 runs   (  280.30 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   15183.10 ms /   101 tokens

llama_perf_context_print:        load time =    1714.57 ms

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 48, 'total_tokens': 111}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 42, 'total_tokens': 101}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 82, 'completion_tokens': 117, 'total_tokens': 199}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 91, 'total_tokens': 163}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 39, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 56, 'total_tokens': 115}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 45, 'total_tokens': 105}}
llama_perf_context_print: prompt eval time =    2231.36 ms /    46 tokens (   48.51 ms per token,    20.62 tokens per second)

llama_perf_context_print:        eval time =   11191.67 ms /    40 runs   (  279.79 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   13569.83 ms /    86 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2829.48 ms /    68 tokens (   41.61 ms per token,    24.03 tokens per second)

llama_perf_context_print:        eval time =   13491.58 ms /    48 runs   (  281.07 ms per token,     3.56 tokens per second)

llama_perf_context_print:       total time =   16502.95 ms /   116 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1251.16 ms /    14 tokens (   89.37 ms per token,    11.19 tokens per second)

llama_perf_context_print:        eval time =   28227.58 ms /   102 runs   (  276.74 ms per token,     3.61 tokens per second)

llama_perf_context_print:       total time =   29848.65 ms /   116 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2747.11 ms /    59 tokens (   46.56 ms per token,    21.48 tokens per second)

llama_perf_context_print:        eval time =    6531.12 ms /    23 runs   (  283.96 ms per token,     3.52 tokens per second)

llama_perf_context_print:       total time =    9365.88 ms /    82 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =     949.98 ms /    16 tokens (   59.37 ms per token,    16.84 tokens per second)

llama_perf_context_print:        eval time =   19436.67 ms /    70 runs   (  277.67 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   20639.40 ms /    86 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2324.16 ms /    47 tokens (   49.45 ms per token,    20.22 tokens per second)

llama_perf_context_print:        eval time =    8133.39 ms /    29 runs   (  280.46 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   10564.33 ms /    76 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1143.21 ms /    20 tokens (   57.16 ms per token,    17.49 tokens per second)

llama_perf_context_print:        eval time =  287660.72 ms /   999 runs   (  287.95 ms per token,     3.47 tokens per second)

llama_perf_context_print:       total time =  293473.97 ms /  1019 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2385.98 ms /    49 tokens (   48.69 ms per token,    20.54 tokens per second)

llama_perf_context_print:        eval time =   10162.02 ms /    36 runs   (  282.28 ms per token,     3.54 tokens per second)

llama_perf_context_print:       total time =   12680.96 ms /    85 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =     853.00 ms /    16 tokens (   53.31 ms per token,    18.76 tokens per second)

llama_perf_context_print:        eval time =    8091.48 ms /    29 runs   (  279.02 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =    9055.62 ms /    45 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 50, 'completion_tokens': 40, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 72, 'completion_tokens': 48, 'total_tokens': 120}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 102, 'total_tokens': 120}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 63, 'completion_tokens': 23, 'total_tokens': 86}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 70, 'total_tokens': 90}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 29, 'total_tokens': 80}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 36, 'total_tokens': 89}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 29, 'total_tokens': 49}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3271.28 ms /    75 tokens (   43.62 ms per token,    22.93 tokens per second)

llama_perf_context_print:        eval time =   14545.91 ms /    52 runs   (  279.73 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   18010.04 ms /   127 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1097.99 ms /    20 tokens (   54.90 ms per token,    18.22 tokens per second)

llama_perf_context_print:        eval time =  115751.62 ms /   359 runs   (  322.43 ms per token,     3.10 tokens per second)

llama_perf_context_print:       total time =  118244.17 ms /   379 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2673.69 ms /    64 tokens (   41.78 ms per token,    23.94 tokens per second)

llama_perf_context_print:        eval time =    5975.63 ms /    21 runs   (  284.55 ms per token,     3.51 tokens per second)

llama_perf_context_print:       total time =    8734.38 ms /    85 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2225.72 ms /    43 tokens (   51.76 ms per token,    19.32 tokens per second)

llama_perf_context_print:        eval time =   15886.19 ms /    57 runs   (  278.71 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   18335.45 ms /   100 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1790.05 ms /    35 tokens (   51.14 ms per token,    19.55 tokens per second)

llama_perf_context_print:        eval time =   17762.47 ms /    64 runs   (  277.54 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   19797.23 ms /    99 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2032.48 ms /    39 tokens (   52.11 ms per token,    19.19 tokens per second)

llama_perf_context_print:        eval time =   36449.70 ms /   131 runs   (  278.24 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   38956.99 ms /   170 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1853.70 ms /    40 tokens (   46.34 ms per token,    21.58 tokens per second)

llama_perf_context_print:        eval time =   56501.41 ms /   203 runs   (  278.33 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   59101.99 ms /   243 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 79, 'completion_tokens': 52, 'total_tokens': 131}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 21, 'total_tokens': 89}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 47, 'completion_tokens': 57, 'total_tokens': 104}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 39, 'completion_tokens': 64, 'total_tokens': 103}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 43, 'completion_tokens': 131, 'total_tokens': 174}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2468.39 ms /    57 tokens (   43.31 ms per token,    23.09 tokens per second)

llama_perf_context_print:        eval time =   19236.97 ms /    69 runs   (  278.80 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   21962.31 ms /   126 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2033.58 ms /    44 tokens (   46.22 ms per token,    21.64 tokens per second)

llama_perf_context_print:        eval time =   33672.37 ms /   121 runs   (  278.28 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   36171.42 ms /   165 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2133.96 ms /    41 tokens (   52.05 ms per token,    19.21 tokens per second)

llama_perf_context_print:        eval time =   38840.81 ms /   140 runs   (  277.43 ms per token,     3.60 tokens per second)

llama_perf_context_print:       total time =   41489.14 ms /   181 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1982.07 ms /    44 tokens (   45.05 ms per token,    22.20 tokens per second)

llama_perf_context_print:        eval time =    9802.34 ms /    35 runs   (  280.07 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   11914.08 ms /    79 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2234.98 ms /    45 tokens (   49.67 ms per token,    20.13 tokens per second)

llama_perf_context_print:        eval time =   16996.63 ms /    61 runs   (  278.63 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   19448.51 ms /   106 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1833.56 ms /    38 tokens (   48.25 ms per token,    20.72 tokens per second)

llama_perf_context_print:        eval time =   23945.47 ms /    86 runs   (  278.44 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   26085.92 ms /   124 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 44, 'completion_tokens': 203, 'total_tokens': 247}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 61, 'completion_tokens': 69, 'total_tokens': 130}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 121, 'total_tokens': 169}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 45, 'completion_tokens': 140, 'total_tokens': 185}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 48, 'completion_tokens': 35, 'total_tokens': 83}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 61, 'total_tokens': 110}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2629.13 ms /    61 tokens (   43.10 ms per token,    23.20 tokens per second)

llama_perf_context_print:        eval time =  252067.92 ms /   878 runs   (  287.09 ms per token,     3.48 tokens per second)

llama_perf_context_print:       total time =  258593.21 ms /   939 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 42, 'completion_tokens': 86, 'total_tokens': 128}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2123.54 ms /    48 tokens (   44.24 ms per token,    22.60 tokens per second)

llama_perf_context_print:        eval time =   88546.07 ms /   316 runs   (  280.21 ms per token,     3.57 tokens per second)

llama_perf_context_print:       total time =   91901.58 ms /   364 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2687.47 ms /    55 tokens (   48.86 ms per token,    20.47 tokens per second)

llama_perf_context_print:        eval time =   56906.49 ms /   204 runs   (  278.95 ms per token,     3.58 tokens per second)

llama_perf_context_print:       total time =   60376.36 ms /   259 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    3687.52 ms /    79 tokens (   46.68 ms per token,    21.42 tokens per second)

llama_perf_context_print:        eval time =  290431.96 ms /   999 runs   (  290.72 ms per token,     3.44 tokens per second)

llama_perf_context_print:       total time =  298831.51 ms /  1078 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 65, 'completion_tokens': 878, 'total_tokens': 943}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 52, 'completion_tokens': 316, 'total_tokens': 368}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 204, 'total_tokens': 263}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2813.92 ms /    62 tokens (   45.39 ms per token,    22.03 tokens per second)

llama_perf_context_print:        eval time =   31784.97 ms /   114 runs   (  278.82 ms per token,     3.59 tokens per second)

llama_perf_context_print:       total time =   35029.31 ms /   176 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2832.61 ms /    63 tokens (   44.96 ms per token,    22.24 tokens per second)

llama_perf_context_print:        eval time =  112605.06 ms /   400 runs   (  281.51 ms per token,     3.55 tokens per second)

llama_perf_context_print:       total time =  117032.70 ms /   463 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 83, 'completion_tokens': 1000, 'total_tokens': 1083}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 66, 'completion_tokens': 114, 'total_tokens': 180}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2724.76 ms /    60 tokens (   45.41 ms per token,    22.02 tokens per second)

llama_perf_context_print:        eval time =  291659.97 ms /   999 runs   (  291.95 ms per token,     3.43 tokens per second)

llama_perf_context_print:       total time =  299100.91 ms /  1059 tokens

logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 400, 'total_tokens': 468}}
llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    1781.36 ms /    33 tokens (   53.98 ms per token,    18.53 tokens per second)

llama_perf_context_print:        eval time =    6554.94 ms /    22 runs   (  297.95 ms per token,     3.36 tokens per second)

llama_perf_context_print:       total time =    8437.28 ms /    55 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    2962.43 ms /    58 tokens (   51.08 ms per token,    19.58 tokens per second)

llama_perf_context_print:        eval time =  166677.58 ms /   550 runs   (  303.05 ms per token,     3.30 tokens per second)

llama_perf_context_print:       total time =  171769.30 ms /   608 tokens

llama_perf_context_print:        load time =    1714.57 ms

llama_perf_context_print: prompt eval time =    4745.19 ms /   111 tokens (   42.75 ms per token,    23.39 tokens per second)

llama_perf_context_print:        eval time =  148148.19 ms /   461 runs   (  321.36 ms per token,     3.11 tokens per second)

llama_perf_context_print:       total time =  154671.91 ms /   572 tokens

logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 64, 'completion_tokens': 1000, 'total_tokens': 1064}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 550, 'total_tokens': 612}}
logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 115, 'completion_tokens': 461, 'total_tokens': 576}}
